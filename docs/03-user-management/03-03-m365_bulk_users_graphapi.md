# 3.3 ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ä¸€æ‹¬ç®¡ç† (Microsoft Graph API / Pythonç‰ˆ)

---

## ğŸ“– å­¦ç¿’ç›®æ¨™

Python ã¨ Microsoft Graph API ã‚’æ´»ç”¨ã—ãŸé«˜åº¦ãªãƒ¦ãƒ¼ã‚¶ãƒ¼ä¸€æ‹¬ç®¡ç†æ‰‹æ³•ã‚’ç¿’å¾—ã—ã€æŸ”è»Ÿã§ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªMicrosoft 365ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã®æ§‹ç¯‰ã‚¹ã‚­ãƒ«ã‚’èº«ã«ã¤ã‘ã¾ã™ã€‚PowerShellç‰ˆã§ã¯å®Ÿç¾å›°é›£ãªè¤‡é›‘ãªå‡¦ç†ã‚„ã€ä»–ã‚·ã‚¹ãƒ†ãƒ ã¨ã®é€£æºã«å¯¾å¿œã§ãã‚‹æŠ€è¡“ã‚’ç¿’å¾—ã§ãã¾ã™ã€‚

### ğŸ¯ ã“ã®ç¯€ã§ç¿’å¾—ã™ã‚‹ã“ã¨

- **Pythonç’°å¢ƒã®æ§‹ç¯‰**ã‹ã‚‰ **Microsoft Graph APIé€£æº**ã¾ã§ã€åŸºç¤ã‹ã‚‰å®Ÿè·µã¾ã§ã‚’ç¿’å¾—
- **RESTful API**ã®ç†è§£ã‚’æ·±ã‚ã€Microsoft 365ã®å…¨æ©Ÿèƒ½ã«ãƒ—ãƒ­ã‚°ãƒ©ãƒãƒ†ã‚£ãƒƒã‚¯ã«ã‚¢ã‚¯ã‚»ã‚¹
- **éåŒæœŸå‡¦ç†ãƒ»ä¸¦åˆ—å‡¦ç†**ã«ã‚ˆã‚‹è¶…é«˜é€Ÿãªå¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿å‡¦ç†æ‰‹æ³•ã‚’ãƒã‚¹ã‚¿ãƒ¼
- **è¤‡é›‘ãªãƒ“ã‚¸ãƒã‚¹ãƒ­ã‚¸ãƒƒã‚¯**ã®å®Ÿè£…ã«ã‚ˆã‚Šã€çµ„ç¹”å›ºæœ‰ã®è¦ä»¶ã«æŸ”è»Ÿã«å¯¾å¿œ
- **ä»–ã‚·ã‚¹ãƒ†ãƒ é€£æº**ï¼ˆäººäº‹ã‚·ã‚¹ãƒ†ãƒ ã€å­¦å‹™ã‚·ã‚¹ãƒ†ãƒ ç­‰ï¼‰ã®è¨­è¨ˆãƒ»å®Ÿè£…èƒ½åŠ›ã‚’ç¿’å¾—

### ğŸ’¼ å®Ÿå‹™ã§ã®æ´»ç”¨å ´é¢

- **è¶…å¤§è¦æ¨¡å±•é–‹**: æ•°ä¸‡åè¦æ¨¡ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ç®¡ç†ï¼ˆPowerShellã®å‡¦ç†èƒ½åŠ›ã‚’è¶…ãˆã‚‹è¦æ¨¡ï¼‰
- **ä»–ã‚·ã‚¹ãƒ†ãƒ é€£æº**: äººäº‹ã‚·ã‚¹ãƒ†ãƒ ãƒ»å­¦å‹™ã‚·ã‚¹ãƒ†ãƒ ã¨ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åŒæœŸ
- **è¤‡é›‘ãªæ¥­å‹™ãƒ­ã‚¸ãƒƒã‚¯**: å¤šæ®µéšæ‰¿èªã€æ¡ä»¶åˆ†å²ã€ã‚«ã‚¹ã‚¿ãƒ ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®å®Ÿè£…
- **ç¶™ç¶šçš„ãªè‡ªå‹•åŒ–**: å®šæœŸå®Ÿè¡Œã€ã‚¤ãƒ™ãƒ³ãƒˆé§†å‹•ã«ã‚ˆã‚‹å®Œå…¨è‡ªå‹•åŒ–ã‚·ã‚¹ãƒ†ãƒ 

---

## ğŸ”„ PowerShellç‰ˆã¨ã®æ¯”è¼ƒãƒ»Graph APIç‰ˆã®ç‰¹å¾´

### æ‰‹æ³•åˆ¥ç‰¹å¾´æ¯”è¼ƒ

| é …ç›® | PowerShellç‰ˆ | Graph API (Python)ç‰ˆ | æ¨å¥¨ç”¨é€” |
|------|-------------|---------------------|----------|
| **å­¦ç¿’ã‚³ã‚¹ãƒˆ** | â˜…â˜…â˜† | â˜…â˜…â˜…â˜… | PowerShell: Windowsç®¡ç†è€…ã€Python: é–‹ç™ºè€… |
| **å‡¦ç†é€Ÿåº¦** | ä¸­ç¨‹åº¦ | é«˜é€Ÿï¼ˆéåŒæœŸå‡¦ç†æ´»ç”¨ï¼‰ | Python: å¤§è¦æ¨¡ãƒ»é«˜é€Ÿå‡¦ç†è¦æ±‚æ™‚ |
| **æ‹¡å¼µæ€§** | é™å®šçš„ | éå¸¸ã«é«˜ã„ | Python: ã‚«ã‚¹ã‚¿ãƒ æ©Ÿèƒ½ãƒ»ã‚·ã‚¹ãƒ†ãƒ é€£æº |
| **ãƒ‡ãƒãƒƒã‚°ãƒ»ä¿å®ˆ** | â˜…â˜…â˜† | â˜…â˜…â˜…â˜… | Python: è¤‡é›‘ãªãƒ­ã‚¸ãƒƒã‚¯ãƒ»é•·æœŸä¿å®ˆ |
| **å¯¾è±¡è¦æ¨¡** | ã€œ5,000å | åˆ¶é™ãªã— | Python: è¶…å¤§è¦æ¨¡ç’°å¢ƒ |
| **ã‚·ã‚¹ãƒ†ãƒ é€£æº** | å›°é›£ | å®¹æ˜“ | Python: ä»–ã‚·ã‚¹ãƒ†ãƒ çµ±åˆå¿…é ˆæ™‚ |

### Graph APIç‰ˆã®ä¸»è¦ãªåˆ©ç‚¹

#### 1. **åœ§å€’çš„ãªå‡¦ç†æ€§èƒ½**

```python
# éåŒæœŸå‡¦ç†ã«ã‚ˆã‚‹è¶…é«˜é€ŸåŒ–ã®ä¾‹
import asyncio
import aiohttp

async def create_users_async(users_batch):
    """éåŒæœŸã§ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’ä¸¦åˆ—ä½œæˆï¼ˆå¾“æ¥æ¯”10å€ä»¥ä¸Šé«˜é€Ÿï¼‰"""
    tasks = []
    for user in users_batch:
        task = asyncio.create_task(create_single_user_async(user))
        tasks.append(task)
    
    results = await asyncio.gather(*tasks, return_exceptions=True)
    return results

# 1000åã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’ä¸¦åˆ—ä½œæˆï¼ˆç´„2-3åˆ†ã§å®Œäº†ï¼‰
results = asyncio.run(create_users_async(users_data))
```

#### 2. **é«˜åº¦ãªã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã¨å†è©¦è¡Œãƒ­ã‚¸ãƒƒã‚¯**

```python
from tenacity import retry, wait_exponential, stop_after_attempt

@retry(
    wait=wait_exponential(multiplier=1, min=4, max=10),
    stop=stop_after_attempt(5),
    reraise=True
)
async def robust_user_creation(user_data):
    """æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•ã«ã‚ˆã‚‹è‡ªå‹•å†è©¦è¡Œæ©Ÿèƒ½ä»˜ããƒ¦ãƒ¼ã‚¶ãƒ¼ä½œæˆ"""
    try:
        response = await graph_client.users.post(user_data)
        return {"status": "success", "user": response}
    except APIError as e:
        if e.status_code == 429:  # Rate limit
            await asyncio.sleep(int(e.retry_after))
            raise  # å†è©¦è¡Œã•ã‚Œã‚‹
        elif e.status_code >= 500:  # Server error
            raise  # å†è©¦è¡Œã•ã‚Œã‚‹
        else:
            return {"status": "failed", "error": str(e)}
```

#### 3. **è¤‡é›‘ãªãƒ“ã‚¸ãƒã‚¹ãƒ­ã‚¸ãƒƒã‚¯ã®å®Ÿè£…**

```python
class UniversityUserManager:
    """å¤§å­¦ç‰¹æœ‰ã®è¤‡é›‘ãªè¦ä»¶ã«å¯¾å¿œã—ãŸãƒ¦ãƒ¼ã‚¶ãƒ¼ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ """
    
    async def process_new_semester(self, semester_data):
        """å­¦æœŸé–‹å§‹æ™‚ã®è¤‡é›‘ãªå‡¦ç†ã‚’è‡ªå‹•åŒ–"""
        # 1. æ–°å…¥ç”Ÿã®ã‚¢ã‚«ã‚¦ãƒ³ãƒˆä½œæˆ
        new_students = await self.create_new_students(semester_data.new_students)
        
        # 2. é€²ç´šç”Ÿã®å­¦å¹´æ›´æ–°
        promoted_students = await self.update_grade_levels(semester_data.promotions)
        
        # 3. å’æ¥­ç”Ÿã®æ¨©é™å¤‰æ›´
        graduates = await self.process_graduates(semester_data.graduates)
        
        # 4. æ•™è·å“¡ã®æ‹…å½“å¤‰æ›´
        faculty_updates = await self.update_faculty_assignments(semester_data.faculty_changes)
        
        # 5. å­¦å‹™ã‚·ã‚¹ãƒ†ãƒ ã¨ã®åŒæœŸç¢ºèª
        sync_results = await self.sync_with_student_system()
        
        return {
            "new_students": new_students,
            "promotions": promoted_students,
            "graduates": graduates,
            "faculty_updates": faculty_updates,
            "sync_status": sync_results
        }
```

#### 4. **ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–ã¨ã‚¢ãƒ©ãƒ¼ãƒˆ**

```python
class RealTimeMonitor:
    """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§ã®å‡¦ç†ç›£è¦–ã¨Slack/Teamsé€šçŸ¥"""
    
    async def monitor_bulk_operation(self, operation_id):
        """å¤§è¦æ¨¡å‡¦ç†ã®é€²æ—ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–"""
        while True:
            status = await self.get_operation_status(operation_id)
            
            if status.progress_percentage % 25 == 0:  # 25%åˆ»ã¿ã§é€šçŸ¥
                await self.send_teams_notification(
                    f"å‡¦ç†é€²æ—: {status.progress_percentage}% å®Œäº† "
                    f"({status.completed}/{status.total})"
                )
            
            if status.is_completed:
                await self.send_completion_report(status)
                break
                
            await asyncio.sleep(30)  # 30ç§’é–“éš”ã§ãƒã‚§ãƒƒã‚¯
```

---

## ğŸ› ï¸ Pythonç’°å¢ƒã®æ§‹ç¯‰

### Step 1: Python ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼ˆWindowsç’°å¢ƒï¼‰

#### å…¬å¼Pythonã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ»ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

1. **Pythonå…¬å¼ã‚µã‚¤ãƒˆ**ã«ã‚¢ã‚¯ã‚»ã‚¹: [https://www.python.org/downloads/](https://www.python.org/downloads/)

2. **Windowså‘ã‘ã®æœ€æ–°ç‰ˆPython**ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆPython 3.9ä»¥ä¸Šã‚’æ¨å¥¨ï¼‰

![Pythonå…¬å¼ã‚µã‚¤ãƒˆã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒšãƒ¼ã‚¸](../../assets/images/screenshots/python/python-download-page.png)

3. **ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ©ãƒ¼ã®å®Ÿè¡Œ**:
   ```markdown
   âœ… ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ™‚ã®é‡è¦è¨­å®š
   - â˜‘ï¸ "Add Python to PATH" ã‚’å¿…ãšãƒã‚§ãƒƒã‚¯
   - â˜‘ï¸ "Install for all users" ã‚’é¸æŠï¼ˆæ¨å¥¨ï¼‰
   - ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å…ˆ: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼ˆC:\Program Files\Python39ï¼‰
   ```

4. **ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ç¢ºèª**:
   ```cmd
   # ã‚³ãƒãƒ³ãƒ‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§ç¢ºèª
   python --version
   # å‡ºåŠ›ä¾‹: Python 3.11.5
   
   pip --version
   # å‡ºåŠ›ä¾‹: pip 23.2.1 from C:\Program Files\Python311\Lib\site-packages\pip (python 3.11)
   ```

#### ä»£æ›¿æ–¹æ³•: Microsoft Storeç‰ˆPython

```markdown
ğŸª Microsoft Storeç‰ˆã®ãƒ¡ãƒªãƒƒãƒˆ
- è‡ªå‹•æ›´æ–°
- PATHè¨­å®šä¸è¦
- ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¼·åŒ–
- ç°¡å˜ã‚¢ãƒ³ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ‰‹é †:
1. Microsoft Store ã‚’é–‹ã
2. "Python 3.11" ã§æ¤œç´¢
3. ã€Œå…¥æ‰‹ã€ã‚’ã‚¯ãƒªãƒƒã‚¯
4. è‡ªå‹•çš„ã«PATHãŒè¨­å®šã•ã‚Œã‚‹
```

### Step 2: ä»®æƒ³ç’°å¢ƒã®ä½œæˆã¨è¨­å®š

#### ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç”¨ãƒ•ã‚©ãƒ«ãƒ€ã®ä½œæˆ

```cmd
# ä½œæ¥­ç”¨ãƒ•ã‚©ãƒ«ãƒ€ã®ä½œæˆ
mkdir C:\M365_Management
cd C:\M365_Management

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ã®ä½œæˆ
mkdir scripts
mkdir data
mkdir logs
mkdir config
```

#### Pythonä»®æƒ³ç’°å¢ƒã®ä½œæˆ

**ğŸ¯ ä»®æƒ³ç’°å¢ƒã‚’ä½¿ç”¨ã™ã‚‹ç†ç”±**
- **ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåˆ†é›¢**: ä»–ã®Pythonãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¨ä¾å­˜é–¢ä¿‚ã‚’åˆ†é›¢
- **ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†**: ç‰¹å®šã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’å›ºå®š
- **ç’°å¢ƒå†ç¾**: ä»–ã®ç’°å¢ƒã§ã®åŒä¸€è¨­å®šã®å†ç¾
- **ã‚·ã‚¹ãƒ†ãƒ ä¿è­·**: ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã®Pythonç’°å¢ƒã‚’æ±šæŸ“ã—ãªã„

```cmd
# ä»®æƒ³ç’°å¢ƒã®ä½œæˆ
python -m venv m365_env

# ä»®æƒ³ç’°å¢ƒã®æœ‰åŠ¹åŒ–ï¼ˆWindowsï¼‰
m365_env\Scripts\activate

# ä»®æƒ³ç’°å¢ƒæœ‰åŠ¹åŒ–ã®ç¢ºèª
(m365_env) C:\M365_Management>
```

**Linux/Mac ã®å ´åˆ**:
```bash
# ä»®æƒ³ç’°å¢ƒã®æœ‰åŠ¹åŒ–ï¼ˆLinux/Macï¼‰
source m365_env/bin/activate
```

#### å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

```cmd
# ä»®æƒ³ç’°å¢ƒãŒæœ‰åŠ¹åŒ–ã•ã‚ŒãŸçŠ¶æ…‹ã§å®Ÿè¡Œ

# Microsoft Graph å…¬å¼SDK
pip install msgraph-sdk

# èªè¨¼ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
pip install azure-identity

# éåŒæœŸå‡¦ç†ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
pip install aiohttp asyncio

# ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
pip install pandas openpyxl

# è‡ªå‹•å†è©¦è¡Œãƒ©ã‚¤ãƒ–ãƒ©ãƒª
pip install tenacity

# è¨­å®šç®¡ç†ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
pip install python-dotenv

# ãƒ­ã‚°ç®¡ç†ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
pip install loguru

# ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼
pip install tqdm rich

# JSONã‚¹ã‚­ãƒ¼ãƒæ¤œè¨¼
pip install jsonschema

# HTTPã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
pip install requests
```

#### requirements.txt ã®ä½œæˆ

```python
# requirements.txt ãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆ
cat > requirements.txt << EOF
msgraph-sdk>=1.0.0
azure-identity>=1.14.0
aiohttp>=3.8.5
pandas>=2.0.0
openpyxl>=3.1.0
tenacity>=8.2.0
python-dotenv>=1.0.0
loguru>=0.7.0
tqdm>=4.65.0
rich>=13.5.0
jsonschema>=4.19.0
requests>=2.31.0
asyncio>=3.4.3
EOF

# ä¸€æ‹¬ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install -r requirements.txt
```

### Step 3: IDEãƒ»ã‚¨ãƒ‡ã‚£ã‚¿ã®è¨­å®š

#### Visual Studio Code ã®æ¨å¥¨è¨­å®š

1. **VS Code ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«**: [https://code.visualstudio.com/](https://code.visualstudio.com/)

2. **æ¨å¥¨æ‹¡å¼µæ©Ÿèƒ½ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«**:
   ```markdown
   ğŸ”Œ å¿…é ˆæ‹¡å¼µæ©Ÿèƒ½
   - Python (Microsoft)
   - Pylance (Microsoft) 
   - Python Docstring Generator
   - autoDocstring
   
   ğŸ”Œ æ¨å¥¨æ‹¡å¼µæ©Ÿèƒ½
   - REST Clientï¼ˆAPI ãƒ†ã‚¹ãƒˆç”¨ï¼‰
   - GitLensï¼ˆãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ï¼‰
   - Thunder Clientï¼ˆAPI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆï¼‰
   ```

3. **ãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹è¨­å®š** (.vscode/settings.json):
   ```json
   {
       "python.defaultInterpreterPath": "./m365_env/Scripts/python.exe",
       "python.linting.enabled": true,
       "python.linting.pylintEnabled": true,
       "python.formatting.provider": "black",
       "python.testing.pytestEnabled": true,
       "files.associations": {
           "*.py": "python"
       },
       "editor.rulers": [88],
       "editor.formatOnSave": true
   }
   ```

---

## ğŸ” Microsoft Graph API èªè¨¼è¨­å®š

### Azure AD ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ç™»éŒ²

#### Step 1: Azure Portal ã§ã®ã‚¢ãƒ—ãƒªç™»éŒ²

1. **Azure Portal**ã«ã‚¢ã‚¯ã‚»ã‚¹: [https://portal.azure.com](https://portal.azure.com)

2. **ã€ŒAzure Active Directoryã€** â†’ **ã€Œã‚¢ãƒ—ãƒªã®ç™»éŒ²ã€** ã‚’ã‚¯ãƒªãƒƒã‚¯

3. **ã€Œæ–°è¦ç™»éŒ²ã€**ã‚’ã‚¯ãƒªãƒƒã‚¯:
   ```markdown
   ğŸ“ ã‚¢ãƒ—ãƒªç™»éŒ²è¨­å®š
   - åå‰: "M365 User Management Tool"
   - ã‚µãƒãƒ¼ãƒˆã•ã‚Œã‚‹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®ç¨®é¡: "ã“ã®çµ„ç¹”ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ã¿ã®ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ"
   - ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆ URI: "ãƒ‘ãƒ–ãƒªãƒƒã‚¯ ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ (ãƒ¢ãƒã‚¤ãƒ«ã¨ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—)" â†’ "http://localhost"
   ```

4. **ã€Œç™»éŒ²ã€**ã‚’ã‚¯ãƒªãƒƒã‚¯

#### Step 2: å¿…è¦ãªæ¨©é™ã®è¨­å®š

1. **ã€ŒAPI ã®ã‚¢ã‚¯ã‚»ã‚¹è¨±å¯ã€**ã‚’ã‚¯ãƒªãƒƒã‚¯

2. **ã€Œã‚¢ã‚¯ã‚»ã‚¹è¨±å¯ã®è¿½åŠ ã€** â†’ **ã€ŒMicrosoft Graphã€** â†’ **ã€Œã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®æ¨©é™ã€**

3. **å¿…è¦ãªæ¨©é™ã‚’é¸æŠ**:
   ```markdown
   ğŸ”‘ æœ€å°æ¨©é™ã‚»ãƒƒãƒˆï¼ˆèª­ã¿å–ã‚Šå°‚ç”¨ï¼‰
   - User.Read.All
   - Group.Read.All
   - Directory.Read.All
   
   ğŸ”‘ ä¸€æ‹¬ç®¡ç†ç”¨æ¨©é™ã‚»ãƒƒãƒˆ
   - User.ReadWrite.All
   - Group.ReadWrite.All
   - Directory.ReadWrite.All
   
   ğŸ”‘ ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ç®¡ç†ç”¨æ¨©é™
   - Organization.Read.All
   - Directory.ReadWrite.All
   ```

4. **ã€Œç®¡ç†è€…ã®åŒæ„ã‚’ä¸ãˆã‚‹ã€**ã‚’ã‚¯ãƒªãƒƒã‚¯

#### Step 3: èªè¨¼æƒ…å ±ã®å–å¾—

```markdown
ğŸ” å¿…è¦ãªèªè¨¼æƒ…å ±
- ãƒ†ãƒŠãƒ³ãƒˆ ID (Directory ID)
- ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ ID (Client ID)
- ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆï¼ˆä½œæˆãŒå¿…è¦ï¼‰

ğŸ“‹ ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã®ä½œæˆæ‰‹é †:
1. ã€Œè¨¼æ˜æ›¸ã¨ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã€ã‚’ã‚¯ãƒªãƒƒã‚¯
2. ã€Œæ–°ã—ã„ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã€ã‚’ã‚¯ãƒªãƒƒã‚¯
3. èª¬æ˜: "M365 Management Secret"
4. æœ‰åŠ¹æœŸé™: 24ãƒ¶æœˆï¼ˆæ¨å¥¨ï¼‰
5. ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆå€¤ã‚’ã‚³ãƒ”ãƒ¼ï¼ˆä¸€åº¦ã—ã‹è¡¨ç¤ºã•ã‚Œãªã„ï¼‰
```

### èªè¨¼è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆ

#### .env ãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆï¼ˆæ©Ÿå¯†æƒ…å ±ç®¡ç†ï¼‰

```python
# .env ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ä½œæˆï¼‰
# âš ï¸ æ³¨æ„: ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯ .gitignore ã«è¿½åŠ ã—ã€ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã‹ã‚‰é™¤å¤–ã™ã‚‹

TENANT_ID=your-tenant-id-here
CLIENT_ID=your-client-id-here
CLIENT_SECRET=your-client-secret-here

# ã‚ªãƒ—ã‚·ãƒ§ãƒ³è¨­å®š
GRAPH_ENDPOINT=https://graph.microsoft.com
AUTHORITY=https://login.microsoftonline.com
SCOPE=https://graph.microsoft.com/.default
```

#### èªè¨¼ã‚¯ãƒ©ã‚¹ã®å®Ÿè£…

**ğŸ¯ ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ç›®çš„**
Microsoft Graph API ã¸ã®èªè¨¼ã‚’ç®¡ç†ã—ã€ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³ã®å–å¾—ãƒ»æ›´æ–°ãƒ»æœ‰åŠ¹æ€§ç¢ºèªã‚’è‡ªå‹•åŒ–ã—ã¾ã™ã€‚ç’°å¢ƒå¤‰æ•°ã‹ã‚‰ã®è¨­å®šèª­ã¿è¾¼ã¿ã€ãƒˆãƒ¼ã‚¯ãƒ³ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã‚’å«ã‚€åŒ…æ‹¬çš„ãªèªè¨¼ã‚·ã‚¹ãƒ†ãƒ ã‚’æä¾›ã—ã¾ã™ã€‚

**ğŸ“ Usage**
```python
# åŸºæœ¬çš„ãªä½¿ç”¨æ–¹æ³•
auth = GraphAuthenticator()
token = await auth.get_access_token()

# ã‚«ã‚¹ã‚¿ãƒ ã‚¹ã‚³ãƒ¼ãƒ—ã§ã®èªè¨¼
auth = GraphAuthenticator(scopes=["User.ReadWrite.All", "Group.ReadWrite.All"])
token = await auth.get_access_token()

# èªè¨¼çŠ¶æ…‹ã®ç¢ºèª
if await auth.is_authenticated():
    print("èªè¨¼æ¸ˆã¿")
```

**âš™ï¸ ä¸»ãªæ©Ÿèƒ½**
- ç’°å¢ƒå¤‰æ•°ã‹ã‚‰ã®è‡ªå‹•è¨­å®šèª­ã¿è¾¼ã¿
- ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³ã®è‡ªå‹•å–å¾—ãƒ»æ›´æ–°
- ãƒˆãƒ¼ã‚¯ãƒ³æœ‰åŠ¹æœŸé™ã®è‡ªå‹•ç®¡ç†
- ã‚¨ãƒ©ãƒ¼æ™‚ã®è©³ç´°ãƒ­ã‚°å‡ºåŠ›

#### èªè¨¼ã‚¯ãƒ©ã‚¹ã®å®Ÿè£…

ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã¯ã€Microsoft Graph API ã¸ã®å®‰å…¨ã§åŠ¹ç‡çš„ãªèªè¨¼ã‚’ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹ã§ã™ã€‚ã“ã®ã‚¯ãƒ©ã‚¹ã¯ç’°å¢ƒå¤‰æ•°ã‹ã‚‰èªè¨¼æƒ…å ±ã‚’è‡ªå‹•èª­ã¿è¾¼ã¿ã—ã€ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³ã®å–å¾—ãƒ»æ›´æ–°ãƒ»æœ‰åŠ¹æœŸé™ç®¡ç†ã‚’å…¨ã¦è‡ªå‹•åŒ–ã—ã¾ã™ã€‚

**ä¸»ãªæ©Ÿèƒ½:**
- **.env ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã®è‡ªå‹•è¨­å®šèª­ã¿è¾¼ã¿**: æ©Ÿå¯†æƒ…å ±ã‚’å®‰å…¨ã«ç®¡ç†
- **ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³ã®è‡ªå‹•å–å¾—ãƒ»æ›´æ–°**: æœŸé™åˆ‡ã‚Œã‚’è‡ªå‹•æ¤œçŸ¥ã—ã¦æ›´æ–°
- **ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°**: èªè¨¼å¤±æ•—æ™‚ã®è©³ç´°ãƒ­ã‚°ã¨ã‚¨ãƒ©ãƒ¼æƒ…å ±
- **ã‚¹ãƒ¬ãƒƒãƒ‰ã‚»ãƒ¼ãƒ•**: è¤‡æ•°ã®å‡¦ç†ã‹ã‚‰åŒæ™‚åˆ©ç”¨å¯èƒ½

**ä½¿ç”¨å‰ã®æº–å‚™:**
1. `.env` ãƒ•ã‚¡ã‚¤ãƒ«ã« `TENANT_ID`, `CLIENT_ID`, `CLIENT_SECRET` ã‚’è¨­å®š
2. Azure AD ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§é©åˆ‡ãªæ¨©é™ã‚’ä»˜ä¸
3. ç®¡ç†è€…åŒæ„ã‚’å®Ÿè¡Œ

```python
# auth.py
import os
from typing import Optional, List
from azure.identity import ClientSecretCredential
from azure.core.exceptions import ClientAuthenticationError
from dotenv import load_dotenv
import asyncio
from loguru import logger

class GraphAuthenticator:
    """Microsoft Graph API èªè¨¼ç®¡ç†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, scopes: Optional[List[str]] = None):
        load_dotenv()  # .env ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã¿
        
        self.tenant_id = os.getenv('TENANT_ID')
        self.client_id = os.getenv('CLIENT_ID') 
        self.client_secret = os.getenv('CLIENT_SECRET')
        self.scopes = scopes or [os.getenv('SCOPE', 'https://graph.microsoft.com/.default')]
        
        # å¿…é ˆç’°å¢ƒå¤‰æ•°ã®ç¢ºèª
        if not all([self.tenant_id, self.client_id, self.client_secret]):
            raise ValueError("å¿…é ˆç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“: TENANT_ID, CLIENT_ID, CLIENT_SECRET")
        
        # èªè¨¼ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–
        self.credential = ClientSecretCredential(
            tenant_id=self.tenant_id,
            client_id=self.client_id,
            client_secret=self.client_secret
        )
        
        self._access_token = None
        self._token_expires_at = None
        
        logger.info(f"Graphèªè¨¼ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–å®Œäº† - ãƒ†ãƒŠãƒ³ãƒˆ: {self.tenant_id}")
    
    async def get_access_token(self) -> str:
        """ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³ã®å–å¾—ï¼ˆè‡ªå‹•æ›´æ–°æ©Ÿèƒ½ä»˜ãï¼‰"""
        try:
            # ãƒˆãƒ¼ã‚¯ãƒ³ã®æœ‰åŠ¹æ€§ç¢ºèª
            if self._is_token_valid():
                return self._access_token
            
            # æ–°ã—ã„ãƒˆãƒ¼ã‚¯ãƒ³ã®å–å¾—
            token_result = self.credential.get_token(*self.scopes)
            self._access_token = token_result.token
            self._token_expires_at = token_result.expires_on
            
            logger.info("ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³å–å¾—æˆåŠŸ")
            return self._access_token
            
        except ClientAuthenticationError as e:
            logger.error(f"èªè¨¼å¤±æ•—: {e}")
            raise
        except Exception as e:
            logger.error(f"ãƒˆãƒ¼ã‚¯ãƒ³å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            raise
    
    def _is_token_valid(self) -> bool:
        """ãƒˆãƒ¼ã‚¯ãƒ³ã®æœ‰åŠ¹æ€§ãƒã‚§ãƒƒã‚¯"""
        if not self._access_token or not self._token_expires_at:
            return False
        
        import time
        # 5åˆ†ã®ãƒãƒƒãƒ•ã‚¡ã‚’è¨­ã‘ã¦æœŸé™ã‚’ãƒã‚§ãƒƒã‚¯
        return time.time() < (self._token_expires_at - 300)
    
    async def is_authenticated(self) -> bool:
        """èªè¨¼çŠ¶æ…‹ã®ç¢ºèª"""
        try:
            token = await self.get_access_token()
            return bool(token)
        except Exception:
            return False
    
    def get_headers(self) -> dict:
        """API ãƒªã‚¯ã‚¨ã‚¹ãƒˆç”¨ãƒ˜ãƒƒãƒ€ãƒ¼ã®ç”Ÿæˆ"""
        if not self._access_token:
            raise ValueError("èªè¨¼ãŒå¿…è¦ã§ã™ã€‚å…ˆã« get_access_token() ã‚’å‘¼ã³å‡ºã—ã¦ãã ã•ã„ã€‚")
        
        return {
            'Authorization': f'Bearer {self._access_token}',
            'Content-Type': 'application/json',
            'Accept': 'application/json'
        }

# ä½¿ç”¨ä¾‹
async def main():
    auth = GraphAuthenticator()
    
    try:
        token = await auth.get_access_token()
        print("âœ… èªè¨¼æˆåŠŸ")
        
        headers = auth.get_headers()
        print("ğŸ“‹ ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ˜ãƒƒãƒ€ãƒ¼æº–å‚™å®Œäº†")
        
    except Exception as e:
        print(f"âŒ èªè¨¼å¤±æ•—: {e}")

if __name__ == "__main__":
    asyncio.run(main())
```

---

## ğŸ” Graph API ã«ã‚ˆã‚‹åŸºæœ¬æ“ä½œ

### HTTP ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®å®Ÿè£…

**ğŸ¯ ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ç›®çš„**
Microsoft Graph API ã¸ã® HTTP ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’åŠ¹ç‡çš„ã«å®Ÿè¡Œã™ã‚‹ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚¯ãƒ©ã‚¹ã‚’æä¾›ã—ã¾ã™ã€‚è‡ªå‹•å†è©¦è¡Œã€ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾å¿œã€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã€ãƒ¬ã‚¹ãƒãƒ³ã‚¹è§£æã‚’å«ã‚€å …ç‰¢ãªAPIé€šä¿¡æ©Ÿèƒ½ã‚’å®Ÿè£…ã—ã¾ã™ã€‚

**ğŸ“ Usage**
```python
# åŸºæœ¬çš„ãªä½¿ç”¨æ–¹æ³•
client = GraphAPIClient()

# å˜ä¸€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å–å¾—
user = await client.get_user("t.tanaka@school.edu.jp")

# å…¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å–å¾—ï¼ˆãƒšãƒ¼ã‚¸ãƒ³ã‚°è‡ªå‹•å‡¦ç†ï¼‰
all_users = await client.get_all_users()

# ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ä½œæˆ
new_user_data = {
    "displayName": "ç”°ä¸­å¤ªéƒ",
    "userPrincipalName": "t.tanaka@school.edu.jp",
    "accountEnabled": True,
    "passwordProfile": {
        "password": "TempPass123!",
        "forceChangePasswordNextSignIn": True
    }
}
created_user = await client.create_user(new_user_data)
```

**âš™ï¸ ä¸»ãªæ©Ÿèƒ½**
- è‡ªå‹•èªè¨¼ãƒ˜ãƒƒãƒ€ãƒ¼ä»˜ä¸
- ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã®è‡ªå‹•æ¤œå‡ºãƒ»å¾…æ©Ÿ
- æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•ã«ã‚ˆã‚‹è‡ªå‹•å†è©¦è¡Œ
- ãƒšãƒ¼ã‚¸ãƒ³ã‚°å‡¦ç†ã®è‡ªå‹•åŒ–
- è©³ç´°ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ãƒ»ãƒ‡ãƒãƒƒã‚°æƒ…å ±

### HTTP ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®å®Ÿè£…

ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã¯ã€Microsoft Graph API ã¸ã® HTTP ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’åŠ¹ç‡çš„ã‹ã¤å®‰å…¨ã«å®Ÿè¡Œã™ã‚‹ãŸã‚ã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚¯ãƒ©ã‚¹ã§ã™ã€‚ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºãƒ¬ãƒ™ãƒ«ã®è¦ä»¶ï¼ˆè‡ªå‹•å†è©¦è¡Œã€ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾å¿œã€åŒ…æ‹¬çš„ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ï¼‰ã‚’æº€ãŸã™è¨­è¨ˆã¨ãªã£ã¦ã„ã¾ã™ã€‚

**ã“ã®ã‚¯ãƒ©ã‚¹ãŒè§£æ±ºã™ã‚‹èª²é¡Œ:**
- **ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã®è‡ªå‹•å¯¾å¿œ**: HTTP 429 ã‚¨ãƒ©ãƒ¼ã‚’æ¤œå‡ºã—ã€é©åˆ‡ãªå¾…æ©Ÿæ™‚é–“ã§è‡ªå‹•å†è©¦è¡Œ
- **æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•**: ä¸€æ™‚çš„ãªéšœå®³ã«å¯¾ã™ã‚‹åŠ¹æœçš„ãªå†è©¦è¡Œæˆ¦ç•¥
- **ãƒšãƒ¼ã‚¸ãƒ³ã‚°å‡¦ç†**: å¤§é‡ãƒ‡ãƒ¼ã‚¿ã®è‡ªå‹•åˆ†å‰²å–å¾—
- **æ¥ç¶šç®¡ç†**: ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®é©åˆ‡ãªé–‹å§‹ãƒ»çµ‚äº†ã¨ãƒªã‚½ãƒ¼ã‚¹ç®¡ç†

**ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³:**
```python
# æ¨å¥¨ä½¿ç”¨æ–¹æ³•ï¼ˆéåŒæœŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ï¼‰
async with GraphAPIClient() as client:
    users = await client.get_all_users()
    
# å˜ç™ºä½¿ç”¨ï¼ˆå°è¦æ¨¡å‡¦ç†ç”¨ï¼‰
client = GraphAPIClient()
user = await client.get_user("user@domain.com")
```

**é‡è¦ãªæ³¨æ„äº‹é …:**
- å¤§é‡ã®APIå‘¼ã³å‡ºã—ã‚’è¡Œã†éš›ã¯ã€å¿…ãšã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã‚’ä½¿ç”¨
- ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã¯ Microsoft å´ã§å‹•çš„ã«èª¿æ•´ã•ã‚Œã‚‹ãŸã‚ã€è‡ªå‹•å†è©¦è¡Œæ©Ÿèƒ½ã¯å¿…é ˆ
- æœ¬ç•ªç’°å¢ƒã§ã¯é©åˆ‡ãªãƒ­ã‚°ãƒ¬ãƒ™ãƒ«è¨­å®šã‚’è¡Œã„ã€ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã®å‡ºåŠ›ã‚’åˆ¶å¾¡

```python
# graph_client.py
import aiohttp
import asyncio
import json
from typing import Dict, List, Optional, Any
from tenacity import retry, wait_exponential, stop_after_attempt
from loguru import logger
from auth import GraphAuthenticator

class GraphAPIClient:
    """Microsoft Graph API ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ"""
    
    def __init__(self, base_url: str = "https://graph.microsoft.com/v1.0"):
        self.base_url = base_url
        self.auth = GraphAuthenticator()
        self.session = None
        
    async def __aenter__(self):
        """éåŒæœŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ï¼ˆæ¨å¥¨ä½¿ç”¨æ–¹æ³•ï¼‰"""
        self.session = aiohttp.ClientSession()
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        if self.session:
            await self.session.close()
    
    @retry(
        wait=wait_exponential(multiplier=1, min=4, max=10),
        stop=stop_after_attempt(5),
        reraise=True
    )
    async def _make_request(
        self, 
        method: str, 
        endpoint: str, 
        data: Optional[Dict] = None,
        params: Optional[Dict] = None
    ) -> Dict[str, Any]:
        """HTTP ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®å®Ÿè¡Œï¼ˆè‡ªå‹•å†è©¦è¡Œä»˜ãï¼‰"""
        
        if not self.session:
            self.session = aiohttp.ClientSession()
        
        url = f"{self.base_url}/{endpoint.lstrip('/')}"
        headers = await self._get_headers()
        
        try:
            async with self.session.request(
                method=method,
                url=url,
                headers=headers,
                json=data,
                params=params
            ) as response:
                
                # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã®å‡¦ç†
                if response.status == 429:
                    retry_after = int(response.headers.get('Retry-After', 60))
                    logger.warning(f"ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã«é”ã—ã¾ã—ãŸã€‚{retry_after}ç§’å¾…æ©Ÿã—ã¾ã™ã€‚")
                    await asyncio.sleep(retry_after)
                    raise aiohttp.ClientError("Rate limited")
                
                # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®è§£æ
                response_text = await response.text()
                
                if response.status >= 400:
                    error_data = json.loads(response_text) if response_text else {}
                    error_message = error_data.get('error', {}).get('message', f'HTTP {response.status}')
                    logger.error(f"API ã‚¨ãƒ©ãƒ¼ [{response.status}]: {error_message}")
                    raise aiohttp.ClientError(f"API Error: {error_message}")
                
                # æˆåŠŸãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®å‡¦ç†
                if response_text:
                    return json.loads(response_text)
                else:
                    return {}
                    
        except aiohttp.ClientError as e:
            logger.error(f"ãƒªã‚¯ã‚¨ã‚¹ãƒˆå¤±æ•— [{method} {url}]: {e}")
            raise
        except Exception as e:
            logger.error(f"äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ [{method} {url}]: {e}")
            raise
    
    async def _get_headers(self) -> Dict[str, str]:
        """èªè¨¼ãƒ˜ãƒƒãƒ€ãƒ¼ã®å–å¾—"""
        token = await self.auth.get_access_token()
        return {
            'Authorization': f'Bearer {token}',
            'Content-Type': 'application/json',
            'Accept': 'application/json'
        }
    
    async def get_user(self, user_id: str) -> Dict[str, Any]:
        """ç‰¹å®šãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å–å¾—"""
        return await self._make_request('GET', f'users/{user_id}')
    
    async def get_all_users(self, batch_size: int = 100) -> List[Dict[str, Any]]:
        """å…¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å–å¾—ï¼ˆãƒšãƒ¼ã‚¸ãƒ³ã‚°è‡ªå‹•å‡¦ç†ï¼‰"""
        all_users = []
        next_url = f'users?$top={batch_size}'
        
        while next_url:
            response = await self._make_request('GET', next_url)
            users = response.get('value', [])
            all_users.extend(users)
            
            # æ¬¡ã®ãƒšãƒ¼ã‚¸ã®URLå–å¾—
            next_url = response.get('@odata.nextLink')
            if next_url:
                # ãƒ™ãƒ¼ã‚¹URLã‚’é™¤å»ã—ã¦ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®ã¿æŠ½å‡º
                next_url = next_url.replace(self.base_url + '/', '')
            
            logger.info(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼å–å¾—é€²æ—: {len(all_users)}å")
        
        logger.info(f"å…¨ãƒ¦ãƒ¼ã‚¶ãƒ¼å–å¾—å®Œäº†: ç·æ•° {len(all_users)}å")
        return all_users
    
    async def create_user(self, user_data: Dict[str, Any]) -> Dict[str, Any]:
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ä½œæˆ"""
        return await self._make_request('POST', 'users', data=user_data)
    
    async def update_user(self, user_id: str, user_data: Dict[str, Any]) -> Dict[str, Any]:
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±ã®æ›´æ–°"""
        return await self._make_request('PATCH', f'users/{user_id}', data=user_data)
    
    async def delete_user(self, user_id: str) -> None:
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å‰Šé™¤"""
        await self._make_request('DELETE', f'users/{user_id}')
    
    async def get_user_licenses(self, user_id: str) -> List[Dict[str, Any]]:
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ©ã‚¤ã‚»ãƒ³ã‚¹æƒ…å ±å–å¾—"""
        response = await self._make_request('GET', f'users/{user_id}/licenseDetails')
        return response.get('value', [])
    
    async def assign_license(self, user_id: str, add_licenses: List[str], remove_licenses: List[str] = None) -> Dict[str, Any]:
        """ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã®å‰²ã‚Šå½“ã¦ãƒ»å‰Šé™¤"""
        license_data = {
            "addLicenses": [{"skuId": sku_id} for sku_id in add_licenses],
            "removeLicenses": remove_licenses or []
        }
        return await self._make_request('POST', f'users/{user_id}/assignLicense', data=license_data)

# ä½¿ç”¨ä¾‹
async def example_usage():
    async with GraphAPIClient() as client:
        try:
            # ç‰¹å®šãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å–å¾—
            user = await client.get_user('t.tanaka@school.edu.jp')
            print(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼å–å¾—: {user['displayName']}")
            
            # æ–°ã—ã„ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ä½œæˆ
            new_user = {
                "displayName": "ãƒ†ã‚¹ãƒˆ ãƒ¦ãƒ¼ã‚¶ãƒ¼",
                "userPrincipalName": "test.user@school.edu.jp",
                "accountEnabled": True,
                "usageLocation": "JP",
                "passwordProfile": {
                    "password": "TempPass123!",
                    "forceChangePasswordNextSignIn": True
                }
            }
            
            created = await client.create_user(new_user)
            print(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½œæˆæˆåŠŸ: {created['id']}")
            
        except Exception as e:
            logger.error(f"æ“ä½œå¤±æ•—: {e}")

if __name__ == "__main__":
    asyncio.run(example_usage())
```

### CSV ãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†ãƒ»æ¤œè¨¼

**ğŸ¯ ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ç›®çš„**
CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã€ãƒ‡ãƒ¼ã‚¿å“è³ªæ¤œè¨¼ã€Graph APIå½¢å¼ã¸ã®å¤‰æ›ã‚’è‡ªå‹•åŒ–ã—ã¾ã™ã€‚ä¸æ­£ãƒ‡ãƒ¼ã‚¿ã®æ¤œå‡ºã€é‡è¤‡ãƒã‚§ãƒƒã‚¯ã€å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ç¢ºèªã€ãƒ‡ãƒ¼ã‚¿å‹æ¤œè¨¼ã‚’åŒ…æ‹¬çš„ã«å®Ÿè¡Œã—ã€ä¸€æ‹¬å‡¦ç†ã®ç¢ºå®Ÿæ€§ã‚’å‘ä¸Šã•ã›ã¾ã™ã€‚

**ğŸ“ Usage**
```python
# åŸºæœ¬çš„ãªCSVå‡¦ç†
processor = CSVDataProcessor()
users_data = processor.load_and_validate_csv("users.csv")

# ã‚«ã‚¹ã‚¿ãƒ æ¤œè¨¼ãƒ«ãƒ¼ãƒ«ä»˜ãå‡¦ç†
validator = UserDataValidator(custom_rules=my_validation_rules)
validated_data = processor.load_and_validate_csv("users.csv", validator=validator)

# ã‚¨ãƒ©ãƒ¼ãƒ¬ãƒãƒ¼ãƒˆä»˜ãå‡¦ç†
users_data, errors = processor.load_and_validate_csv("users.csv", return_errors=True)
```

**âš™ï¸ ä¸»ãªæ©Ÿèƒ½**
- CSVèª­ã¿è¾¼ã¿ï¼ˆå„ç¨®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å¯¾å¿œï¼‰
- å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æ¤œè¨¼
- ãƒ‡ãƒ¼ã‚¿å‹ãƒ»å½¢å¼æ¤œè¨¼ï¼ˆãƒ¡ãƒ¼ãƒ«ã€ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ç­‰ï¼‰
- é‡è¤‡ãƒã‚§ãƒƒã‚¯
- Graph APIå½¢å¼ã¸ã®è‡ªå‹•å¤‰æ›
- è©³ç´°ã‚¨ãƒ©ãƒ¼ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ

### CSV ãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†ãƒ»æ¤œè¨¼

ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã¯ã€CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã¨å“è³ªæ¤œè¨¼ã‚’è‡ªå‹•åŒ–ã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ ã§ã™ã€‚å¤§è¦æ¨¡ãªä¸€æ‹¬å‡¦ç†ã«ãŠã„ã¦ã€ãƒ‡ãƒ¼ã‚¿å“è³ªã®ç¢ºä¿ã¯æˆåŠŸã®éµã¨ãªã‚Šã¾ã™ã€‚ã“ã®ã‚·ã‚¹ãƒ†ãƒ ã¯ã€å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®å•é¡Œã‚’äº‹å‰ã«æ¤œå‡ºã—ã€ç¢ºå®Ÿãªå‡¦ç†å®Ÿè¡Œã‚’ä¿è¨¼ã—ã¾ã™ã€‚

**ãƒ‡ãƒ¼ã‚¿å“è³ªæ¤œè¨¼ã®é‡è¦æ€§:**
- **äº‹å‰ã‚¨ãƒ©ãƒ¼æ¤œå‡º**: æ•°æ™‚é–“ã®å‡¦ç†é–‹å§‹å‰ã«å•é¡Œã‚’ç™ºè¦‹
- **éƒ¨åˆ†å¤±æ•—ã®é˜²æ­¢**: ä¸­é€”åŠç«¯ãªçŠ¶æ…‹ã§ã®å‡¦ç†åœæ­¢ã‚’å›é¿
- **é‹ç”¨åŠ¹ç‡å‘ä¸Š**: æ‰‹ä½œæ¥­ã§ã®ãƒ‡ãƒ¼ã‚¿ç¢ºèªä½œæ¥­ã‚’è‡ªå‹•åŒ–
- **ç›£æŸ»å¯¾å¿œ**: ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã®é€æ˜æ€§ã¨è¿½è·¡å¯èƒ½æ€§ã‚’ç¢ºä¿

**æ¤œè¨¼é …ç›®ã®è©³ç´°:**
1. **å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æ¤œè¨¼**: ç©ºå€¤ãƒ»nullå€¤ã®æ¤œå‡º
2. **ãƒ‡ãƒ¼ã‚¿å½¢å¼æ¤œè¨¼**: ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ãƒ»ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰è¤‡é›‘æ€§ã®ãƒã‚§ãƒƒã‚¯
3. **é‡è¤‡æ¤œè¨¼**: åŒä¸€çµ„ç¹”å†…ã§ã®UPNé‡è¤‡ã®æ¤œå‡º
4. **æ–‡å­—æ•°åˆ¶é™**: Microsoft 365ã®åˆ¶é™å€¤ã¸ã®æº–æ‹ ç¢ºèª
5. **æ–‡å­—ã‚³ãƒ¼ãƒ‰æ¤œè¨¼**: ãƒãƒ«ãƒãƒã‚¤ãƒˆæ–‡å­—ã®é©åˆ‡ãªå‡¦ç†

**å®Ÿç”¨çš„ãªä½¿ç”¨ä¾‹:**
```python
# åŸºæœ¬çš„ãªä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³
processor = CSVDataProcessor()
users_data = processor.load_and_validate_csv("users.csv")

# ã‚¨ãƒ©ãƒ¼è©³ç´°ã®å–å¾—
users_data, errors = processor.load_and_validate_csv("users.csv", return_errors=True)
if errors:
    processor.generate_error_report(errors, "error_report.xlsx")
```

**CSVä½œæˆæ™‚ã®æ³¨æ„äº‹é …:**
- æ–‡å­—ã‚³ãƒ¼ãƒ‰ã¯ UTF-8 with BOM ã‚’æ¨å¥¨ï¼ˆExceläº’æ›æ€§ï¼‰
- ã‚«ãƒ³ãƒã‚’å«ã‚€ãƒ‡ãƒ¼ã‚¿ã¯å¼•ç”¨ç¬¦ã§å›²ã‚€
- æ”¹è¡Œæ–‡å­—ã¯çµ±ä¸€ï¼ˆWindows: CRLFæ¨å¥¨ï¼‰
- ç©ºç™½è¡Œã¯ãƒ•ã‚¡ã‚¤ãƒ«æœ«å°¾ã«ä½œã‚‰ãªã„

```python
# csv_processor.py
import pandas as pd
import re
from typing import List, Dict, Any, Tuple, Optional
from dataclasses import dataclass
from loguru import logger
import json

@dataclass
class ValidationError:
    """æ¤œè¨¼ã‚¨ãƒ©ãƒ¼ã®è©³ç´°æƒ…å ±"""
    row_number: int
    field_name: str
    field_value: Any
    error_message: str
    severity: str = "error"  # error, warning, info

class UserDataValidator:
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿ã®æ¤œè¨¼ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.required_fields = [
            'displayName', 'userPrincipalName', 'givenName', 
            'surname', 'passwordProfile'
        ]
        
        self.email_pattern = re.compile(r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$')
        self.password_pattern = re.compile(r'^(?=.*[a-z])(?=.*[A-Z])(?=.*\d)(?=.*[@$!%*?&])[A-Za-z\d@$!%*?&]{8,}$')
    
    def validate_user_data(self, user_data: Dict[str, Any], row_number: int) -> List[ValidationError]:
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿ã®åŒ…æ‹¬çš„æ¤œè¨¼"""
        errors = []
        
        # å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ç¢ºèª
        for field in self.required_fields:
            if field not in user_data or not user_data[field]:
                errors.append(ValidationError(
                    row_number=row_number,
                    field_name=field,
                    field_value=user_data.get(field),
                    error_message=f"å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ '{field}' ãŒç©ºã§ã™"
                ))
        
        # ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹å½¢å¼ã®ç¢ºèª
        upn = user_data.get('userPrincipalName', '')
        if upn and not self.email_pattern.match(upn):
            errors.append(ValidationError(
                row_number=row_number,
                field_name='userPrincipalName',
                field_value=upn,
                error_message="ç„¡åŠ¹ãªãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹å½¢å¼ã§ã™"
            ))
        
        # ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰è¤‡é›‘æ€§ã®ç¢ºèª
        password = user_data.get('passwordProfile', {}).get('password', '')
        if password and not self.password_pattern.match(password):
            errors.append(ValidationError(
                row_number=row_number,
                field_name='password',
                field_value="[ãƒã‚¹ã‚¯æ¸ˆã¿]",
                error_message="ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒè¤‡é›‘æ€§è¦ä»¶ã‚’æº€ãŸã—ã¦ã„ã¾ã›ã‚“ï¼ˆ8æ–‡å­—ä»¥ä¸Šã€å¤§æ–‡å­—ãƒ»å°æ–‡å­—ãƒ»æ•°å­—ãƒ»è¨˜å·ã‚’å«ã‚€ï¼‰"
            ))
        
        # è¡¨ç¤ºåã®å¦¥å½“æ€§ç¢ºèª
        display_name = user_data.get('displayName', '')
        if display_name and len(display_name) > 256:
            errors.append(ValidationError(
                row_number=row_number,
                field_name='displayName',
                field_value=display_name[:50] + "...",
                error_message="è¡¨ç¤ºåãŒé•·ã™ãã¾ã™ï¼ˆ256æ–‡å­—ä»¥å†…ï¼‰"
            ))
        
        return errors
    
    def check_duplicates(self, users_data: List[Dict[str, Any]]) -> List[ValidationError]:
        """é‡è¤‡ãƒã‚§ãƒƒã‚¯"""
        errors = []
        upn_counts = {}
        
        for i, user in enumerate(users_data):
            upn = user.get('userPrincipalName', '').lower()
            if upn in upn_counts:
                errors.append(ValidationError(
                    row_number=i + 2,  # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’è€ƒæ…®
                    field_name='userPrincipalName',
                    field_value=upn,
                    error_message=f"é‡è¤‡ã™ã‚‹UPN: è¡Œ{upn_counts[upn] + 2}ã¨é‡è¤‡"
                ))
            else:
                upn_counts[upn] = i
        
        return errors

class CSVDataProcessor:
    """CSV ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.validator = UserDataValidator()
    
    def load_csv(self, file_path: str, encoding: str = 'utf-8') -> pd.DataFrame:
        """CSV ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ï¼ˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°è‡ªå‹•æ¤œå‡ºï¼‰"""
        encodings = ['utf-8', 'utf-8-sig', 'shift_jis', 'cp932']
        
        for enc in encodings:
            try:
                df = pd.read_csv(file_path, encoding=enc)
                logger.info(f"CSVèª­ã¿è¾¼ã¿æˆåŠŸ: {file_path} (ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°: {enc})")
                return df
            except UnicodeDecodeError:
                continue
            except Exception as e:
                logger.error(f"CSVèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
                raise
        
        raise ValueError(f"ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸ: {encodings}")
    
    def csv_to_graph_format(self, df: pd.DataFrame) -> List[Dict[str, Any]]:
        """CSV ãƒ‡ãƒ¼ã‚¿ã‚’ Graph API å½¢å¼ã«å¤‰æ›"""
        graph_users = []
        
        for _, row in df.iterrows():
            # NaNå€¤ã‚’ç©ºæ–‡å­—åˆ—ã«å¤‰æ›
            row = row.fillna('')
            
            # Graph API ç”¨ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæ§‹ç¯‰
            user_data = {
                "displayName": str(row.get('DisplayName', '')),
                "userPrincipalName": str(row.get('UserPrincipalName', '')).lower(),
                "givenName": str(row.get('FirstName', '')),
                "surname": str(row.get('LastName', '')),
                "accountEnabled": True,
                "usageLocation": str(row.get('UsageLocation', 'JP')),
                "passwordProfile": {
                    "password": str(row.get('Password', '')),
                    "forceChangePasswordNextSignIn": bool(row.get('ForcePasswordChange', True))
                }
            }
            
            # ã‚ªãƒ—ã‚·ãƒ§ãƒ³é …ç›®ã®è¿½åŠ 
            optional_fields = {
                'department': 'Department',
                'jobTitle': 'JobTitle',
                'officeLocation': 'OfficeLocation',
                'businessPhones': 'PhoneNumber'
            }
            
            for graph_field, csv_field in optional_fields.items():
                value = str(row.get(csv_field, '')).strip()
                if value:
                    if graph_field == 'businessPhones':
                        user_data[graph_field] = [value]
                    else:
                        user_data[graph_field] = value
            
            graph_users.append(user_data)
        
        return graph_users
    
    def load_and_validate_csv(
        self, 
        file_path: str, 
        return_errors: bool = False
    ) -> Tuple[List[Dict[str, Any]], List[ValidationError]]:
        """CSV ã®èª­ã¿è¾¼ã¿ã¨æ¤œè¨¼ã‚’ä¸€æ‹¬å®Ÿè¡Œ"""
        
        logger.info(f"CSVå‡¦ç†é–‹å§‹: {file_path}")
        
        # CSVèª­ã¿è¾¼ã¿
        df = self.load_csv(file_path)
        logger.info(f"èª­ã¿è¾¼ã¿å®Œäº†: {len(df)}è¡Œ")
        
        # Graph APIå½¢å¼ã«å¤‰æ›
        users_data = self.csv_to_graph_format(df)
        
        # ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼
        all_errors = []
        
        # å„è¡Œã®æ¤œè¨¼
        for i, user in enumerate(users_data):
            row_errors = self.validator.validate_user_data(user, i + 2)
            all_errors.extend(row_errors)
        
        # é‡è¤‡ãƒã‚§ãƒƒã‚¯
        duplicate_errors = self.validator.check_duplicates(users_data)
        all_errors.extend(duplicate_errors)
        
        # ã‚¨ãƒ©ãƒ¼ã‚µãƒãƒªãƒ¼ã®è¡¨ç¤º
        if all_errors:
            logger.warning(f"æ¤œè¨¼ã‚¨ãƒ©ãƒ¼ {len(all_errors)}ä»¶ã‚’æ¤œå‡º:")
            for error in all_errors[:10]:  # æœ€åˆã®10ä»¶ã®ã¿è¡¨ç¤º
                logger.warning(f"  è¡Œ{error.row_number}: {error.field_name} - {error.error_message}")
            
            if len(all_errors) > 10:
                logger.warning(f"  ... ä»– {len(all_errors) - 10}ä»¶")
        else:
            logger.info("âœ… å…¨ãƒ‡ãƒ¼ã‚¿ã®æ¤œè¨¼ãŒå®Œäº†ã—ã¾ã—ãŸï¼ˆã‚¨ãƒ©ãƒ¼ãªã—ï¼‰")
        
        if return_errors:
            return users_data, all_errors
        else:
            # ã‚¨ãƒ©ãƒ¼ãŒã‚ã‚‹å ´åˆã¯ä¾‹å¤–ã‚’ç™ºç”Ÿ
            if all_errors:
                error_summary = f"{len(all_errors)}ä»¶ã®æ¤œè¨¼ã‚¨ãƒ©ãƒ¼ãŒã‚ã‚Šã¾ã™"
                raise ValueError(error_summary)
            return users_data
    
    def generate_error_report(self, errors: List[ValidationError], output_path: str):
        """ã‚¨ãƒ©ãƒ¼ãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ"""
        if not errors:
            logger.info("ã‚¨ãƒ©ãƒ¼ãŒãªã„ãŸã‚ã€ãƒ¬ãƒãƒ¼ãƒˆã¯ç”Ÿæˆã•ã‚Œã¾ã›ã‚“")
            return
        
        # ã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’DataFrameã«å¤‰æ›
        error_data = []
        for error in errors:
            error_data.append({
                'è¡Œç•ªå·': error.row_number,
                'ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å': error.field_name,
                'ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å€¤': error.field_value,
                'ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸': error.error_message,
                'é‡è¦åº¦': error.severity
            })
        
        error_df = pd.DataFrame(error_data)
        error_df.to_excel(output_path, index=False, sheet_name='æ¤œè¨¼ã‚¨ãƒ©ãƒ¼')
        
        logger.info(f"ã‚¨ãƒ©ãƒ¼ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¾ã—ãŸ: {output_path}")

# ä½¿ç”¨ä¾‹
async def example_csv_processing():
    processor = CSVDataProcessor()
    
    try:
        # CSVã®èª­ã¿è¾¼ã¿ã¨æ¤œè¨¼
        users_data, errors = processor.load_and_validate_csv(
            "sample_users.csv", 
            return_errors=True
        )
        
        if errors:
            # ã‚¨ãƒ©ãƒ¼ãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ
            processor.generate_error_report(errors, "validation_errors.xlsx")
            
            # ã‚¨ãƒ©ãƒ¼ã®ãªã„ãƒ‡ãƒ¼ã‚¿ã®ã¿æŠ½å‡º
            valid_users = []
            error_rows = {error.row_number for error in errors}
            
            for i, user in enumerate(users_data):
                if (i + 2) not in error_rows:  # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’è€ƒæ…®
                    valid_users.append(user)
            
            logger.info(f"æœ‰åŠ¹ãªãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿: {len(valid_users)}ä»¶")
            return valid_users
        else:
            logger.info(f"å…¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿ãŒæœ‰åŠ¹: {len(users_data)}ä»¶")
            return users_data
            
    except Exception as e:
        logger.error(f"CSVå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
        raise

if __name__ == "__main__":
    asyncio.run(example_csv_processing())
```

---

## ğŸš€ é«˜é€Ÿä¸€æ‹¬å‡¦ç†ã®å®Ÿè£…

### éåŒæœŸå‡¦ç†ã«ã‚ˆã‚‹è¶…é«˜é€ŸåŒ–

**ğŸ¯ ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ç›®çš„**
Python ã®éåŒæœŸå‡¦ç†æ©Ÿèƒ½ã‚’æœ€å¤§é™æ´»ç”¨ã—ã€å¾“æ¥ã®é€æ¬¡å‡¦ç†ã¨æ¯”è¼ƒã—ã¦5-10å€ã®å‡¦ç†é€Ÿåº¦ã‚’å®Ÿç¾ã—ã¾ã™ã€‚å¤§è¦æ¨¡ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½œæˆã«ãŠã„ã¦ã€æ•°åƒåã®ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’æ•°åˆ†ã§å‡¦ç†ã§ãã‚‹é«˜æ€§èƒ½ã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚

**ğŸ“ Usage**
```python
# åŸºæœ¬çš„ãªé«˜é€Ÿä¸€æ‹¬ä½œæˆ
manager = AsyncBulkUserManager()
results = await manager.create_users_async(users_data, concurrency=20)

# é€²æ—ç›£è¦–ä»˜ãå‡¦ç†
results = await manager.create_users_with_progress(users_data, progress_callback=my_progress_handler)

# ãƒãƒƒãƒå‡¦ç†ï¼ˆãƒ¡ãƒ¢ãƒªåŠ¹ç‡é‡è¦–ï¼‰
results = await manager.create_users_in_batches(users_data, batch_size=100, concurrency=10)
```

**âš™ï¸ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**
- `users_data`: ä½œæˆå¯¾è±¡ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒªã‚¹ãƒˆ
- `concurrency`: åŒæ™‚å®Ÿè¡Œæ•°ï¼ˆæ¨å¥¨: 10-30ï¼‰
- `batch_size`: ãƒãƒƒãƒã‚µã‚¤ã‚ºï¼ˆãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡èª¿æ•´ï¼‰
- `progress_callback`: é€²æ—é€šçŸ¥ç”¨ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°

**ğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒ**
- é€æ¬¡å‡¦ç†: 1000ãƒ¦ãƒ¼ã‚¶ãƒ¼ = ç´„45åˆ†
- éåŒæœŸå‡¦ç†ï¼ˆ20ä¸¦åˆ—ï¼‰: 1000ãƒ¦ãƒ¼ã‚¶ãƒ¼ = ç´„5åˆ†
- éåŒæœŸå‡¦ç†ï¼ˆ30ä¸¦åˆ—ï¼‰: 1000ãƒ¦ãƒ¼ã‚¶ãƒ¼ = ç´„3åˆ†

### éåŒæœŸå‡¦ç†ã«ã‚ˆã‚‹è¶…é«˜é€ŸåŒ–

ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã¯ã€Python ã®éåŒæœŸå‡¦ç†ï¼ˆasyncioï¼‰ã‚’æ´»ç”¨ã—ã¦ã€å¾“æ¥ã®é€æ¬¡å‡¦ç†ã¨æ¯”è¼ƒã—ã¦**5-10å€ã®å‡¦ç†é€Ÿåº¦**ã‚’å®Ÿç¾ã™ã‚‹é«˜æ€§èƒ½ãƒ¦ãƒ¼ã‚¶ãƒ¼ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã§ã™ã€‚å¤§è¦æ¨¡çµ„ç¹”ã§ã®æ•°åƒåã®ã‚¢ã‚«ã‚¦ãƒ³ãƒˆå‡¦ç†ã‚’æ•°åˆ†ã§å®Œäº†ã§ãã¾ã™ã€‚

**éåŒæœŸå‡¦ç†ã®æŠ€è¡“çš„å„ªä½æ€§:**
- **I/Oå¾…æ©Ÿæ™‚é–“ã®æœ‰åŠ¹æ´»ç”¨**: APIå¿œç­”å¾…ã¡ä¸­ã«ä»–ã®å‡¦ç†ã‚’ä¸¦åˆ—å®Ÿè¡Œ
- **CPUåŠ¹ç‡ã®æœ€å¤§åŒ–**: å˜ä¸€ãƒ—ãƒ­ã‚»ã‚¹ã§æ•°åã®åŒæ™‚å‡¦ç†ã‚’å®Ÿç¾
- **ãƒ¡ãƒ¢ãƒªåŠ¹ç‡**: ã‚¹ãƒ¬ãƒƒãƒ‰ãƒ—ãƒ¼ãƒ«æ¯”ã§å¤§å¹…ãªãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡å‰Šæ¸›
- **ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£**: ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢æ€§èƒ½ã«å¿œã˜ãŸæŸ”è»Ÿãªèª¿æ•´

**ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒï¼ˆ1000ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å ´åˆï¼‰:**
```
é€æ¬¡å‡¦ç†:     ç´„45åˆ†  ï¼ˆ1ä»¶ãšã¤é †ç•ªã«å‡¦ç†ï¼‰
éåŒæœŸå‡¦ç†:   ç´„5åˆ†   ï¼ˆ20ä»¶ä¸¦åˆ—ã€9å€é«˜é€Ÿï¼‰
æœ€é©åŒ–ç‰ˆ:     ç´„3åˆ†   ï¼ˆ30ä»¶ä¸¦åˆ—ã€15å€é«˜é€Ÿï¼‰
```

**åŒæ™‚å®Ÿè¡Œæ•°ã®é¸æŠæŒ‡é‡:**
- **å°è¦æ¨¡ï¼ˆã€œ200åï¼‰**: 10-15ä¸¦åˆ—ï¼ˆå®‰å®šæ€§é‡è¦–ï¼‰
- **ä¸­è¦æ¨¡ï¼ˆ200-1000åï¼‰**: 15-25ä¸¦åˆ—ï¼ˆãƒãƒ©ãƒ³ã‚¹å‹ï¼‰
- **å¤§è¦æ¨¡ï¼ˆ1000åã€œï¼‰**: 25-35ä¸¦åˆ—ï¼ˆé€Ÿåº¦é‡è¦–ï¼‰
- **æ³¨æ„**: 40ä¸¦åˆ—ä»¥ä¸Šã¯APIåˆ¶é™ã«æŠµè§¦ã™ã‚‹å¯èƒ½æ€§ãŒé«˜ã„

**å®Ÿè£…æ™‚ã®é‡è¦ãƒã‚¤ãƒ³ãƒˆ:**
1. **ã‚»ãƒãƒ•ã‚©åˆ¶å¾¡**: åŒæ™‚å®Ÿè¡Œæ•°ã®å³å¯†ãªåˆ¶é™
2. **ä¾‹å¤–ã®åˆ†é›¢**: 1ä»¶ã®å¤±æ•—ãŒå…¨ä½“ã«å½±éŸ¿ã—ãªã„è¨­è¨ˆ
3. **é€²æ—ã®å¯è¦–åŒ–**: é•·æ™‚é–“å‡¦ç†ã§ã®çŠ¶æ³æŠŠæ¡
4. **ãƒ¡ãƒ¢ãƒªç®¡ç†**: å¤§é‡ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®é©åˆ‡ãªè§£æ”¾

**ä½¿ç”¨å‰ã®ç¢ºèªäº‹é …:**
- Python 3.7ä»¥ä¸Šï¼ˆasyncio ã®å®‰å®šç‰ˆï¼‰
- ååˆ†ãªãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å¸¯åŸŸï¼ˆ100Mbpsä»¥ä¸Šæ¨å¥¨ï¼‰
- Microsoft Graph API ã®åˆ©ç”¨åˆ¶é™ç¢ºèª

```python
# async_bulk_manager.py
import asyncio
import aiohttp
from typing import List, Dict, Any, Callable, Optional
from dataclasses import dataclass, field
from datetime import datetime
import time
from concurrent.futures import ThreadPoolExecutor
from loguru import logger
import json
from graph_client import GraphAPIClient

@dataclass
class ProcessingResult:
    """å‡¦ç†çµæœã®è©³ç´°æƒ…å ±"""
    success_count: int = 0
    failed_count: int = 0
    total_count: int = 0
    start_time: datetime = field(default_factory=datetime.now)
    end_time: Optional[datetime] = None
    successful_users: List[Dict[str, Any]] = field(default_factory=list)
    failed_users: List[Dict[str, Any]] = field(default_factory=list)
    processing_time: Optional[float] = None
    
    def finalize(self):
        """å‡¦ç†å®Œäº†æ™‚ã®æœ€çµ‚åŒ–"""
        self.end_time = datetime.now()
        self.processing_time = (self.end_time - self.start_time).total_seconds()
        self.total_count = self.success_count + self.failed_count
    
    def get_summary(self) -> Dict[str, Any]:
        """å‡¦ç†ã‚µãƒãƒªãƒ¼ã®å–å¾—"""
        return {
            "ç·æ•°": self.total_count,
            "æˆåŠŸ": self.success_count,
            "å¤±æ•—": self.failed_count,
            "æˆåŠŸç‡": f"{(self.success_count / self.total_count * 100):.1f}%" if self.total_count > 0 else "0%",
            "å‡¦ç†æ™‚é–“": f"{self.processing_time:.1f}ç§’" if self.processing_time else "æœªå®Œäº†",
            "å‡¦ç†é€Ÿåº¦": f"{self.total_count / self.processing_time:.1f}ãƒ¦ãƒ¼ã‚¶ãƒ¼/ç§’" if self.processing_time and self.processing_time > 0 else "è¨ˆç®—ä¸å¯"
        }

class AsyncBulkUserManager:
    """éåŒæœŸå¤§é‡ãƒ¦ãƒ¼ã‚¶ãƒ¼ç®¡ç†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, max_concurrent_requests: int = 20):
        self.max_concurrent_requests = max_concurrent_requests
        self.semaphore = asyncio.Semaphore(max_concurrent_requests)
        self.client = None
    
    async def __aenter__(self):
        """éåŒæœŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼"""
        self.client = GraphAPIClient()
        await self.client.__aenter__()
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """ãƒªã‚½ãƒ¼ã‚¹ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        if self.client:
            await self.client.__aexit__(exc_type, exc_val, exc_tb)
    
    async def create_single_user_async(self, user_data: Dict[str, Any]) -> Dict[str, Any]:
        """å˜ä¸€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®éåŒæœŸä½œæˆï¼ˆã‚»ãƒãƒ•ã‚©åˆ¶å¾¡ä»˜ãï¼‰"""
        async with self.semaphore:
            try:
                start_time = time.time()
                result = await self.client.create_user(user_data)
                processing_time = time.time() - start_time
                
                return {
                    "status": "success",
                    "user_data": user_data,
                    "created_user": result,
                    "processing_time": processing_time
                }
                
            except Exception as e:
                return {
                    "status": "failed",
                    "user_data": user_data,
                    "error": str(e),
                    "error_type": type(e).__name__
                }
    
    async def create_users_async(
        self, 
        users_data: List[Dict[str, Any]], 
        progress_callback: Optional[Callable] = None
    ) -> ProcessingResult:
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®éåŒæœŸä¸€æ‹¬ä½œæˆ"""
        
        logger.info(f"éåŒæœŸä¸€æ‹¬ä½œæˆé–‹å§‹: {len(users_data)}åã®ãƒ¦ãƒ¼ã‚¶ãƒ¼")
        logger.info(f"ä¸¦åˆ—å‡¦ç†æ•°: {self.max_concurrent_requests}")
        
        result = ProcessingResult()
        result.total_count = len(users_data)
        
        # å…¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®éåŒæœŸã‚¿ã‚¹ã‚¯ã‚’ä½œæˆ
        tasks = []
        for i, user_data in enumerate(users_data):
            task = asyncio.create_task(
                self.create_single_user_async(user_data),
                name=f"create_user_{i}"
            )
            tasks.append(task)
        
        # é€²æ—ç›£è¦–ç”¨ã®éåŒæœŸã‚¿ã‚¹ã‚¯
        if progress_callback:
            progress_task = asyncio.create_task(
                self._monitor_progress(tasks, progress_callback)
            )
        
        # å…¨ã‚¿ã‚¹ã‚¯ã®å®Œäº†ã‚’å¾…æ©Ÿ
        completed_tasks = await asyncio.gather(*tasks, return_exceptions=True)
        
        # é€²æ—ç›£è¦–ã®åœæ­¢
        if progress_callback:
            progress_task.cancel()
        
        # çµæœã®é›†è¨ˆ
        for task_result in completed_tasks:
            if isinstance(task_result, Exception):
                result.failed_count += 1
                result.failed_users.append({
                    "error": str(task_result),
                    "error_type": type(task_result).__name__
                })
            elif task_result["status"] == "success":
                result.success_count += 1
                result.successful_users.append(task_result)
            else:
                result.failed_count += 1
                result.failed_users.append(task_result)
        
        result.finalize()
        
        # çµæœã‚µãƒãƒªãƒ¼ã®è¡¨ç¤º
        summary = result.get_summary()
        logger.info("=== éåŒæœŸä¸€æ‹¬ä½œæˆå®Œäº† ===")
        for key, value in summary.items():
            logger.info(f"  {key}: {value}")
        
        return result
    
    async def _monitor_progress(self, tasks: List[asyncio.Task], callback: Callable):
        """é€²æ—ç›£è¦–ï¼ˆéåŒæœŸï¼‰"""
        total_tasks = len(tasks)
        
        while True:
            completed = sum(1 for task in tasks if task.done())
            progress_percentage = (completed / total_tasks) * 100
            
            await callback(completed, total_tasks, progress_percentage)
            
            if completed == total_tasks:
                break
            
            await asyncio.sleep(5)  # 5ç§’é–“éš”ã§é€²æ—ç¢ºèª
    
    async def create_users_in_batches(
        self,
        users_data: List[Dict[str, Any]],
        batch_size: int = 100,
        delay_between_batches: float = 2.0
    ) -> ProcessingResult:
        """ãƒãƒƒãƒå‡¦ç†ã«ã‚ˆã‚‹ä¸€æ‹¬ä½œæˆï¼ˆãƒ¡ãƒ¢ãƒªåŠ¹ç‡é‡è¦–ï¼‰"""
        
        logger.info(f"ãƒãƒƒãƒå‡¦ç†é–‹å§‹: {len(users_data)}åã‚’{batch_size}åãšã¤å‡¦ç†")
        
        overall_result = ProcessingResult()
        overall_result.total_count = len(users_data)
        
        # ãƒãƒƒãƒã”ã¨ã«å‡¦ç†
        for i in range(0, len(users_data), batch_size):
            batch = users_data[i:i + batch_size]
            batch_number = i // batch_size + 1
            total_batches = (len(users_data) + batch_size - 1) // batch_size
            
            logger.info(f"ãƒãƒƒãƒ {batch_number}/{total_batches} å‡¦ç†é–‹å§‹: {len(batch)}å")
            
            # ãƒãƒƒãƒã®éåŒæœŸå‡¦ç†
            batch_result = await self.create_users_async(batch)
            
            # çµæœã®çµ±åˆ
            overall_result.success_count += batch_result.success_count
            overall_result.failed_count += batch_result.failed_count
            overall_result.successful_users.extend(batch_result.successful_users)
            overall_result.failed_users.extend(batch_result.failed_users)
            
            logger.info(f"ãƒãƒƒãƒ {batch_number} å®Œäº†: æˆåŠŸ{batch_result.success_count}å, å¤±æ•—{batch_result.failed_count}å")
            
            # ãƒãƒƒãƒé–“ã®å¾…æ©Ÿ
            if i + batch_size < len(users_data):
                logger.info(f"{delay_between_batches}ç§’å¾…æ©Ÿä¸­...")
                await asyncio.sleep(delay_between_batches)
        
        overall_result.finalize()
        
        # æœ€çµ‚ã‚µãƒãƒªãƒ¼
        summary = overall_result.get_summary()
        logger.info("=== ãƒãƒƒãƒå‡¦ç†å®Œäº† ===")
        for key, value in summary.items():
            logger.info(f"  {key}: {value}")
        
        return overall_result
    
    async def update_users_async(
        self,
        updates_data: List[Dict[str, Any]]
    ) -> ProcessingResult:
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±ã®éåŒæœŸä¸€æ‹¬æ›´æ–°"""
        
        logger.info(f"éåŒæœŸä¸€æ‹¬æ›´æ–°é–‹å§‹: {len(updates_data)}åã®ãƒ¦ãƒ¼ã‚¶ãƒ¼")
        
        result = ProcessingResult()
        result.total_count = len(updates_data)
        
        async def update_single_user(update_data: Dict[str, Any]) -> Dict[str, Any]:
            async with self.semaphore:
                try:
                    user_id = update_data.pop('userPrincipalName')  # æ›´æ–°å¯¾è±¡ã®è­˜åˆ¥å­
                    updated_user = await self.client.update_user(user_id, update_data)
                    
                    return {
                        "status": "success",
                        "user_id": user_id,
                        "updated_user": updated_user
                    }
                    
                except Exception as e:
                    return {
                        "status": "failed",
                        "user_id": update_data.get('userPrincipalName', 'unknown'),
                        "error": str(e),
                        "error_type": type(e).__name__
                    }
        
        # å…¨æ›´æ–°ã‚¿ã‚¹ã‚¯ã®éåŒæœŸå®Ÿè¡Œ
        tasks = [update_single_user(update.copy()) for update in updates_data]
        completed_tasks = await asyncio.gather(*tasks, return_exceptions=True)
        
        # çµæœã®é›†è¨ˆ
        for task_result in completed_tasks:
            if isinstance(task_result, Exception):
                result.failed_count += 1
                result.failed_users.append({"error": str(task_result)})
            elif task_result["status"] == "success":
                result.success_count += 1
                result.successful_users.append(task_result)
            else:
                result.failed_count += 1
                result.failed_users.append(task_result)
        
        result.finalize()
        
        # çµæœè¡¨ç¤º
        summary = result.get_summary()
        logger.info("=== éåŒæœŸä¸€æ‹¬æ›´æ–°å®Œäº† ===")
        for key, value in summary.items():
            logger.info(f"  {key}: {value}")
        
        return result

# ä½¿ç”¨ä¾‹ã¨ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯
async def progress_handler(completed: int, total: int, percentage: float):
    """é€²æ—è¡¨ç¤ºç”¨ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
    print(f"\ré€²æ—: {completed}/{total} ({percentage:.1f}%) å®Œäº†", end="", flush=True)

async def example_async_bulk_creation():
    """éåŒæœŸä¸€æ‹¬å‡¦ç†ã®ä½¿ç”¨ä¾‹"""
    
    # ã‚µãƒ³ãƒ—ãƒ«ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ
    users_data = []
    for i in range(100):
        user = {
            "displayName": f"ãƒ†ã‚¹ãƒˆãƒ¦ãƒ¼ã‚¶ãƒ¼ {i+1}",
            "userPrincipalName": f"test{i+1:03d}@school.edu.jp",
            "givenName": f"ãƒ¦ãƒ¼ã‚¶ãƒ¼{i+1}",
            "surname": "ãƒ†ã‚¹ãƒˆ",
            "accountEnabled": True,
            "usageLocation": "JP",
            "passwordProfile": {
                "password": f"TempPass{i+1:03d}!",
                "forceChangePasswordNextSignIn": True
            }
        }
        users_data.append(user)
    
    # éåŒæœŸä¸€æ‹¬ä½œæˆã®å®Ÿè¡Œ
    async with AsyncBulkUserManager(max_concurrent_requests=15) as manager:
        try:
            # é€²æ—ç›£è¦–ä»˜ãã§å®Ÿè¡Œ
            result = await manager.create_users_async(
                users_data, 
                progress_callback=progress_handler
            )
            
            print(f"\n\nâœ… å‡¦ç†å®Œäº†!")
            print(f"æˆåŠŸ: {result.success_count}å")
            print(f"å¤±æ•—: {result.failed_count}å")
            print(f"å‡¦ç†æ™‚é–“: {result.processing_time:.1f}ç§’")
            
            if result.failed_users:
                print("\nâŒ å¤±æ•—ã—ãŸãƒ¦ãƒ¼ã‚¶ãƒ¼:")
                for failed in result.failed_users[:5]:  # æœ€åˆã®5ä»¶ã®ã¿è¡¨ç¤º
                    print(f"  - {failed.get('user_data', {}).get('userPrincipalName', 'unknown')}: {failed.get('error', 'unknown error')}")
            
        except Exception as e:
            logger.error(f"ä¸€æ‹¬ä½œæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

if __name__ == "__main__":
    asyncio.run(example_async_bulk_creation())
```

### ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆãªé€²æ—ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ 

**ğŸ¯ ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ç›®çš„**
å¤§è¦æ¨¡ãªä¸€æ‹¬å‡¦ç†ã®é€²æ—ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§å¯è¦–åŒ–ã—ã€å‡¦ç†çŠ¶æ³ã®æŠŠæ¡ã€ETAï¼ˆå®Œäº†äºˆæƒ³æ™‚åˆ»ï¼‰ã®ç®—å‡ºã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ã‚’æä¾›ã—ã¾ã™ã€‚Web ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã€Slack/Teamsé€šçŸ¥ã€è©³ç´°ãƒ­ã‚°å‡ºåŠ›ã«ã‚ˆã‚Šã€é‹ç”¨ãƒãƒ¼ãƒ ãŒå‡¦ç†çŠ¶æ³ã‚’çš„ç¢ºã«æŠŠæ¡ã§ãã¾ã™ã€‚

**ğŸ“ Usage**
```python
# åŸºæœ¬çš„ãªé€²æ—ç›£è¦–
monitor = IntelligentProgressMonitor()
await monitor.start_monitoring(operation_id="bulk_creation_001")

# Web ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ä»˜ãç›£è¦–
monitor = IntelligentProgressMonitor(enable_web_dashboard=True)
await monitor.start_monitoring_with_dashboard(operation_id="bulk_creation_001", port=8080)

# é€šçŸ¥æ©Ÿèƒ½ä»˜ãç›£è¦–
monitor = IntelligentProgressMonitor(
    slack_webhook_url="https://hooks.slack.com/...",
    teams_webhook_url="https://outlook.office.com/webhook/..."
)
```

**âš™ï¸ ä¸»ãªæ©Ÿèƒ½**
- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é€²æ—è¡¨ç¤ºï¼ˆã‚³ãƒ³ã‚½ãƒ¼ãƒ«ãƒ»Webãƒ»é€šçŸ¥ï¼‰
- ETAï¼ˆå®Œäº†äºˆæƒ³æ™‚åˆ»ï¼‰ã®å‹•çš„è¨ˆç®—
- å‡¦ç†é€Ÿåº¦ã®ç›£è¦–ãƒ»åˆ†æ
- ã‚¨ãƒ©ãƒ¼ç‡ã®è¿½è·¡
- ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨çŠ¶æ³ã®ç›£è¦–
- è‡ªå‹•ã‚¢ãƒ©ãƒ¼ãƒˆæ©Ÿèƒ½

### ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆãªé€²æ—ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ 

ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã¯ã€å¤§è¦æ¨¡ä¸€æ‹¬å‡¦ç†ã®ãŸã‚ã®åŒ…æ‹¬çš„ãªç›£è¦–ãƒ»ã‚¢ãƒ©ãƒ¼ãƒˆã‚·ã‚¹ãƒ†ãƒ ã§ã™ã€‚å˜ãªã‚‹é€²æ—è¡¨ç¤ºã‚’è¶…ãˆã¦ã€**äºˆæ¸¬åˆ†æ**ã€**ç•°å¸¸æ¤œçŸ¥**ã€**è‡ªå‹•é€šçŸ¥**ã‚’çµ±åˆã—ãŸã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºãƒ¬ãƒ™ãƒ«ã®ç›£è¦–ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã§ã™ã€‚

**å¾“æ¥ã®é€²æ—è¡¨ç¤ºã¨ã®é•ã„:**
- **äºˆæ¸¬æ©Ÿèƒ½**: ETAï¼ˆå®Œäº†äºˆæƒ³æ™‚åˆ»ï¼‰ã®å‹•çš„è¨ˆç®—
- **ç•°å¸¸æ¤œçŸ¥**: å‡¦ç†é€Ÿåº¦ä½ä¸‹ãƒ»ã‚¨ãƒ©ãƒ¼ç‡ä¸Šæ˜‡ã®è‡ªå‹•æ¤œå‡º  
- **ãƒ—ãƒ­ã‚¢ã‚¯ãƒ†ã‚£ãƒ–é€šçŸ¥**: å•é¡Œç™ºç”Ÿå‰ã®æ—©æœŸè­¦å‘Š
- **åŒ…æ‹¬çš„ãƒ¡ãƒˆãƒªã‚¯ã‚¹**: æˆåŠŸç‡ãƒ»é€Ÿåº¦ãƒ»ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹ã®çµ±åˆç›£è¦–

**ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ ã®ä¾¡å€¤:**
1. **é‹ç”¨åŠ¹ç‡å‘ä¸Š**: ç„¡äººé‹è»¢ã§ã®å®‰å…¨ãªå¤§è¦æ¨¡å‡¦ç†
2. **å•é¡Œã®æ—©æœŸç™ºè¦‹**: æ•°æ™‚é–“ã®å‡¦ç†ä¸­æ–­ã‚’æ•°åˆ†ã§æ¤œçŸ¥
3. **é€æ˜æ€§ã®ç¢ºä¿**: ã‚¹ãƒ†ãƒ¼ã‚¯ãƒ›ãƒ«ãƒ€ãƒ¼ã¸ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ çŠ¶æ³å…±æœ‰
4. **è‡ªå‹•åŒ–ã®ä¿ƒé€²**: äººçš„ç›£è¦–ã‚³ã‚¹ãƒˆã®å‰Šæ¸›

**é€šçŸ¥ãƒ»ã‚¢ãƒ©ãƒ¼ãƒˆæ©Ÿèƒ½:**
- **Slack/Teamsçµ±åˆ**: ãƒãƒ£ãƒƒãƒˆãƒ„ãƒ¼ãƒ«ã§ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é€šçŸ¥
- **ãƒã‚¤ãƒ«ã‚¹ãƒˆãƒ¼ãƒ³é€šçŸ¥**: 25%ã€50%ã€75%ã€90%ã®ç¯€ç›®ã§è‡ªå‹•å ±å‘Š
- **ç•°å¸¸ã‚¢ãƒ©ãƒ¼ãƒˆ**: ã‚¨ãƒ©ãƒ¼ç‡10%è¶…éã€å‡¦ç†åœæ­¢ã€é€Ÿåº¦ä½ä¸‹ã‚’å³åº§ã«é€šçŸ¥
- **å®Œäº†ãƒ¬ãƒãƒ¼ãƒˆ**: è©³ç´°ãªå®Ÿè¡Œçµæœã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ

**ä¼æ¥­ç’°å¢ƒã§ã®å®Ÿç”¨ä¾‹:**
```python
# å¤œé–“ãƒãƒƒãƒå‡¦ç†ã§ã®ç„¡äººç›£è¦–
monitor = IntelligentProgressMonitor(
    slack_webhook_url="https://hooks.slack.com/...",
    teams_webhook_url="https://outlook.office.com/webhook/..."
)

# ç¿Œæœã«ã¯è©³ç´°ãªãƒ¬ãƒãƒ¼ãƒˆãŒãƒãƒ£ãƒƒãƒˆã«é…ä¿¡ã•ã‚Œã‚‹
await monitor.start_monitoring(total_items=5000, progress_callback=get_progress)
```

**ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºå¯èƒ½ãªè¨­å®š:**
- ã‚¢ãƒ©ãƒ¼ãƒˆé–¾å€¤ï¼ˆã‚¨ãƒ©ãƒ¼ç‡ã€å‡¦ç†é€Ÿåº¦ã€åœæ­¢æ™‚é–“ï¼‰
- é€šçŸ¥é–“éš”ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ30ç§’ã€èª¿æ•´å¯èƒ½ï¼‰
- ãƒ¡ãƒˆãƒªã‚¯ã‚¹ä¿æŒæœŸé–“ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ24æ™‚é–“ï¼‰
- ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰æ›´æ–°é »åº¦

```python
# intelligent_monitor.py
import asyncio
import time
from datetime import datetime, timedelta
from typing import Dict, Any, Optional, Callable, List
from dataclasses import dataclass, field
import json
import aiohttp
from rich.console import Console
from rich.progress import Progress, TaskID, BarColumn, TextColumn, TimeRemainingColumn
from rich.table import Table
from rich.live import Live
import psutil
from loguru import logger

@dataclass
class MonitoringMetrics:
    """ç›£è¦–ãƒ¡ãƒˆãƒªã‚¯ã‚¹"""
    total_items: int
    completed_items: int = 0
    successful_items: int = 0
    failed_items: int = 0
    start_time: datetime = field(default_factory=datetime.now)
    last_update_time: datetime = field(default_factory=datetime.now)
    items_per_second: float = 0.0
    estimated_completion_time: Optional[datetime] = None
    error_rate: float = 0.0
    
    def update_metrics(self, completed: int, successful: int, failed: int):
        """ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®æ›´æ–°"""
        self.completed_items = completed
        self.successful_items = successful
        self.failed_items = failed
        self.last_update_time = datetime.now()
        
        # å‡¦ç†é€Ÿåº¦ã®è¨ˆç®—
        elapsed_time = (self.last_update_time - self.start_time).total_seconds()
        if elapsed_time > 0:
            self.items_per_second = self.completed_items / elapsed_time
        
        # å®Œäº†äºˆæƒ³æ™‚åˆ»ã®è¨ˆç®—
        if self.items_per_second > 0:
            remaining_items = self.total_items - self.completed_items
            remaining_seconds = remaining_items / self.items_per_second
            self.estimated_completion_time = self.last_update_time + timedelta(seconds=remaining_seconds)
        
        # ã‚¨ãƒ©ãƒ¼ç‡ã®è¨ˆç®—
        if self.completed_items > 0:
            self.error_rate = (self.failed_items / self.completed_items) * 100
    
    def get_progress_percentage(self) -> float:
        """é€²æ—ãƒ‘ãƒ¼ã‚»ãƒ³ãƒ†ãƒ¼ã‚¸ã®å–å¾—"""
        return (self.completed_items / self.total_items) * 100 if self.total_items > 0 else 0

class IntelligentProgressMonitor:
    """ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆé€²æ—ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(
        self,
        update_interval: float = 2.0,
        slack_webhook_url: Optional[str] = None,
        teams_webhook_url: Optional[str] = None,
        enable_web_dashboard: bool = False
    ):
        self.update_interval = update_interval
        self.slack_webhook_url = slack_webhook_url
        self.teams_webhook_url = teams_webhook_url
        self.enable_web_dashboard = enable_web_dashboard
        
        self.console = Console()
        self.metrics: Optional[MonitoringMetrics] = None
        self.monitoring_active = False
        
        # ã‚¢ãƒ©ãƒ¼ãƒˆè¨­å®š
        self.alert_thresholds = {
            "error_rate": 10.0,  # 10%ä»¥ä¸Šã®ã‚¨ãƒ©ãƒ¼ç‡ã§ã‚¢ãƒ©ãƒ¼ãƒˆ
            "slow_processing": 0.5,  # 0.5ä»¶/ç§’ä»¥ä¸‹ã§ã‚¢ãƒ©ãƒ¼ãƒˆ
            "stalled_time": 300  # 5åˆ†é–“é€²æ—ãªã—ã§ã‚¢ãƒ©ãƒ¼ãƒˆ
        }
        
        self.last_progress_time = datetime.now()
        self.alerts_sent = set()
    
    async def start_monitoring(
        self,
        total_items: int,
        progress_callback: Callable[[], tuple[int, int, int]]  # (completed, successful, failed)
    ):
        """ç›£è¦–é–‹å§‹"""
        self.metrics = MonitoringMetrics(total_items=total_items)
        self.monitoring_active = True
        
        logger.info(f"é€²æ—ç›£è¦–é–‹å§‹: ç·æ•°{total_items}ä»¶")
        
        # Rich ã® Progress ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆè¨­å®š
        with Progress(
            TextColumn("[bold blue]{task.description}"),
            BarColumn(bar_width=40),
            "[progress.percentage]{task.percentage:>3.1f}%",
            "â€¢",
            TextColumn("[bold green]{task.completed}/{task.total}"),
            "â€¢",
            TextColumn("[bold cyan]{task.fields[speed]:.1f} items/sec"),
            "â€¢",
            TimeRemainingColumn(),
            refresh_per_second=4,
        ) as progress:
            
            main_task = progress.add_task(
                "ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½œæˆé€²æ—",
                total=total_items,
                speed=0.0
            )
            
            while self.monitoring_active:
                try:
                    # é€²æ—æƒ…å ±ã®å–å¾—
                    completed, successful, failed = progress_callback()
                    
                    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®æ›´æ–°
                    old_completed = self.metrics.completed_items
                    self.metrics.update_metrics(completed, successful, failed)
                    
                    # é€²æ—ã®æ›´æ–°æ¤œå‡º
                    if completed > old_completed:
                        self.last_progress_time = datetime.now()
                    
                    # Rich Progress ã®æ›´æ–°
                    progress.update(
                        main_task,
                        completed=completed,
                        speed=self.metrics.items_per_second
                    )
                    
                    # ã‚¢ãƒ©ãƒ¼ãƒˆãƒã‚§ãƒƒã‚¯
                    await self._check_alerts()
                    
                    # å®šæœŸé€šçŸ¥ï¼ˆ25%åˆ»ã¿ï¼‰
                    await self._send_milestone_notifications()
                    
                    # å®Œäº†ãƒã‚§ãƒƒã‚¯
                    if completed >= total_items:
                        break
                    
                    await asyncio.sleep(self.update_interval)
                    
                except Exception as e:
                    logger.error(f"ç›£è¦–ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
                    break
        
        # æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆã®é€ä¿¡
        await self._send_completion_report()
    
    async def _check_alerts(self):
        """ã‚¢ãƒ©ãƒ¼ãƒˆãƒã‚§ãƒƒã‚¯"""
        if not self.metrics:
            return
        
        current_time = datetime.now()
        
        # ã‚¨ãƒ©ãƒ¼ç‡ã‚¢ãƒ©ãƒ¼ãƒˆ
        if (self.metrics.error_rate > self.alert_thresholds["error_rate"] and 
            "high_error_rate" not in self.alerts_sent):
            await self._send_alert(
                f"âš ï¸ é«˜ã‚¨ãƒ©ãƒ¼ç‡æ¤œå‡º: {self.metrics.error_rate:.1f}%",
                "error_rate"
            )
            self.alerts_sent.add("high_error_rate")
        
        # å‡¦ç†é€Ÿåº¦ä½ä¸‹ã‚¢ãƒ©ãƒ¼ãƒˆ
        if (self.metrics.items_per_second < self.alert_thresholds["slow_processing"] and 
            self.metrics.completed_items > 50 and  # ååˆ†ãªã‚µãƒ³ãƒ—ãƒ«æ•°ãŒå¿…è¦
            "slow_processing" not in self.alerts_sent):
            await self._send_alert(
                f"âš ï¸ å‡¦ç†é€Ÿåº¦ä½ä¸‹: {self.metrics.items_per_second:.2f} items/sec",
                "processing"
            )
            self.alerts_sent.add("slow_processing")
        
        # å‡¦ç†åœæ­¢ã‚¢ãƒ©ãƒ¼ãƒˆ
        stalled_seconds = (current_time - self.last_progress_time).total_seconds()
        if (stalled_seconds > self.alert_thresholds["stalled_time"] and 
            "stalled" not in self.alerts_sent):
            await self._send_alert(
                f"ğŸš¨ å‡¦ç†ãŒåœæ­¢ã—ã¦ã„ã‚‹å¯èƒ½æ€§: {stalled_seconds:.0f}ç§’é–“é€²æ—ãªã—",
                "stalled"
            )
            self.alerts_sent.add("stalled")
    
    async def _send_milestone_notifications(self):
        """ãƒã‚¤ãƒ«ã‚¹ãƒˆãƒ¼ãƒ³é€šçŸ¥ï¼ˆ25%åˆ»ã¿ï¼‰"""
        if not self.metrics:
            return
        
        progress_percentage = self.metrics.get_progress_percentage()
        milestones = [25, 50, 75, 90]
        
        for milestone in milestones:
            if (progress_percentage >= milestone and 
                f"milestone_{milestone}" not in self.alerts_sent):
                
                eta_str = ""
                if self.metrics.estimated_completion_time:
                    eta_str = f"\näºˆæƒ³å®Œäº†æ™‚åˆ»: {self.metrics.estimated_completion_time.strftime('%H:%M:%S')}"
                
                await self._send_notification(
                    f"ğŸ“Š é€²æ— {milestone}% é”æˆ\n"
                    f"å®Œäº†: {self.metrics.completed_items}/{self.metrics.total_items}\n"
                    f"æˆåŠŸç‡: {((self.metrics.successful_items / self.metrics.completed_items) * 100):.1f}%\n"
                    f"å‡¦ç†é€Ÿåº¦: {self.metrics.items_per_second:.1f} items/sec"
                    f"{eta_str}"
                )
                self.alerts_sent.add(f"milestone_{milestone}")
    
    async def _send_completion_report(self):
        """å®Œäº†ãƒ¬ãƒãƒ¼ãƒˆã®é€ä¿¡"""
        if not self.metrics:
            return
        
        total_time = (datetime.now() - self.metrics.start_time).total_seconds()
        
        report = f"""
ğŸ‰ ä¸€æ‹¬å‡¦ç†å®Œäº†ãƒ¬ãƒãƒ¼ãƒˆ

ğŸ“Š å‡¦ç†çµæœ:
â€¢ ç·æ•°: {self.metrics.total_items}ä»¶
â€¢ æˆåŠŸ: {self.metrics.successful_items}ä»¶
â€¢ å¤±æ•—: {self.metrics.failed_items}ä»¶
â€¢ æˆåŠŸç‡: {((self.metrics.successful_items / self.metrics.total_items) * 100):.1f}%

â±ï¸ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹:
â€¢ ç·å‡¦ç†æ™‚é–“: {total_time:.1f}ç§’
â€¢ å¹³å‡å‡¦ç†é€Ÿåº¦: {self.metrics.items_per_second:.1f} items/sec
â€¢ æœ€å¤§ç†è«–å‡¦ç†èƒ½åŠ›: {self.metrics.items_per_second * 3600:.0f} items/hour

ğŸ–¥ï¸ ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹:
â€¢ CPUä½¿ç”¨ç‡: {psutil.cpu_percent()}%
â€¢ ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡: {psutil.virtual_memory().percent}%
"""
        await self._send_notification(report)
    
    async def _send_notification(self, message: str):
        """é€šçŸ¥ã®é€ä¿¡ï¼ˆSlack/Teamsï¼‰"""
        tasks = []
        
        if self.slack_webhook_url:
            tasks.append(self._send_slack_notification(message))
        
        if self.teams_webhook_url:
            tasks.append(self._send_teams_notification(message))
        
        if tasks:
            await asyncio.gather(*tasks, return_exceptions=True)
    
    async def _send_alert(self, message: str, alert_type: str):
        """ã‚¢ãƒ©ãƒ¼ãƒˆé€ä¿¡"""
        alert_message = f"ğŸš¨ ALERT [{alert_type.upper()}]\n{message}"
        await self._send_notification(alert_message)
        logger.warning(f"ã‚¢ãƒ©ãƒ¼ãƒˆé€ä¿¡: {message}")
    
    async def _send_slack_notification(self, message: str):
        """Slacké€šçŸ¥"""
        if not self.slack_webhook_url:
            return
        
        payload = {
            "text": message,
            "username": "M365 Management Bot",
            "icon_emoji": ":office:"
        }
        
        try:
            async with aiohttp.ClientSession() as session:
                async with session.post(self.slack_webhook_url, json=payload) as response:
                    if response.status == 200:
                        logger.debug("Slacké€šçŸ¥é€ä¿¡æˆåŠŸ")
                    else:
                        logger.warning(f"Slacké€šçŸ¥é€ä¿¡å¤±æ•—: {response.status}")
        except Exception as e:
            logger.error(f"Slacké€šçŸ¥ã‚¨ãƒ©ãƒ¼: {e}")
    
    async def _send_teams_notification(self, message: str):
        """Teamsé€šçŸ¥"""
        if not self.teams_webhook_url:
            return
        
        payload = {
            "@type": "MessageCard",
            "@context": "http://schema.org/extensions",
            "summary": "M365 Management Notification",
            "themeColor": "0078D4",
            "sections": [{
                "activityTitle": "Microsoft 365 ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ",
                "activitySubtitle": "ä¸€æ‹¬å‡¦ç†é€šçŸ¥",
                "text": message
            }]
        }
        
        try:
            async with aiohttp.ClientSession() as session:
                async with session.post(self.teams_webhook_url, json=payload) as response:
                    if response.status == 200:
                        logger.debug("Teamsé€šçŸ¥é€ä¿¡æˆåŠŸ")
                    else:
                        logger.warning(f"Teamsé€šçŸ¥é€ä¿¡å¤±æ•—: {response.status}")
        except Exception as e:
            logger.error(f"Teamsé€šçŸ¥ã‚¨ãƒ©ãƒ¼: {e}")
    
    def stop_monitoring(self):
        """ç›£è¦–åœæ­¢"""
        self.monitoring_active = False
        logger.info("é€²æ—ç›£è¦–ã‚’åœæ­¢ã—ã¾ã—ãŸ")

# ä½¿ç”¨ä¾‹
async def example_with_monitoring():
    """é€²æ—ç›£è¦–ä»˜ãã®ä¸€æ‹¬å‡¦ç†ä¾‹"""
    
    # ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–
    monitor = IntelligentProgressMonitor(
        update_interval=1.0,
        slack_webhook_url="https://hooks.slack.com/your-webhook-url",
        enable_web_dashboard=True
    )
    
    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿
    users_data = [{"name": f"user{i}"} for i in range(500)]
    
    # å‡¦ç†çŠ¶æ³ã‚’è¿½è·¡ã™ã‚‹å¤‰æ•°
    completed = 0
    successful = 0
    failed = 0
    
    def get_progress():
        return completed, successful, failed
    
    # ç›£è¦–é–‹å§‹
    monitor_task = asyncio.create_task(
        monitor.start_monitoring(len(users_data), get_progress)
    )
    
    # å®Ÿéš›ã®å‡¦ç†ï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
    async with AsyncBulkUserManager() as manager:
        # å‡¦ç†ã®å®Ÿè¡Œ
        for i, user in enumerate(users_data):
            # å®Ÿéš›ã®å‡¦ç†ã‚’ã“ã“ã§å®Ÿè¡Œ
            await asyncio.sleep(0.1)  # å‡¦ç†æ™‚é–“ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
            
            completed += 1
            if i % 10 != 0:  # 90%ã®æˆåŠŸç‡ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
                successful += 1
            else:
                failed += 1
    
    # ç›£è¦–åœæ­¢
    monitor.stop_monitoring()
    await monitor_task

if __name__ == "__main__":
    asyncio.run(example_with_monitoring())
```

---

## ğŸ§ª å®Ÿç¿’æ¼”ç¿’: Graph API ç‰ˆ

### æ¼”ç¿’1: Pythonç’°å¢ƒæ§‹ç¯‰ã¨åŸºæœ¬APIæ“ä½œï¼ˆ45åˆ†ï¼‰

#### Part A: ç’°å¢ƒæ§‹ç¯‰ï¼ˆ20åˆ†ï¼‰

```markdown
ğŸ› ï¸ å®Ÿç¿’å†…å®¹: å®Œå…¨ãªPythoné–‹ç™ºç’°å¢ƒã®æ§‹ç¯‰

1. Python 3.11ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
2. ä»®æƒ³ç’°å¢ƒã®ä½œæˆãƒ»æœ‰åŠ¹åŒ–
3. å¿…è¦ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ä¸€æ‹¬ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
4. VS Code ã®è¨­å®š
5. Azure AD ã‚¢ãƒ—ãƒªç™»éŒ²
6. èªè¨¼ãƒ†ã‚¹ãƒˆ

âœ… æˆåŠŸåŸºæº–:
- python --version ã§æ­£ã—ã„ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãŒè¡¨ç¤ºã•ã‚Œã‚‹
- ä»®æƒ³ç’°å¢ƒãŒæ­£å¸¸ã«å‹•ä½œã™ã‚‹
- Graph API ã¸ã®èªè¨¼ãŒæˆåŠŸã™ã‚‹
- VS Code ã§ã‚³ãƒ¼ãƒ‰è£œå®ŒãŒå‹•ä½œã™ã‚‹
```

```python
# ç’°å¢ƒæ§‹ç¯‰ç¢ºèªç”¨ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
# check_environment.py

import sys
import subprocess
import importlib

def check_python_version():
    """Python ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®ç¢ºèª"""
    version = sys.version_info
    print(f"Python ãƒãƒ¼ã‚¸ãƒ§ãƒ³: {version.major}.{version.minor}.{version.micro}")
    
    if version >= (3, 9):
        print("âœ… Python ãƒãƒ¼ã‚¸ãƒ§ãƒ³: OK")
        return True
    else:
        print("âŒ Python 3.9ä»¥ä¸ŠãŒå¿…è¦ã§ã™")
        return False

def check_required_packages():
    """å¿…è¦ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ç¢ºèª"""
    required_packages = [
        'msgraph-sdk',
        'azure-identity', 
        'aiohttp',
        'pandas',
        'python-dotenv',
        'loguru',
        'rich',
        'tenacity'
    ]
    
    missing_packages = []
    
    for package in required_packages:
        try:
            # ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸åã®å¤‰æ›ï¼ˆä¾‹: msgraph-sdk -> msgraphï¼‰
            import_name = package.replace('-', '_').replace('msgraph_sdk', 'msgraph')
            importlib.import_module(import_name)
            print(f"âœ… {package}: ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿")
        except ImportError:
            print(f"âŒ {package}: ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãŒå¿…è¦")
            missing_packages.append(package)
    
    return missing_packages

async def test_graph_authentication():
    """Graph API èªè¨¼ãƒ†ã‚¹ãƒˆ"""
    try:
        from auth import GraphAuthenticator
        
        auth = GraphAuthenticator()
        token = await auth.get_access_token()
        
        if token:
            print("âœ… Graph API èªè¨¼: æˆåŠŸ")
            return True
        else:
            print("âŒ Graph API èªè¨¼: å¤±æ•—")
            return False
            
    except Exception as e:
        print(f"âŒ Graph API èªè¨¼ã‚¨ãƒ©ãƒ¼: {e}")
        return False

def main():
    """ç’°å¢ƒãƒã‚§ãƒƒã‚¯ã®å®Ÿè¡Œ"""
    print("=== Python ç’°å¢ƒãƒã‚§ãƒƒã‚¯ ===\n")
    
    # Python ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãƒã‚§ãƒƒã‚¯
    if not check_python_version():
        return
    
    print("\n=== ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒã‚§ãƒƒã‚¯ ===")
    missing = check_required_packages()
    
    if missing:
        print(f"\nä»¥ä¸‹ã®ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„:")
        print(f"pip install {' '.join(missing)}")
        return
    
    print("\n=== èªè¨¼ãƒ†ã‚¹ãƒˆ ===")
    import asyncio
    success = asyncio.run(test_graph_authentication())
    
    if success:
        print("\nğŸ‰ ã™ã¹ã¦ã®ãƒã‚§ãƒƒã‚¯ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
    else:
        print("\nâš ï¸ èªè¨¼è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ï¼ˆ.envãƒ•ã‚¡ã‚¤ãƒ«ï¼‰")

if __name__ == "__main__":
    main()
```

#### Part B: åŸºæœ¬APIæ“ä½œï¼ˆ25åˆ†ï¼‰

#### åŸºæœ¬APIæ“ä½œæ¼”ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ä»¥ä¸‹ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã€Microsoft Graph API ã®åŸºæœ¬æ“ä½œã‚’æ®µéšçš„ã«å­¦ç¿’ã™ã‚‹ãŸã‚ã®å®Ÿè·µçš„æ¼”ç¿’ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã§ã™ã€‚ç†è«–å­¦ç¿’ã‹ã‚‰å®Ÿéš›ã®APIæ“ä½œã¸ã®ã‚¹ãƒ ãƒ¼ã‚ºãªç§»è¡Œã‚’æ”¯æ´ã—ã€ç¢ºå®ŸãªæŠ€è¡“ç¿’å¾—ã‚’ç›®æŒ‡ã—ã¾ã™ã€‚

**æ¼”ç¿’ã®è¨­è¨ˆæ€æƒ³:**
- **æ®µéšçš„å­¦ç¿’**: ç°¡å˜ãªæ“ä½œã‹ã‚‰è¤‡é›‘ãªå‡¦ç†ã¸é †æ¬¡ã‚¹ãƒ†ãƒƒãƒ—ã‚¢ãƒƒãƒ—
- **å®Ÿè·µé‡è¦–**: å®Ÿéš›ã®ãƒ†ãƒŠãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ãŸç¾å®Ÿçš„ãªæ¼”ç¿’
- **ã‚¨ãƒ©ãƒ¼ä½“é¨“**: æ„å›³çš„ãªã‚¨ãƒ©ãƒ¼ç™ºç”Ÿã«ã‚ˆã‚Šã€ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°èƒ½åŠ›ã‚’è‚²æˆ
- **å³åº§ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯**: å„æ“ä½œã®çµæœã‚’è¦–è¦šçš„ã«ç¢ºèª

**å„æ¼”ç¿’ã®å­¦ç¿’ç›®æ¨™:**

**æ¼”ç¿’1: ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«å–å¾—**
- Graph API ã®åŸºæœ¬çš„ãªå‘¼ã³å‡ºã—æ–¹æ³•
- JSON ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®è§£æ
- èªè¨¼ãŒæ­£ã—ãæ©Ÿèƒ½ã—ã¦ã„ã‚‹ã“ã¨ã®ç¢ºèª

**æ¼”ç¿’2: ãƒ¦ãƒ¼ã‚¶ãƒ¼ä¸€è¦§å–å¾—** 
- ãƒšãƒ¼ã‚¸ãƒ³ã‚°å‡¦ç†ã®ç†è§£
- å¤§é‡ãƒ‡ãƒ¼ã‚¿å–å¾—æ™‚ã®è€ƒæ…®äº‹é …
- ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ãƒ»ã‚½ãƒ¼ãƒˆæ©Ÿèƒ½ã®æ´»ç”¨

**æ¼”ç¿’3: ãƒ©ã‚¤ã‚»ãƒ³ã‚¹æƒ…å ±å–å¾—**
- çµ„ç¹”ãƒ¬ãƒ™ãƒ«ã®ãƒ‡ãƒ¼ã‚¿ã‚¢ã‚¯ã‚»ã‚¹
- ãƒ“ã‚¸ãƒã‚¹ãƒ‡ãƒ¼ã‚¿ã®è§£é‡ˆæ–¹æ³•
- ã‚³ã‚¹ãƒˆç®¡ç†ã®åŸºç¤çŸ¥è­˜

**æ¼”ç¿’4: ãƒ¦ãƒ¼ã‚¶ãƒ¼æ¤œç´¢**
- å‹•çš„ãªã‚¯ã‚¨ãƒªæ§‹ç¯‰
- ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã®å®‰å…¨ãªå‡¦ç†
- æ¤œç´¢çµæœã®åŠ¹æœçš„ãªè¡¨ç¤º

**å®Ÿç¿’å‰ã®æº–å‚™ç¢ºèª:**
- [ ] ç®¡ç†è€…æ¨©é™ã§ã®ãƒ†ãƒŠãƒ³ãƒˆã‚¢ã‚¯ã‚»ã‚¹
- [ ] Azure ADã‚¢ãƒ—ãƒªã®é©åˆ‡ãªæ¨©é™è¨­å®š
- [ ] ååˆ†ãªãƒ©ã‚¤ã‚»ãƒ³ã‚¹åœ¨åº«ï¼ˆæ¤œç´¢å¯¾è±¡ã¨ãªã‚‹ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å­˜åœ¨ï¼‰

```python
# basic_api_operations.py
"""åŸºæœ¬çš„ãªGraph APIæ“ä½œã®æ¼”ç¿’"""

import asyncio
from graph_client import GraphAPIClient
from loguru import logger

class BasicAPIExercise:
    """åŸºæœ¬APIæ“ä½œæ¼”ç¿’ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.client = None
    
    async def __aenter__(self):
        self.client = GraphAPIClient()
        await self.client.__aenter__()
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.client:
            await self.client.__aexit__(exc_type, exc_val, exc_tb)
    
    async def exercise_1_get_my_profile(self):
        """æ¼”ç¿’1: è‡ªåˆ†ã®ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«å–å¾—"""
        print("\n=== æ¼”ç¿’1: ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«å–å¾— ===")
        
        try:
            # ç¾åœ¨ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±ã‚’å–å¾—
            profile = await self.client._make_request('GET', 'me')
            
            print(f"âœ… è¡¨ç¤ºå: {profile.get('displayName')}")
            print(f"âœ… ãƒ¡ãƒ¼ãƒ«: {profile.get('userPrincipalName')}")
            print(f"âœ… ID: {profile.get('id')}")
            
            return profile
            
        except Exception as e:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    async def exercise_2_list_users(self):
        """æ¼”ç¿’2: ãƒ¦ãƒ¼ã‚¶ãƒ¼ä¸€è¦§å–å¾—ï¼ˆæœ€åˆã®10åï¼‰"""
        print("\n=== æ¼”ç¿’2: ãƒ¦ãƒ¼ã‚¶ãƒ¼ä¸€è¦§å–å¾— ===")
        
        try:
            # æœ€åˆã®10åã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’å–å¾—
            response = await self.client._make_request('GET', 'users?$top=10')
            users = response.get('value', [])
            
            print(f"âœ… å–å¾—ã—ãŸãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°: {len(users)}å")
            
            for i, user in enumerate(users, 1):
                print(f"  {i}. {user.get('displayName')} ({user.get('userPrincipalName')})")
            
            return users
            
        except Exception as e:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    async def exercise_3_get_subscriptions(self):
        """æ¼”ç¿’3: ã‚µãƒ–ã‚¹ã‚¯ãƒªãƒ—ã‚·ãƒ§ãƒ³ï¼ˆãƒ©ã‚¤ã‚»ãƒ³ã‚¹ï¼‰æƒ…å ±å–å¾—"""
        print("\n=== æ¼”ç¿’3: ãƒ©ã‚¤ã‚»ãƒ³ã‚¹æƒ…å ±å–å¾— ===")
        
        try:
            response = await self.client._make_request('GET', 'subscribedSkus')
            subscriptions = response.get('value', [])
            
            print(f"âœ… åˆ©ç”¨å¯èƒ½ãªãƒ©ã‚¤ã‚»ãƒ³ã‚¹ç¨®é¡: {len(subscriptions)}ç¨®é¡")
            
            for sub in subscriptions:
                sku_name = sub.get('skuPartNumber', 'Unknown')
                enabled = sub.get('prepaidUnits', {}).get('enabled', 0)
                consumed = sub.get('consumedUnits', 0)
                available = enabled - consumed
                
                print(f"  ğŸ“„ {sku_name}")
                print(f"     ç·æ•°: {enabled}, ä½¿ç”¨ä¸­: {consumed}, åˆ©ç”¨å¯èƒ½: {available}")
            
            return subscriptions
            
        except Exception as e:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    async def exercise_4_search_user(self):
        """æ¼”ç¿’4: ãƒ¦ãƒ¼ã‚¶ãƒ¼æ¤œç´¢"""
        print("\n=== æ¼”ç¿’4: ãƒ¦ãƒ¼ã‚¶ãƒ¼æ¤œç´¢ ===")
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«æ¤œç´¢å¯¾è±¡ã‚’å…¥åŠ›ã—ã¦ã‚‚ã‚‰ã†
        search_term = input("æ¤œç´¢ã™ã‚‹ãƒ¦ãƒ¼ã‚¶ãƒ¼åã®ä¸€éƒ¨ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„: ")
        
        try:
            # è¡¨ç¤ºåã§éƒ¨åˆ†æ¤œç´¢
            filter_query = f"startswith(displayName, '{search_term}')"
            response = await self.client._make_request('GET', f'users?$filter={filter_query}')
            users = response.get('value', [])
            
            if users:
                print(f"âœ… æ¤œç´¢çµæœ: {len(users)}åã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
                for user in users:
                    print(f"  ğŸ‘¤ {user.get('displayName')} ({user.get('userPrincipalName')})")
            else:
                print("âŒ è©²å½“ã™ã‚‹ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            
            return users
            
        except Exception as e:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    async def run_all_exercises(self):
        """å…¨æ¼”ç¿’ã®å®Ÿè¡Œ"""
        print("ğŸš€ Graph API åŸºæœ¬æ“ä½œæ¼”ç¿’ã‚’é–‹å§‹ã—ã¾ã™ï¼")
        
        # å„æ¼”ç¿’ã‚’é †æ¬¡å®Ÿè¡Œ
        await self.exercise_1_get_my_profile()
        await self.exercise_2_list_users()
        await self.exercise_3_get_subscriptions()
        await self.exercise_4_search_user()
        
        print("\nğŸ‰ å…¨æ¼”ç¿’ãŒå®Œäº†ã—ã¾ã—ãŸï¼")

# å®Ÿè¡Œéƒ¨åˆ†
async def main():
    async with BasicAPIExercise() as exercise:
        await exercise.run_all_exercises()

if __name__ == "__main__":
    asyncio.run(main())
```

### æ¼”ç¿’2: å°è¦æ¨¡ä¸€æ‹¬å‡¦ç†ï¼ˆ30åˆ†ï¼‰

#### 10åã®ãƒ†ã‚¹ãƒˆãƒ¦ãƒ¼ã‚¶ãƒ¼ä½œæˆ

#### å°è¦æ¨¡ä¸€æ‹¬å‡¦ç†æ¼”ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ä»¥ä¸‹ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã€10åè¦æ¨¡ã®ä¸€æ‹¬ãƒ¦ãƒ¼ã‚¶ãƒ¼ç®¡ç†ã‚’é€šã˜ã¦ã€å®Ÿéš›ã®é‹ç”¨ã§å¿…è¦ã¨ãªã‚‹åŒ…æ‹¬çš„ãªã‚¹ã‚­ãƒ«ã‚’ç¿’å¾—ã™ã‚‹ãŸã‚ã®æ¼”ç¿’ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã§ã™ã€‚å°è¦æ¨¡ãªãŒã‚‰ã€å®Ÿé‹ç”¨ã®å…¨ãƒ—ãƒ­ã‚»ã‚¹ã‚’ä½“é¨“ã§ãã‚‹è¨­è¨ˆã¨ãªã£ã¦ã„ã¾ã™ã€‚

**æ¼”ç¿’ã®å®Ÿç”¨çš„ä¾¡å€¤:**
- **å®‰å…¨ãªå­¦ç¿’ç’°å¢ƒ**: å°‘æ•°ãƒ¦ãƒ¼ã‚¶ãƒ¼ã§ã®å®Ÿé¨“ã«ã‚ˆã‚Šã€å¤§è¦æ¨¡å±•é–‹å‰ã®ã‚¹ã‚­ãƒ«ç¢ºèª
- **å®Œå…¨ãªãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«**: ä½œæˆâ†’ç¢ºèªâ†’æ›´æ–°â†’å‰Šé™¤ã®å…¨å·¥ç¨‹ã‚’ä½“é¨“
- **ã‚¨ãƒ©ãƒ¼å‡¦ç†ã®ç¿’å¾—**: æ„å›³çš„ãªå¤±æ•—ã‚·ãƒŠãƒªã‚ªã«ã‚ˆã‚‹å¯¾å¿œåŠ›è‚²æˆ
- **æœ¬ç•ªç’°å¢ƒã¸ã®æº–å‚™**: å®Ÿéš›ã®é‹ç”¨ã§é­é‡ã™ã‚‹çŠ¶æ³ã®äº‹å‰ä½“é¨“

**æ¼”ç¿’ã§ç¿’å¾—ã§ãã‚‹ã‚¹ã‚­ãƒ«:**

**1. ãƒ‡ãƒ¼ã‚¿æº–å‚™ãƒ»æ¤œè¨¼ã‚¹ã‚­ãƒ«**
- Excel/CSV ã§ã®åŠ¹ç‡çš„ãªãƒ‡ãƒ¼ã‚¿ä½œæˆ
- ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯ã®é‡è¦æ€§
- å‘½åè¦å‰‡ãƒ»ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãƒãƒªã‚·ãƒ¼ã®å®Ÿè£…

**2. ä¸€æ‹¬å‡¦ç†ã®å®Ÿè¡Œã‚¹ã‚­ãƒ«**
- éåŒæœŸå‡¦ç†ã«ã‚ˆã‚‹åŠ¹ç‡åŒ–
- ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®å®Ÿè·µ
- é€²æ—ç›£è¦–ã®æ´»ç”¨

**3. é‹ç”¨æ¤œè¨¼ã‚¹ã‚­ãƒ«**
- ä½œæˆçµæœã®ç¢ºèªæ–¹æ³•
- ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ã®æ¤œè¨¼
- å•é¡Œç™ºç”Ÿæ™‚ã®å¯¾å¿œæ‰‹é †

**4. ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¹ã‚­ãƒ«**
- ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®é©åˆ‡ãªå‰Šé™¤
- æœ¬ç•ªç’°å¢ƒã¸ã®å½±éŸ¿å›é¿
- ç›£æŸ»ãƒ­ã‚°ã®é‡è¦æ€§

**å®Ÿç¿’ã«ãŠã‘ã‚‹å®‰å…¨å¯¾ç­–:**
- ãƒ†ã‚¹ãƒˆå°‚ç”¨ãƒ‰ãƒ¡ã‚¤ãƒ³ã®ä½¿ç”¨æ¨å¥¨
- è‡ªå‹•ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—æ©Ÿèƒ½ã®æä¾›
- å‰Šé™¤å‰ã®ç¢ºèªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
- æ“ä½œãƒ­ã‚°ã®å®Œå…¨ãªè¨˜éŒ²

**æ™‚é–“é…åˆ†ã®ç›®å®‰:**
- ãƒ‡ãƒ¼ã‚¿æº–å‚™: 5åˆ†
- ä¸€æ‹¬ä½œæˆ: 10åˆ†
- æ¤œè¨¼ãƒ»æ›´æ–°: 10åˆ†  
- ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—: 5åˆ†

```python
# small_batch_exercise.py
"""å°è¦æ¨¡ä¸€æ‹¬å‡¦ç†æ¼”ç¿’"""

import asyncio
import json
from datetime import datetime
from csv_processor import CSVDataProcessor
from async_bulk_manager import AsyncBulkUserManager
from intelligent_monitor import IntelligentProgressMonitor

class SmallBatchExercise:
    """å°è¦æ¨¡ä¸€æ‹¬å‡¦ç†æ¼”ç¿’ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.processor = CSVDataProcessor()
        self.test_users = []
    
    def generate_test_users_csv(self, filename: str = "test_users_10.csv"):
        """ãƒ†ã‚¹ãƒˆãƒ¦ãƒ¼ã‚¶ãƒ¼ç”¨CSVã®ç”Ÿæˆ"""
        import pandas as pd
        
        test_data = []
        for i in range(1, 11):
            user = {
                'DisplayName': f'ãƒ†ã‚¹ãƒˆãƒ¦ãƒ¼ã‚¶ãƒ¼ {i:02d}',
                'UserPrincipalName': f'testuser{i:02d}@{input("ãƒ‰ãƒ¡ã‚¤ãƒ³åã‚’å…¥åŠ›: ")}',
                'FirstName': f'ãƒ¦ãƒ¼ã‚¶ãƒ¼{i:02d}',
                'LastName': 'ãƒ†ã‚¹ãƒˆ',
                'Password': f'TestPass{i:02d}!',
                'Department': 'æƒ…å ±ã‚·ã‚¹ãƒ†ãƒ éƒ¨' if i <= 5 else 'ãƒ†ã‚¹ãƒˆéƒ¨',
                'JobTitle': 'æ¤œè¨¼ç”¨ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ',
                'UsageLocation': 'JP',
                'ForcePasswordChange': True
            }
            test_data.append(user)
        
        df = pd.DataFrame(test_data)
        df.to_csv(filename, index=False, encoding='utf-8-sig')
        
        print(f"âœ… ãƒ†ã‚¹ãƒˆãƒ¦ãƒ¼ã‚¶ãƒ¼CSVã‚’ç”Ÿæˆã—ã¾ã—ãŸ: {filename}")
        return filename
    
    async def exercise_create_users(self, csv_filename: str):
        """æ¼”ç¿’: ãƒ¦ãƒ¼ã‚¶ãƒ¼ä¸€æ‹¬ä½œæˆ"""
        print("\n=== æ¼”ç¿’: 10åã®ä¸€æ‹¬ä½œæˆ ===")
        
        try:
            # CSVã‹ã‚‰ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
            users_data = self.processor.load_and_validate_csv(csv_filename)
            print(f"ğŸ“‹ æ¤œè¨¼å®Œäº†: {len(users_data)}åã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿")
            
            # ä¸€æ‹¬ä½œæˆã®å®Ÿè¡Œ
            async with AsyncBulkUserManager(max_concurrent_requests=5) as manager:
                result = await manager.create_users_async(users_data)
                
                # çµæœã®è¡¨ç¤º
                summary = result.get_summary()
                print("\nğŸ“Š ä½œæˆçµæœ:")
                for key, value in summary.items():
                    print(f"  {key}: {value}")
                
                # æˆåŠŸã—ãŸãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ä¿å­˜
                if result.successful_users:
                    self.test_users = result.successful_users
                    print(f"\nâœ… {len(self.test_users)}åã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ­£å¸¸ã«ä½œæˆã•ã‚Œã¾ã—ãŸ")
                
                return result
                
        except Exception as e:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    async def exercise_verify_users(self):
        """æ¼”ç¿’: ä½œæˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç¢ºèª"""
        print("\n=== æ¼”ç¿’: ä½œæˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç¢ºèª ===")
        
        if not self.test_users:
            print("âŒ ç¢ºèªã™ã‚‹ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã‚ã‚Šã¾ã›ã‚“")
            return
        
        from graph_client import GraphAPIClient
        
        async with GraphAPIClient() as client:
            verified_count = 0
            
            for user_result in self.test_users:
                try:
                    created_user = user_result['created_user']
                    user_id = created_user['id']
                    
                    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å­˜åœ¨ç¢ºèª
                    fetched_user = await client.get_user(user_id)
                    
                    print(f"âœ… {fetched_user['displayName']} - ç¢ºèªå®Œäº†")
                    verified_count += 1
                    
                except Exception as e:
                    print(f"âŒ ãƒ¦ãƒ¼ã‚¶ãƒ¼ç¢ºèªå¤±æ•—: {e}")
            
            print(f"\nğŸ“Š ç¢ºèªçµæœ: {verified_count}/{len(self.test_users)}åã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå­˜åœ¨")
    
    async def exercise_update_users(self):
        """æ¼”ç¿’: ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±ã®ä¸€æ‹¬æ›´æ–°"""
        print("\n=== æ¼”ç¿’: ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±ã®ä¸€æ‹¬æ›´æ–° ===")
        
        if not self.test_users:
            print("âŒ æ›´æ–°ã™ã‚‹ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã‚ã‚Šã¾ã›ã‚“")
            return
        
        from graph_client import GraphAPIClient
        
        async with GraphAPIClient() as client:
            update_count = 0
            
            for user_result in self.test_users:
                try:
                    created_user = user_result['created_user']
                    user_id = created_user['id']
                    
                    # éƒ¨ç½²æƒ…å ±ã‚’æ›´æ–°
                    update_data = {
                        'department': 'æ›´æ–°æ¸ˆã¿éƒ¨ç½²',
                        'jobTitle': 'ãƒ†ã‚¹ãƒˆå®Œäº†ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ'
                    }
                    
                    await client.update_user(user_id, update_data)
                    print(f"âœ… {created_user['displayName']} - æ›´æ–°å®Œäº†")
                    update_count += 1
                    
                except Exception as e:
                    print(f"âŒ ãƒ¦ãƒ¼ã‚¶ãƒ¼æ›´æ–°å¤±æ•—: {e}")
            
            print(f"\nğŸ“Š æ›´æ–°çµæœ: {update_count}/{len(self.test_users)}åã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’æ›´æ–°")
    
    async def exercise_cleanup_users(self):
        """æ¼”ç¿’: ãƒ†ã‚¹ãƒˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        print("\n=== æ¼”ç¿’: ãƒ†ã‚¹ãƒˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ— ===")
        
        if not self.test_users:
            print("âŒ ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã™ã‚‹ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã‚ã‚Šã¾ã›ã‚“")
            return
        
        from graph_client import GraphAPIClient
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ç¢ºèª
        confirm = input(f"\n{len(self.test_users)}åã®ãƒ†ã‚¹ãƒˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’å‰Šé™¤ã—ã¾ã™ã‹ï¼Ÿ (yes/no): ")
        if confirm.lower() != 'yes':
            print("ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸ")
            return
        
        async with GraphAPIClient() as client:
            deleted_count = 0
            
            for user_result in self.test_users:
                try:
                    created_user = user_result['created_user']
                    user_id = created_user['id']
                    
                    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å‰Šé™¤
                    await client.delete_user(user_id)
                    print(f"âœ… {created_user['displayName']} - å‰Šé™¤å®Œäº†")
                    deleted_count += 1
                    
                except Exception as e:
                    print(f"âŒ ãƒ¦ãƒ¼ã‚¶ãƒ¼å‰Šé™¤å¤±æ•—: {e}")
            
            print(f"\nğŸ“Š å‰Šé™¤çµæœ: {deleted_count}/{len(self.test_users)}åã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’å‰Šé™¤")
    
    async def run_small_batch_exercise(self):
        """å°è¦æ¨¡ä¸€æ‹¬å‡¦ç†æ¼”ç¿’ã®å®Ÿè¡Œ"""
        print("ğŸš€ å°è¦æ¨¡ä¸€æ‹¬å‡¦ç†æ¼”ç¿’ã‚’é–‹å§‹ã—ã¾ã™ï¼")
        
        # Step 1: ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ
        csv_file = self.generate_test_users_csv()
        
        # Step 2: ãƒ¦ãƒ¼ã‚¶ãƒ¼ä¸€æ‹¬ä½œæˆ
        result = await self.exercise_create_users(csv_file)
        
        if result and result.success_count > 0:
            # Step 3: ä½œæˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç¢ºèª
            await self.exercise_verify_users()
            
            # Step 4: ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±ã®æ›´æ–°
            await self.exercise_update_users()
            
            # Step 5: ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            cleanup = input("\nãƒ†ã‚¹ãƒˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã—ã¾ã™ã‹ï¼Ÿ (y/n): ")
            if cleanup.lower() == 'y':
                await self.exercise_cleanup_users()
        
        print("\nğŸ‰ å°è¦æ¨¡ä¸€æ‹¬å‡¦ç†æ¼”ç¿’ãŒå®Œäº†ã—ã¾ã—ãŸï¼")

# å®Ÿè¡Œéƒ¨åˆ†
async def main():
    exercise = SmallBatchExercise()
    await exercise.run_small_batch_exercise()

if __name__ == "__main__":
    asyncio.run(main())
```

### æ¼”ç¿’3: å¤§è¦æ¨¡å‡¦ç†ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆ60åˆ†ï¼‰

#### å¤§è¦æ¨¡å‡¦ç†ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ¼”ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ä»¥ä¸‹ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã€1000åè¦æ¨¡ã®å¤§è¦æ¨¡å‡¦ç†ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆã—ã€ç•°ãªã‚‹å‡¦ç†æ‰‹æ³•ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒã‚’è¡Œã†é«˜åº¦ãªæ¼”ç¿’ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã§ã™ã€‚å®Ÿéš›ã®APIå‘¼ã³å‡ºã—ã¯è¡Œã‚ãšã€å‡¦ç†æ™‚é–“ã‚’çŸ­ç¸®ã—ã¦ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆã™ã‚‹ã“ã¨ã§ã€å¤§è¦æ¨¡ç’°å¢ƒã§ã®æ€§èƒ½ç‰¹æ€§ã‚’å®‰å…¨ã«å­¦ç¿’ã§ãã¾ã™ã€‚

**ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ¼”ç¿’ã®æ„ç¾©:**
- **ãƒªã‚¹ã‚¯ãƒ•ãƒªãƒ¼å­¦ç¿’**: å®Ÿéš›ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½œæˆã‚’è¡Œã‚ãšã«å¤§è¦æ¨¡å‡¦ç†ã‚’ä½“é¨“
- **æ€§èƒ½åˆ†æã‚¹ã‚­ãƒ«**: ç•°ãªã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®å®šé‡çš„æ¯”è¼ƒæ‰‹æ³•ã‚’ç¿’å¾—
- **æœ€é©åŒ–æ€è€ƒ**: ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã®ç‰¹å®šã¨æ”¹å–„ç­–ã®æ¤œè¨èƒ½åŠ›ã‚’è‚²æˆ
- **å®¹é‡è¨ˆç”»**: æœ¬ç•ªç’°å¢ƒã§ã®å¿…è¦ãƒªã‚½ãƒ¼ã‚¹ã®äº‹å‰è¦‹ç©ã‚‚ã‚Š

**æ¯”è¼ƒå¯¾è±¡ã®å‡¦ç†æ‰‹æ³•:**

**1. é€æ¬¡å‡¦ç†ï¼ˆãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ï¼‰**
- ä¼çµ±çš„ãª1ä»¶ãšã¤ã®é †æ¬¡å‡¦ç†
- ç†è§£ã—ã‚„ã™ã„ãŒå‡¦ç†æ™‚é–“ãŒé•·ã„
- å°è¦æ¨¡ç’°å¢ƒã‚„ç¢ºå®Ÿæ€§é‡è¦–ã®å ´åˆã«é©ç”¨

**2. éåŒæœŸå‡¦ç†ï¼ˆ5-30ä¸¦åˆ—ï¼‰**
- Python asyncio ã«ã‚ˆã‚‹ä¸¦åˆ—å‡¦ç†
- ä¸¦åˆ—æ•°ã«ã‚ˆã‚‹æ€§èƒ½å¤‰åŒ–ã®è¦³æ¸¬
- å®Ÿç”¨çš„ãªé«˜é€ŸåŒ–ã®å®Ÿç¾

**å­¦ç¿’ã§ãã‚‹é‡è¦æ¦‚å¿µ:**

**æ€§èƒ½æ¸¬å®šã®åŸºç¤:**
- ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆï¼ˆä»¶/ç§’ï¼‰ã®è¨ˆç®—
- ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“ã®æ¸¬å®š
- ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨åŠ¹ç‡ã®è©•ä¾¡

**ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£åˆ†æ:**
- ä¸¦åˆ—æ•°å¢—åŠ ã«ã‚ˆã‚‹æ€§èƒ½å‘ä¸Šã®é™ç•Œ
- ãƒªã‚½ãƒ¼ã‚¹ç«¶åˆã«ã‚ˆã‚‹ãƒœãƒˆãƒ«ãƒãƒƒã‚¯
- æœ€é©ãªä¸¦åˆ—æ•°ã®æ±ºå®šæ–¹æ³•

**å®Ÿé‹ç”¨ã¸ã®å¿œç”¨:**
- å‡¦ç†æ™‚é–“ã®äºˆæ¸¬æ‰‹æ³•
- å¿…è¦ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã‚¹ãƒšãƒƒã‚¯ã®ç®—å‡º
- é‹ç”¨ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ç­–å®š

**ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç²¾åº¦ã®è€ƒæ…®:**
- å®Ÿéš›ã®APIå‡¦ç†æ™‚é–“: 0.5-1.5ç§’/ä»¶
- ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ™‚é–“: 0.05-0.15ç§’/ä»¶ï¼ˆ1/10ã«çŸ­ç¸®ï¼‰
- ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯é…å»¶ãƒ»ã‚µãƒ¼ãƒãƒ¼è² è·ã¯ç°¡ç•¥åŒ–

**æ¼”ç¿’å¾Œã®ç™ºå±•å­¦ç¿’:**
- å®Ÿç’°å¢ƒã§ã®å°è¦æ¨¡ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
- ç›£è¦–ãƒ„ãƒ¼ãƒ«ã«ã‚ˆã‚‹è©³ç´°ãªæ€§èƒ½åˆ†æ
- ä»–ã®é«˜é€ŸåŒ–æ‰‹æ³•ï¼ˆãƒãƒƒãƒAPIç­‰ï¼‰ã®æ¤œè¨

```python
# large_scale_simulation.py
"""å¤§è¦æ¨¡å‡¦ç†ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ¼”ç¿’"""

import asyncio
import random
import time
from datetime import datetime, timedelta
from typing import List, Dict, Any
import pandas as pd
from loguru import logger

class LargeScaleSimulation:
    """å¤§è¦æ¨¡å‡¦ç†ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, target_count: int = 1000):
        self.target_count = target_count
        self.departments = ['æƒ…å ±å­¦éƒ¨', 'å·¥å­¦éƒ¨', 'æ–‡å­¦éƒ¨', 'æ³•å­¦éƒ¨', 'çµŒæ¸ˆå­¦éƒ¨', 'åŒ»å­¦éƒ¨']
        self.job_titles = ['å­¦ç”Ÿ', 'å¤§å­¦é™¢ç”Ÿ', 'ç ”ç©¶å“¡', 'åŠ©æ•™', 'å‡†æ•™æˆ', 'æ•™æˆ']
        
    def generate_large_dataset(self, filename: str = None) -> str:
        """å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ç”Ÿæˆ"""
        print(f"ğŸ“Š {self.target_count}åã®å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç”Ÿæˆä¸­...")
        
        users_data = []
        start_time = time.time()
        
        for i in range(1, self.target_count + 1):
            # ãƒ©ãƒ³ãƒ€ãƒ ãªéƒ¨ç½²ãƒ»è·ç¨®ã®é¸æŠ
            dept = random.choice(self.departments)
            job = random.choice(self.job_titles)
            
            user = {
                'DisplayName': f'{dept[:-2]} {job} {i:04d}',
                'UserPrincipalName': f'user{i:04d}@university-sim.edu.jp',
                'FirstName': f'ãƒ¦ãƒ¼ã‚¶ãƒ¼{i:04d}',
                'LastName': f'{dept[:-2]}',
                'Password': f'SimPass{i:04d}!',
                'Department': dept,
                'JobTitle': job,
                'OfficeLocation': f'{random.randint(1,10)}å·é¤¨{random.randint(100,999)}å®¤',
                'PhoneNumber': f'03-{random.randint(1000,9999)}-{random.randint(1000,9999)}',
                'UsageLocation': 'JP',
                'ForcePasswordChange': True
            }
            users_data.append(user)
            
            # é€²æ—è¡¨ç¤º
            if i % 100 == 0:
                elapsed = time.time() - start_time
                rate = i / elapsed
                eta = (self.target_count - i) / rate
                print(f"  ç”Ÿæˆé€²æ—: {i}/{self.target_count} ({rate:.0f}ä»¶/ç§’, æ®‹ã‚Šç´„{eta:.0f}ç§’)")
        
        # CSVãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
        if not filename:
            filename = f"simulation_users_{self.target_count}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
        
        df = pd.DataFrame(users_data)
        df.to_csv(filename, index=False, encoding='utf-8-sig')
        
        generation_time = time.time() - start_time
        print(f"âœ… ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç”Ÿæˆå®Œäº†: {filename}")
        print(f"   ç”Ÿæˆæ™‚é–“: {generation_time:.1f}ç§’")
        print(f"   ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {len(df) * len(df.columns) * 50 / 1024:.0f}KB (æ¦‚ç®—)")
        
        return filename
    
    async def performance_test_sequential(self, users_data: List[Dict[str, Any]]) -> Dict[str, Any]:
        """é€æ¬¡å‡¦ç†ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰"""
        print("\n=== é€æ¬¡å‡¦ç†ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ ===")
        
        start_time = time.time()
        processed = 0
        
        # é€æ¬¡å‡¦ç†ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆï¼ˆå®Ÿéš›ã®APIå‘¼ã³å‡ºã—ã¯è¡Œã‚ãªã„ï¼‰
        for i, user in enumerate(users_data):
            # å®Ÿéš›ã®APIå‡¦ç†æ™‚é–“ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆï¼ˆ0.5-1.5ç§’ï¼‰
            await asyncio.sleep(random.uniform(0.05, 0.15))  # å®Ÿéš›ã®1/10ã®æ™‚é–“ã§ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
            
            processed += 1
            
            # å®šæœŸçš„ãªé€²æ—è¡¨ç¤º
            if processed % 50 == 0:
                elapsed = time.time() - start_time
                rate = processed / elapsed
                eta = (len(users_data) - processed) / rate
                print(f"  é€æ¬¡å‡¦ç†é€²æ—: {processed}/{len(users_data)} "
                      f"({rate:.1f}ä»¶/ç§’, æ®‹ã‚Šç´„{eta:.0f}ç§’)")
        
        total_time = time.time() - start_time
        
        result = {
            'method': 'é€æ¬¡å‡¦ç†',
            'total_count': len(users_data),
            'processing_time': total_time,
            'rate': len(users_data) / total_time,
            'estimated_real_time': total_time * 10  # å®Ÿéš›ã®å‡¦ç†æ™‚é–“ã‚’æ¨å®š
        }
        
        return result
    
    async def performance_test_async(self, users_data: List[Dict[str, Any]], concurrency: int = 20) -> Dict[str, Any]:
        """éåŒæœŸå‡¦ç†ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰"""
        print(f"\n=== éåŒæœŸå‡¦ç†ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆä¸¦åˆ—æ•°: {concurrency}ï¼‰ ===")
        
        start_time = time.time()
        semaphore = asyncio.Semaphore(concurrency)
        
        async def process_user_async(user_data: Dict[str, Any]) -> Dict[str, Any]:
            """å˜ä¸€ãƒ¦ãƒ¼ã‚¶ãƒ¼å‡¦ç†ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ"""
            async with semaphore:
                # APIå‡¦ç†æ™‚é–“ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
                await asyncio.sleep(random.uniform(0.05, 0.15))
                
                # 95%ã®æˆåŠŸç‡ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
                if random.random() < 0.95:
                    return {'status': 'success', 'user': user_data}
                else:
                    return {'status': 'failed', 'user': user_data, 'error': 'Simulated error'}
        
        # é€²æ—ç›£è¦–ç”¨
        completed = 0
        total = len(users_data)
        
        async def progress_monitor():
            """é€²æ—ç›£è¦–"""
            while completed < total:
                await asyncio.sleep(2)
                if completed < total:
                    elapsed = time.time() - start_time
                    rate = completed / elapsed if elapsed > 0 else 0
                    eta = (total - completed) / rate if rate > 0 else 0
                    print(f"  éåŒæœŸå‡¦ç†é€²æ—: {completed}/{total} "
                          f"({rate:.1f}ä»¶/ç§’, æ®‹ã‚Šç´„{eta:.0f}ç§’)")
        
        # é€²æ—ç›£è¦–é–‹å§‹
        monitor_task = asyncio.create_task(progress_monitor())
        
        # å…¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®éåŒæœŸå‡¦ç†
        tasks = [process_user_async(user) for user in users_data]
        results = await asyncio.gather(*tasks)
        
        # é€²æ—ç›£è¦–åœæ­¢
        monitor_task.cancel()
        completed = total
        
        total_time = time.time() - start_time
        
        # çµæœã®é›†è¨ˆ
        success_count = sum(1 for r in results if r['status'] == 'success')
        failed_count = len(results) - success_count
        
        result = {
            'method': f'éåŒæœŸå‡¦ç†ï¼ˆ{concurrency}ä¸¦åˆ—ï¼‰',
            'total_count': len(users_data),
            'success_count': success_count,
            'failed_count': failed_count,
            'processing_time': total_time,
            'rate': len(users_data) / total_time,
            'estimated_real_time': total_time * 10,
            'concurrency': concurrency
        }
        
        return result
    
    async def run_performance_comparison(self, sample_size: int = 200):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒã®å®Ÿè¡Œ"""
        print("ğŸš€ å¤§è¦æ¨¡å‡¦ç†ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒã‚’é–‹å§‹ã—ã¾ã™ï¼")
        print(f"ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚º: {sample_size}åï¼ˆæ™‚é–“çŸ­ç¸®ã®ãŸã‚ï¼‰")
        
        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ
        print("\nğŸ“Š ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆä¸­...")
        self.target_count = sample_size
        csv_file = self.generate_large_dataset()
        
        # CSVãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
        from csv_processor import CSVDataProcessor
        processor = CSVDataProcessor()
        users_data = processor.load_and_validate_csv(csv_file)
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ
        results = []
        
        # 1. é€æ¬¡å‡¦ç†ãƒ†ã‚¹ãƒˆ
        sequential_result = await self.performance_test_sequential(users_data[:50])  # æ™‚é–“çŸ­ç¸®ã®ãŸã‚50åã®ã¿
        results.append(sequential_result)
        
        # 2. éåŒæœŸå‡¦ç†ãƒ†ã‚¹ãƒˆï¼ˆç•°ãªã‚‹ä¸¦åˆ—æ•°ï¼‰
        concurrency_levels = [5, 10, 20, 30]
        
        for concurrency in concurrency_levels:
            async_result = await self.performance_test_async(users_data, concurrency)
            results.append(async_result)
        
        # çµæœã®æ¯”è¼ƒè¡¨ç¤º
        self.display_performance_results(results)
        
        return results
    
    def display_performance_results(self, results: List[Dict[str, Any]]):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµæœã®è¡¨ç¤º"""
        print("\n" + "="*80)
        print("ğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒçµæœ")
        print("="*80)
        
        # çµæœãƒ†ãƒ¼ãƒ–ãƒ«ã®ä½œæˆ
        from rich.console import Console
        from rich.table import Table
        
        console = Console()
        table = Table(show_header=True, header_style="bold magenta")
        
        table.add_column("å‡¦ç†æ–¹å¼", style="dim", width=20)
        table.add_column("å‡¦ç†ä»¶æ•°", justify="right")
        table.add_column("å‡¦ç†æ™‚é–“", justify="right")
        table.add_column("å‡¦ç†é€Ÿåº¦", justify="right")
        table.add_column("æ¨å®šå®Ÿæ™‚é–“", justify="right")
        table.add_column("ç›¸å¯¾æ€§èƒ½", justify="right")
        
        baseline_rate = results[0]['rate']  # é€æ¬¡å‡¦ç†ã‚’åŸºæº–ã¨ã™ã‚‹
        
        for result in results:
            relative_performance = result['rate'] / baseline_rate
            
            table.add_row(
                result['method'],
                str(result['total_count']),
                f"{result['processing_time']:.1f}ç§’",
                f"{result['rate']:.1f}ä»¶/ç§’",
                f"{result['estimated_real_time']:.0f}ç§’",
                f"{relative_performance:.1f}x"
            )
        
        console.print(table)
        
        # æ¨å¥¨è¨­å®šã®è¡¨ç¤º
        best_result = max(results[1:], key=lambda x: x['rate'])  # éåŒæœŸå‡¦ç†ã®ä¸­ã§æœ€é«˜æ€§èƒ½
        
        print(f"\nğŸ¯ æ¨å¥¨è¨­å®š:")
        print(f"   æ–¹å¼: {best_result['method']}")
        print(f"   ç†ç”±: é€æ¬¡å‡¦ç†æ¯” {best_result['rate']/baseline_rate:.1f}å€ã®æ€§èƒ½")
        
        if 'concurrency' in best_result:
            print(f"   ä¸¦åˆ—æ•°: {best_result['concurrency']} ãŒæœ€é©")

# å®Ÿè¡Œéƒ¨åˆ†
async def main():
    """å¤§è¦æ¨¡ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®å®Ÿè¡Œ"""
    simulation = LargeScaleSimulation()
    
    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒã®å®Ÿè¡Œ
    await simulation.run_performance_comparison(sample_size=200)
    
    print("\nğŸ‰ å¤§è¦æ¨¡å‡¦ç†ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
    print("\nğŸ’¡ å®Ÿéš›ã®é‹ç”¨ã§ã¯:")
    print("   - æœ¬ç•ªç’°å¢ƒã§ã®äº‹å‰ãƒ†ã‚¹ãƒˆã‚’å®Ÿæ–½")
    print("   - ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å¸¯åŸŸãƒ»APIåˆ¶é™ã‚’è€ƒæ…®")
    print("   - æ®µéšçš„ãªå±•é–‹ï¼ˆãƒãƒƒãƒå‡¦ç†ï¼‰ã‚’æ¨å¥¨")
    print("   - ç›£è¦–ãƒ»ã‚¢ãƒ©ãƒ¼ãƒˆæ©Ÿèƒ½ã®æ´»ç”¨")

if __name__ == "__main__":
    asyncio.run(main())
```

---

## ğŸ› ï¸ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### ã‚ˆãã‚ã‚‹å•é¡Œã¨è§£æ±ºæ–¹æ³•

#### å•é¡Œ1: Pythonç’°å¢ƒé–¢é€£ã®ã‚¨ãƒ©ãƒ¼

**ç—‡çŠ¶**: `ModuleNotFoundError: No module named 'msgraph'`

**åŸå› **: ä»®æƒ³ç’°å¢ƒãŒæ­£ã—ãæœ‰åŠ¹åŒ–ã•ã‚Œã¦ã„ãªã„ã€ã¾ãŸã¯å¿…è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ãªã„

**è§£æ±ºæ–¹æ³•**:

```cmd
# ä»®æƒ³ç’°å¢ƒã®çŠ¶æ…‹ç¢ºèª
where python
# æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›: C:\M365_Management\m365_env\Scripts\python.exe

# ä»®æƒ³ç’°å¢ƒãŒæœ‰åŠ¹åŒ–ã•ã‚Œã¦ã„ãªã„å ´åˆ
m365_env\Scripts\activate

# ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®å†ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install --upgrade pip
pip install -r requirements.txt

# ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ç¢ºèª
pip list | findstr msgraph
```

#### å•é¡Œ2: èªè¨¼ã‚¨ãƒ©ãƒ¼

**ç—‡çŠ¶**: `ClientAuthenticationError: Invalid client secret`

**è¨ºæ–­ãƒ»è§£æ±ºã‚¹ã‚¯ãƒªãƒ—ãƒˆ**:

#### èªè¨¼å•é¡Œè¨ºæ–­ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ä»¥ä¸‹ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã€Microsoft Graph API èªè¨¼ã«é–¢ã™ã‚‹å•é¡Œã‚’ä½“ç³»çš„ã«è¨ºæ–­ã—ã€å…·ä½“çš„ãªè§£æ±ºç­–ã‚’æç¤ºã™ã‚‹å°‚é–€çš„ãªãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ãƒ„ãƒ¼ãƒ«ã§ã™ã€‚èªè¨¼å•é¡Œã¯åˆå¿ƒè€…ãŒæœ€ã‚‚é »ç¹ã«é­é‡ã™ã‚‹éšœå£ã§ã‚ã‚Šã€ã“ã®ãƒ„ãƒ¼ãƒ«ã«ã‚ˆã‚Šè¿…é€Ÿãªå•é¡Œè§£æ±ºãŒå¯èƒ½ã«ãªã‚Šã¾ã™ã€‚

**èªè¨¼å•é¡Œã®è¤‡é›‘æ€§:**
- **å¤šå±¤çš„ãªè¨­å®š**: Azure ADã€ã‚¢ãƒ—ãƒªç™»éŒ²ã€æ¨©é™ã€ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆç­‰ã®è¤‡æ•°è¨­å®šãŒé–¢é€£
- **ã‚¿ã‚¤ãƒŸãƒ³ã‚°è¦å› **: ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆæœ‰åŠ¹æœŸé™ã€ãƒˆãƒ¼ã‚¯ãƒ³ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç­‰ã®æ™‚é–“çš„è¦ç´ 
- **æ¨©é™ã®è¤‡é›‘æ€§**: ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³æ¨©é™ã¨å§”ä»»æ¨©é™ã®ç†è§£ãŒå¿…è¦
- **ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®æ›–æ˜§æ€§**: æ ¹æœ¬åŸå› ã¨è¡¨é¢çš„ç—‡çŠ¶ã®ä¹–é›¢

**è¨ºæ–­ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®è§£æ±ºã‚¢ãƒ—ãƒ­ãƒ¼ãƒ:**

**1. æ®µéšçš„è¨ºæ–­**
- ç’°å¢ƒå¤‰æ•° â†’ èªè¨¼æƒ…å ± â†’ æ¨©é™ â†’ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ ã®é †ã§å•é¡Œã‚’ç‰¹å®š
- å„æ®µéšã§ã®è©³ç´°ãªãƒã‚§ãƒƒã‚¯ã¨æ˜ç¢ºãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯

**2. æ ¹æœ¬åŸå› åˆ†æ**
- ç—‡çŠ¶ã‹ã‚‰é€†ç®—ã—ãŸåŸå› ç‰¹å®š
- ä¸€èˆ¬çš„ãªè¨­å®šãƒŸã‚¹ãƒ‘ã‚¿ãƒ¼ãƒ³ã®è‡ªå‹•æ¤œå‡º

**3. å®Ÿè·µçš„è§£æ±ºç­–**
- å…·ä½“çš„ãªè¨­å®šæ‰‹é †ã®æç¤º
- Azure Portal ã§ã®ç¢ºèªç®‡æ‰€ã®æ˜ç¤º

**ã‚ˆãã‚ã‚‹èªè¨¼ã‚¨ãƒ©ãƒ¼ã¨å¯¾å¿œ:**

**`AADSTS70011: Invalid client secret`**
- åŸå› : ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã®æœ‰åŠ¹æœŸé™åˆ‡ã‚Œã¾ãŸã¯å…¥åŠ›ãƒŸã‚¹
- å¯¾ç­–: æ–°ã—ã„ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã®ç”Ÿæˆã¨æ›´æ–°

**`AADSTS650057: Invalid resource`**
- åŸå› : ã‚¹ã‚³ãƒ¼ãƒ—è¨­å®šã®èª¤ã‚Š
- å¯¾ç­–: `https://graph.microsoft.com/.default` ã®ç¢ºèª

**`AADSTS50020: User account is not found`**
- åŸå› : ãƒ†ãƒŠãƒ³ãƒˆIDã®èª¤ã‚Š
- å¯¾ç­–: Azure AD ãƒ†ãƒŠãƒ³ãƒˆæ¦‚è¦ã§ã®æ­£ç¢ºãªIDç¢ºèª

**ä½¿ç”¨ã‚¿ã‚¤ãƒŸãƒ³ã‚°:**
- åˆå›ç’°å¢ƒæ§‹ç¯‰æ™‚ã®å‹•ä½œç¢ºèª
- èªè¨¼ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚ã®ç¬¬ä¸€æ¬¡è¨ºæ–­
- å®šæœŸçš„ãªè¨­å®šçŠ¶æ³ã®å¥å…¨æ€§ãƒã‚§ãƒƒã‚¯

```python
# auth_troubleshoot.py
"""èªè¨¼å•é¡Œã®è¨ºæ–­ãƒ»è§£æ±ºã‚¹ã‚¯ãƒªãƒ—ãƒˆ"""

import os
from dotenv import load_dotenv
from azure.identity import ClientSecretCredential
from azure.core.exceptions import ClientAuthenticationError
import asyncio

class AuthTroubleshooter:
    """èªè¨¼å•é¡Œè¨ºæ–­ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        load_dotenv()
        self.tenant_id = os.getenv('TENANT_ID')
        self.client_id = os.getenv('CLIENT_ID')
        self.client_secret = os.getenv('CLIENT_SECRET')
    
    def check_environment_variables(self):
        """ç’°å¢ƒå¤‰æ•°ã®ç¢ºèª"""
        print("=== ç’°å¢ƒå¤‰æ•°ãƒã‚§ãƒƒã‚¯ ===")
        
        issues = []
        
        if not self.tenant_id:
            issues.append("TENANT_ID ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        else:
            print(f"âœ… TENANT_ID: {self.tenant_id[:8]}...")
        
        if not self.client_id:
            issues.append("CLIENT_ID ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        else:
            print(f"âœ… CLIENT_ID: {self.client_id[:8]}...")
        
        if not self.client_secret:
            issues.append("CLIENT_SECRET ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        else:
            print(f"âœ… CLIENT_SECRET: {'*' * len(self.client_secret)}")
        
        if issues:
            print("\nâŒ ä»¥ä¸‹ã®å•é¡ŒãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ:")
            for issue in issues:
                print(f"   - {issue}")
            return False
        
        return True
    
    async def test_authentication(self):
        """èªè¨¼ãƒ†ã‚¹ãƒˆ"""
        print("\n=== èªè¨¼ãƒ†ã‚¹ãƒˆ ===")
        
        if not self.check_environment_variables():
            return False
        
        try:
            credential = ClientSecretCredential(
                tenant_id=self.tenant_id,
                client_id=self.client_id,
                client_secret=self.client_secret
            )
            
            # ãƒˆãƒ¼ã‚¯ãƒ³ã®å–å¾—ãƒ†ã‚¹ãƒˆ
            token = credential.get_token("https://graph.microsoft.com/.default")
            
            if token:
                print("âœ… èªè¨¼æˆåŠŸ")
                print(f"   ãƒˆãƒ¼ã‚¯ãƒ³ã‚¿ã‚¤ãƒ—: Bearer")
                print(f"   æœ‰åŠ¹æœŸé™: {token.expires_on}")
                return True
            else:
                print("âŒ ãƒˆãƒ¼ã‚¯ãƒ³å–å¾—å¤±æ•—")
                return False
                
        except ClientAuthenticationError as e:
            print(f"âŒ èªè¨¼ã‚¨ãƒ©ãƒ¼: {e}")
            print("\nğŸ”§ è§£æ±ºæ–¹æ³•:")
            print("   1. Azure ADã‚¢ãƒ—ãƒªã®è¨­å®šç¢ºèª")
            print("   2. ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã®æœ‰åŠ¹æœŸé™ç¢ºèª")
            print("   3. ãƒ†ãƒŠãƒ³ãƒˆIDã®æ­£ç¢ºæ€§ç¢ºèª")
            return False
        
        except Exception as e:
            print(f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def check_azure_app_configuration(self):
        """Azure ADã‚¢ãƒ—ãƒªè¨­å®šã®ç¢ºèªã‚¬ã‚¤ãƒ‰"""
        print("\n=== Azure ADã‚¢ãƒ—ãƒªè¨­å®šç¢ºèªã‚¬ã‚¤ãƒ‰ ===")
        print("ä»¥ä¸‹ã®è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„:")
        print("\n1. ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ç™»éŒ²:")
        print("   - https://portal.azure.com â†’ Azure Active Directory â†’ ã‚¢ãƒ—ãƒªã®ç™»éŒ²")
        print(f"   - ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ (ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ) ID: {self.client_id}")
        
        print("\n2. å¿…è¦ãªæ¨©é™:")
        print("   - User.ReadWrite.All")
        print("   - Group.ReadWrite.All") 
        print("   - Directory.ReadWrite.All")
        print("   - ç®¡ç†è€…ã®åŒæ„ãŒä»˜ä¸ã•ã‚Œã¦ã„ã‚‹ã“ã¨")
        
        print("\n3. ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆ:")
        print("   - ã€Œè¨¼æ˜æ›¸ã¨ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã€ã§æœ‰åŠ¹ãªã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆãŒå­˜åœ¨")
        print("   - æœ‰åŠ¹æœŸé™ãŒåˆ‡ã‚Œã¦ã„ãªã„ã“ã¨")
        
        print("\n4. ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆURI:")
        print("   - ç¨®é¡: ãƒ‘ãƒ–ãƒªãƒƒã‚¯ ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ")
        print("   - URI: http://localhost")

# å®Ÿè¡Œéƒ¨åˆ†
async def main():
    troubleshooter = AuthTroubleshooter()
    
    success = await troubleshooter.test_authentication()
    
    if not success:
        troubleshooter.check_azure_app_configuration()

if __name__ == "__main__":
    asyncio.run(main())
```

#### å•é¡Œ3: API ãƒ¬ãƒ¼ãƒˆåˆ¶é™

**ç—‡çŠ¶**: `HTTP 429 Too Many Requests`

**å¯¾ç­–ã¨å›é¿æ–¹æ³•**:

#### é«˜åº¦ãªãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾å¿œã‚·ã‚¹ãƒ†ãƒ 

ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã¯ã€Microsoft Graph API ã®ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚’äºˆé˜²çš„ã«å›é¿ã—ã€åˆ¶é™ã«é­é‡ã—ãŸå ´åˆã®é©åˆ‡ãªå›å¾©å‡¦ç†ã‚’å®Ÿè£…ã™ã‚‹é«˜åº¦ãªã‚·ã‚¹ãƒ†ãƒ ã§ã™ã€‚å¤§è¦æ¨¡ãªä¸€æ‹¬å‡¦ç†ã«ãŠã„ã¦ã€ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã¯é¿ã‘ã‚‰ã‚Œãªã„èª²é¡Œã§ã‚ã‚Šã€ã“ã®ã‚·ã‚¹ãƒ†ãƒ ã«ã‚ˆã‚Šå®‰å®šã—ãŸå‡¦ç†ç¶™ç¶šãŒå¯èƒ½ã«ãªã‚Šã¾ã™ã€‚

**Microsoft Graph ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã®ç‰¹å¾´:**
- **å‹•çš„åˆ¶é™**: ã‚µãƒ¼ãƒãƒ¼è² è·ã«å¿œã˜ã¦ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§å¤‰å‹•
- **ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆåˆ¥åˆ¶é™**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½œæˆã€æ›´æ–°ã€å‰Šé™¤ã§ç•°ãªã‚‹åˆ¶é™å€¤
- **ãƒ†ãƒŠãƒ³ãƒˆå…±æœ‰**: åŒä¸€ãƒ†ãƒŠãƒ³ãƒˆå†…ã®ä»–ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å½±éŸ¿ã‚’å—ã‘ã‚‹
- **å¾©æ—§æ™‚é–“ã®å¤‰å‹•**: æ•°ç§’ã‹ã‚‰æ•°åˆ†ã¾ã§å¹…åºƒã„ç¯„å›²

**å¾“æ¥ã®å˜ç´”å†è©¦è¡Œã¨ã®é•ã„:**

**å¾“æ¥ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®å•é¡Œç‚¹:**
```python
# âŒ å˜ç´”ãªå†è©¦è¡Œï¼ˆéæ¨å¥¨ï¼‰
for i in range(3):
    try:
        return api_call()
    except RateLimitError:
        time.sleep(60)  # å›ºå®šå¾…æ©Ÿ
```

**é«˜åº¦ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®åˆ©ç‚¹:**
```python
# âœ… ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆãªåˆ¶é™å¯¾å¿œ
- äºˆé˜²çš„é…å»¶ã«ã‚ˆã‚‹åˆ¶é™å›é¿
- æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ• + ã‚¸ãƒƒã‚¿ãƒ¼
- ãƒªã‚¯ã‚¨ã‚¹ãƒˆå±¥æ­´ã«ã‚ˆã‚‹å­¦ç¿’æ©Ÿèƒ½
- æœ€å¤§å¾…æ©Ÿæ™‚é–“ã®åˆ¶é™
```

**å®Ÿè£…ã•ã‚ŒãŸé«˜åº¦ãªæ©Ÿèƒ½:**

**1. äºˆé˜²çš„ãƒ¬ãƒ¼ãƒˆåˆ¶é™å›é¿**
- éå»1åˆ†é–“ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°ã‚’ç›£è¦–
- åˆ¶é™è¿‘æ¥æ™‚ã®è‡ªå‹•é…å»¶æŒ¿å…¥
- APIåˆ¶é™ã®äº‹å‰äºˆæ¸¬

**2. ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆãªãƒãƒƒã‚¯ã‚ªãƒ•**
- æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•ï¼ˆ2^retry_countï¼‰
- ãƒ©ãƒ³ãƒ€ãƒ ã‚¸ãƒƒã‚¿ãƒ¼ã«ã‚ˆã‚‹åŒæ™‚ã‚¢ã‚¯ã‚»ã‚¹åˆ†æ•£
- æœ€å¤§å¾…æ©Ÿæ™‚é–“ï¼ˆ5åˆ†ï¼‰ã«ã‚ˆã‚‹ç„¡é™å¾…æ©Ÿé˜²æ­¢

**3. ãƒªã‚¯ã‚¨ã‚¹ãƒˆå±¥æ­´ã®æ´»ç”¨**
- æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³ã®å­¦ç¿’
- åˆ¶é™ç™ºç”Ÿãƒ‘ã‚¿ãƒ¼ãƒ³ã®åˆ†æ
- å‹•çš„ãªå®Ÿè¡Œé–“éš”èª¿æ•´

**å®Ÿç”¨çš„ãªä½¿ç”¨ä¾‹:**
```python
# å¤§é‡å‡¦ç†ã§ã®é©ç”¨ä¾‹
handler = AdvancedRateLimitHandler()

for user_data in large_user_list:
    result = await handler.execute_with_rate_limit_handling(
        create_user_function,
        user_data,
        max_retries=5
    )
```

**ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¸ã®å½±éŸ¿:**
- äºˆé˜²çš„é…å»¶: ç´„5-10%ã®å‡¦ç†æ™‚é–“å¢—åŠ 
- åˆ¶é™å›é¿åŠ¹æœ: 90%ä»¥ä¸Šã®åˆ¶é™ã‚¨ãƒ©ãƒ¼å‰Šæ¸›
- å…¨ä½“åŠ¹ç‡: å†å‡¦ç†å›é¿ã«ã‚ˆã‚Šå®Ÿè³ªçš„ãªé«˜é€ŸåŒ–

```python
# rate_limit_handler.py
"""ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾å¿œã®é«˜åº¦ãªãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°"""

import asyncio
import time
from typing import Callable, Any
import aiohttp
from loguru import logger

class AdvancedRateLimitHandler:
    """é«˜åº¦ãªãƒ¬ãƒ¼ãƒˆåˆ¶é™ãƒãƒ³ãƒ‰ãƒ©ãƒ¼"""
    
    def __init__(self):
        self.request_history = []
        self.backoff_multiplier = 2
        self.max_backoff_time = 300  # æœ€å¤§5åˆ†
        self.rate_limit_buffer = 0.1  # 10%ã®ãƒãƒƒãƒ•ã‚¡
    
    async def execute_with_rate_limit_handling(
        self, 
        func: Callable, 
        *args, 
        max_retries: int = 5,
        **kwargs
    ) -> Any:
        """ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚’è€ƒæ…®ã—ãŸé–¢æ•°å®Ÿè¡Œ"""
        
        for attempt in range(max_retries):
            try:
                # ãƒªã‚¯ã‚¨ã‚¹ãƒˆå‰ã®å¾…æ©Ÿï¼ˆäºˆé˜²çš„ï¼‰
                await self._preventive_delay()
                
                # é–¢æ•°ã®å®Ÿè¡Œ
                result = await func(*args, **kwargs)
                
                # æˆåŠŸæ™‚ã¯ãƒªã‚¯ã‚¨ã‚¹ãƒˆå±¥æ­´ã‚’è¨˜éŒ²
                self.request_history.append(time.time())
                self._cleanup_request_history()
                
                return result
                
            except aiohttp.ClientError as e:
                if "429" in str(e) or "Too Many Requests" in str(e):
                    # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚¨ãƒ©ãƒ¼ã®å‡¦ç†
                    wait_time = await self._calculate_backoff_time(attempt)
                    
                    logger.warning(f"ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã«é”ã—ã¾ã—ãŸã€‚{wait_time}ç§’å¾…æ©Ÿä¸­... (è©¦è¡Œ {attempt + 1}/{max_retries})")
                    await asyncio.sleep(wait_time)
                    
                    if attempt == max_retries - 1:
                        logger.error("æœ€å¤§å†è©¦è¡Œå›æ•°ã«é”ã—ã¾ã—ãŸ")
                        raise
                else:
                    # ãã®ä»–ã®ã‚¨ãƒ©ãƒ¼ã¯ãã®ã¾ã¾å†ç™ºç”Ÿ
                    raise
    
    async def _preventive_delay(self):
        """äºˆé˜²çš„ãªé…å»¶"""
        if len(self.request_history) >= 50:  # ç›´è¿‘50ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ãƒã‚§ãƒƒã‚¯
            recent_requests = [t for t in self.request_history if time.time() - t < 60]
            
            if len(recent_requests) >= 40:  # 1åˆ†é–“ã«40ãƒªã‚¯ã‚¨ã‚¹ãƒˆä»¥ä¸Š
                delay = 1.5  # 1.5ç§’ã®äºˆé˜²çš„å¾…æ©Ÿ
                logger.info(f"äºˆé˜²çš„é…å»¶: {delay}ç§’")
                await asyncio.sleep(delay)
    
    async def _calculate_backoff_time(self, attempt: int) -> float:
        """ãƒãƒƒã‚¯ã‚ªãƒ•æ™‚é–“ã®è¨ˆç®—"""
        base_delay = min(2 ** attempt, self.max_backoff_time)
        
        # ã‚¸ãƒƒã‚¿ãƒ¼è¿½åŠ ï¼ˆåŒæ™‚ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®åˆ†æ•£ï¼‰
        import random
        jitter = random.uniform(0.1, 0.3) * base_delay
        
        return base_delay + jitter
    
    def _cleanup_request_history(self):
        """å¤ã„ãƒªã‚¯ã‚¨ã‚¹ãƒˆå±¥æ­´ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        current_time = time.time()
        self.request_history = [
            t for t in self.request_history 
            if current_time - t < 300  # 5åˆ†ä»¥å†…ã®ã‚‚ã®ã®ã¿ä¿æŒ
        ]

# ä½¿ç”¨ä¾‹
async def example_with_rate_limit_handling():
    """ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾å¿œã®ä½¿ç”¨ä¾‹"""
    
    handler = AdvancedRateLimitHandler()
    
    from graph_client import GraphAPIClient
    
    async with GraphAPIClient() as client:
        
        # å¤§é‡ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾å¿œã§å®Ÿè¡Œ
        users_to_create = [f"user{i}@example.com" for i in range(100)]
        
        for user_email in users_to_create:
            user_data = {
                "displayName": f"User {user_email}",
                "userPrincipalName": user_email,
                # ... ãã®ä»–ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿
            }
            
            try:
                result = await handler.execute_with_rate_limit_handling(
                    client.create_user,
                    user_data
                )
                logger.info(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½œæˆæˆåŠŸ: {user_email}")
                
            except Exception as e:
                logger.error(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½œæˆå¤±æ•—: {user_email} - {e}")
```

#### å•é¡Œ4: ãƒ¡ãƒ¢ãƒªä¸è¶³ã‚¨ãƒ©ãƒ¼

**ç—‡çŠ¶**: å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿å‡¦ç†æ™‚ã® `MemoryError` ã‚„å‡¦ç†é€Ÿåº¦ã®æ¥µç«¯ãªä½ä¸‹

**å¯¾ç­–: ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†ã®å®Ÿè£…**:

#### ãƒ¡ãƒ¢ãƒªåŠ¹ç‡çš„ãªå¤§è¦æ¨¡å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ 

ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã¯ã€æ•°ä¸‡åè¦æ¨¡ã®è¶…å¤§è¦æ¨¡å‡¦ç†ã«ãŠã„ã¦ã€ãƒ¡ãƒ¢ãƒªä¸è¶³ã‚’å›é¿ã—ãªãŒã‚‰å®‰å®šã—ãŸå‡¦ç†ã‚’å®Ÿç¾ã™ã‚‹ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ã§ã™ã€‚å¾“æ¥ã®å…¨ãƒ‡ãƒ¼ã‚¿ä¸€æ‹¬èª­ã¿è¾¼ã¿æ–¹å¼ã§ã¯ä¸å¯èƒ½ãªã€ãƒ¡ãƒ¢ãƒªåˆ¶ç´„ä¸‹ã§ã®å¤§è¦æ¨¡å‡¦ç†ã‚’å¯èƒ½ã«ã—ã¾ã™ã€‚

**å¤§è¦æ¨¡å‡¦ç†ã«ãŠã‘ã‚‹ãƒ¡ãƒ¢ãƒªå•é¡Œ:**
- **ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã®çˆ†ç™ºçš„å¢—åŠ **: 10,000å Ã— 20é …ç›® = ç´„50MBä»¥ä¸Šã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨
- **å‡¦ç†ä¸­é–“ãƒ‡ãƒ¼ã‚¿**: APIå¿œç­”ã€ã‚¨ãƒ©ãƒ¼æƒ…å ±ã€ãƒ­ã‚°ãƒ‡ãƒ¼ã‚¿ãŒè“„ç©
- **ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³**: å¤§é‡ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«ã‚ˆã‚‹GCåœæ­¢æ™‚é–“ã®å¢—åŠ 
- **ã‚·ã‚¹ãƒ†ãƒ å®‰å®šæ€§**: ãƒ¡ãƒ¢ãƒªä¸è¶³ã«ã‚ˆã‚‹ãƒ—ãƒ­ã‚»ã‚¹å¼·åˆ¶çµ‚äº†ã®ãƒªã‚¹ã‚¯

**ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†ã®æŠ€è¡“çš„å„ªä½æ€§:**

**ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®æ¯”è¼ƒ:**
```
å¾“æ¥æ‰‹æ³•:    10,000å Ã— 5KB = 50MB + å‡¦ç†ãƒ‡ãƒ¼ã‚¿ = ç´„200MB
ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°: 1,000å Ã— 5KB = 5MB + å‡¦ç†ãƒ‡ãƒ¼ã‚¿ = ç´„20MBï¼ˆ1/10ï¼‰
```

**å‡¦ç†å®‰å®šæ€§ã®å‘ä¸Š:**
- **ãƒãƒ£ãƒ³ã‚¯å‡¦ç†**: æŒ‡å®šã‚µã‚¤ã‚ºã§ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†å‰²å‡¦ç†
- **ãƒ¡ãƒ¢ãƒªç›£è¦–**: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§ã®ä½¿ç”¨é‡ãƒã‚§ãƒƒã‚¯
- **è‡ªå‹•èª¿æ•´**: è² è·ã«å¿œã˜ãŸå‡¦ç†é–“éš”ã®å‹•çš„èª¿æ•´
- **å¼·åˆ¶GC**: é©åˆ‡ãªã‚¿ã‚¤ãƒŸãƒ³ã‚°ã§ã®ãƒ¡ãƒ¢ãƒªè§£æ”¾

**å®Ÿè£…ã•ã‚ŒãŸãƒ¡ãƒ¢ãƒªç®¡ç†æ©Ÿèƒ½:**

**1. ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°CSVèª­ã¿è¾¼ã¿**
- pandas.read_csv ã® chunksize ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ´»ç”¨
- 1å›ã«èª­ã¿è¾¼ã‚€ãƒ‡ãƒ¼ã‚¿é‡ã®åˆ¶é™
- å‡¦ç†å®Œäº†å¾Œã®å³åº§ãªãƒ¡ãƒ¢ãƒªè§£æ”¾

**2. ãƒãƒƒãƒã‚µã‚¤ã‚ºã®å‹•çš„èª¿æ•´**
- ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡80%è¶…éæ™‚ã®è‡ªå‹•ç¸®å°
- ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹ã«å¿œã˜ãŸæœ€é©åŒ–
- å‡¦ç†åŠ¹ç‡ã¨ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ã®ãƒãƒ©ãƒ³ã‚¹

**3. ç©æ¥µçš„ãªã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³**
- å„ãƒãƒ£ãƒ³ã‚¯å‡¦ç†å¾Œã®å¼·åˆ¶GCå®Ÿè¡Œ
- å¾ªç’°å‚ç…§ã®ç¢ºå®Ÿãªè§£æ”¾
- ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ã®äºˆé˜²

**é©ç”¨ãŒæ¨å¥¨ã•ã‚Œã‚‹ç’°å¢ƒ:**
- **å‡¦ç†å¯¾è±¡**: 5,000åä»¥ä¸Šã®å¤§è¦æ¨¡å‡¦ç†
- **ãƒ¡ãƒ¢ãƒªåˆ¶ç´„**: 8GBä»¥ä¸‹ã®ã‚·ã‚¹ãƒ†ãƒ 
- **é•·æ™‚é–“å‡¦ç†**: æ•°æ™‚é–“ã«ã‚ãŸã‚‹å‡¦ç†
- **å®‰å®šæ€§é‡è¦–**: 24æ™‚é–“ç„¡äººé‹è»¢ãŒå¿…è¦ãªç’°å¢ƒ

**ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç‰¹æ€§:**
- å‡¦ç†é€Ÿåº¦: å¾“æ¥æ¯”ç´„10-20%ä½ä¸‹
- ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: å¾“æ¥æ¯”ç´„70-80%å‰Šæ¸›
- å®‰å®šæ€§: ã‚¯ãƒ©ãƒƒã‚·ãƒ¥ç‡90%ä»¥ä¸Šæ”¹å–„
- ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£: æ•°åä¸‡ä»¶ã¾ã§å¯¾å¿œå¯èƒ½

```python
# memory_efficient_processor.py
"""ãƒ¡ãƒ¢ãƒªåŠ¹ç‡çš„ãªå¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿å‡¦ç†"""

import asyncio
import pandas as pd
from typing import AsyncGenerator, List, Dict, Any
import gc
from loguru import logger

class MemoryEfficientProcessor:
    """ãƒ¡ãƒ¢ãƒªåŠ¹ç‡çš„ãªå¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, chunk_size: int = 1000):
        self.chunk_size = chunk_size
    
    async def process_large_csv_streaming(
        self, 
        csv_file_path: str,
        processor_func: callable
    ) -> AsyncGenerator[Dict[str, Any], None]:
        """å¤§å®¹é‡CSVã®ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†"""
        
        logger.info(f"ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†é–‹å§‹: {csv_file_path}")
        
        # ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºã§CSVã‚’èª­ã¿è¾¼ã¿
        chunk_count = 0
        
        for chunk in pd.read_csv(csv_file_path, chunksize=self.chunk_size):
            chunk_count += 1
            logger.info(f"ãƒãƒ£ãƒ³ã‚¯ {chunk_count} å‡¦ç†ä¸­: {len(chunk)}è¡Œ")
            
            # ãƒãƒ£ãƒ³ã‚¯ã”ã¨ã®å‡¦ç†
            for _, row in chunk.iterrows():
                try:
                    # ãƒ‡ãƒ¼ã‚¿ã®å¤‰æ›
                    processed_data = await processor_func(row.to_dict())
                    yield processed_data
                    
                except Exception as e:
                    logger.error(f"è¡Œå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
                    yield {"error": str(e), "row_data": row.to_dict()}
            
            # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®ç›£è¦–ã¨ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            gc.collect()
            
            # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒé–¾å€¤ã‚’è¶…ãˆãŸå ´åˆã®å¾…æ©Ÿ
            import psutil
            memory_percent = psutil.virtual_memory().percent
            if memory_percent > 80:
                logger.warning(f"ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡ãŒé«˜ã„ã§ã™: {memory_percent}%")
                await asyncio.sleep(2)  # 2ç§’å¾…æ©Ÿ
    
    async def batch_process_with_memory_management(
        self,
        data_generator: AsyncGenerator,
        batch_processor: callable,
        batch_size: int = 100
    ):
        """ãƒ¡ãƒ¢ãƒªç®¡ç†ä»˜ããƒãƒƒãƒå‡¦ç†"""
        
        batch = []
        batch_count = 0
        
        async for item in data_generator:
            batch.append(item)
            
            # ãƒãƒƒãƒã‚µã‚¤ã‚ºã«é”ã—ãŸã‚‰å‡¦ç†å®Ÿè¡Œ
            if len(batch) >= batch_size:
                batch_count += 1
                logger.info(f"ãƒãƒƒãƒ {batch_count} å‡¦ç†å®Ÿè¡Œ: {len(batch)}ä»¶")
                
                try:
                    await batch_processor(batch)
                except Exception as e:
                    logger.error(f"ãƒãƒƒãƒå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
                
                # ãƒãƒƒãƒã‚¯ãƒªã‚¢ãƒ»ãƒ¡ãƒ¢ãƒªè§£æ”¾
                batch.clear()
                gc.collect()
                
                # ãƒ¡ãƒ¢ãƒªçŠ¶æ³ã®ç¢ºèª
                import psutil
                memory_info = psutil.virtual_memory()
                logger.debug(f"ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {memory_info.percent}%")
        
        # æ®‹ã‚Šã®ãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†
        if batch:
            batch_count += 1
            logger.info(f"æœ€çµ‚ãƒãƒƒãƒ {batch_count} å‡¦ç†: {len(batch)}ä»¶")
            await batch_processor(batch)

# ä½¿ç”¨ä¾‹
async def memory_efficient_bulk_creation():
    """ãƒ¡ãƒ¢ãƒªåŠ¹ç‡çš„ãªå¤§é‡ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½œæˆ"""
    
    processor = MemoryEfficientProcessor(chunk_size=500)
    
    async def convert_row_to_user_data(row_dict: Dict[str, Any]) -> Dict[str, Any]:
        """è¡Œãƒ‡ãƒ¼ã‚¿ã‚’ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿ã«å¤‰æ›"""
        return {
            "displayName": row_dict.get('DisplayName', ''),
            "userPrincipalName": row_dict.get('UserPrincipalName', ''),
            "givenName": row_dict.get('FirstName', ''),
            "surname": row_dict.get('LastName', ''),
            "passwordProfile": {
                "password": row_dict.get('Password', ''),
                "forceChangePasswordNextSignIn": True
            }
        }
    
    async def batch_create_users(user_batch: List[Dict[str, Any]]):
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒãƒƒãƒã®ä½œæˆ"""
        from async_bulk_manager import AsyncBulkUserManager
        
        async with AsyncBulkUserManager(max_concurrent_requests=10) as manager:
            # ã‚¨ãƒ©ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’é™¤å¤–
            valid_users = [user for user in user_batch if "error" not in user]
            
            if valid_users:
                result = await manager.create_users_async(valid_users)
                logger.info(f"ãƒãƒƒãƒä½œæˆå®Œäº†: æˆåŠŸ{result.success_count}ä»¶, å¤±æ•—{result.failed_count}ä»¶")
    
    # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†ã®å®Ÿè¡Œ
    csv_file = "large_users_dataset.csv"
    data_stream = processor.process_large_csv_streaming(csv_file, convert_row_to_user_data)
    
    await processor.batch_process_with_memory_management(
        data_stream,
        batch_create_users,
        batch_size=50
    )

if __name__ == "__main__":
    asyncio.run(memory_efficient_bulk_creation())
```

---

## ğŸ“Š å®Ÿé‹ç”¨ã§ã®æ³¨æ„äº‹é …ã¨ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹

### ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è€ƒæ…®äº‹é …

#### 1. æ©Ÿå¯†æƒ…å ±ã®ç®¡ç†

#### ã‚»ã‚­ãƒ¥ã‚¢ãªè¨­å®šç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 

ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã¯ã€ä¼æ¥­ç’°å¢ƒã§ã®æ©Ÿå¯†æƒ…å ±ï¼ˆèªè¨¼æƒ…å ±ã€API ã‚­ãƒ¼ç­‰ï¼‰ã‚’å®‰å…¨ã«ç®¡ç†ã™ã‚‹ãŸã‚ã®åŒ…æ‹¬çš„ãªã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚·ã‚¹ãƒ†ãƒ ã§ã™ã€‚å¾“æ¥ã®å¹³æ–‡ä¿å­˜ã‚„ã‚·ãƒ³ãƒ—ãƒ«ãªç’°å¢ƒå¤‰æ•°ç®¡ç†ã§ã¯ä¸ååˆ†ãªã€ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºãƒ¬ãƒ™ãƒ«ã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¦ä»¶ã‚’æº€ãŸã—ã¾ã™ã€‚

**å¾“æ¥ã®è¨­å®šç®¡ç†æ‰‹æ³•ã®å•é¡Œç‚¹:**
- **å¹³æ–‡ä¿å­˜**: `.env`ãƒ•ã‚¡ã‚¤ãƒ«ã‚„ã‚³ãƒ¼ãƒ‰ã¸ã®ç›´æ¥è¨˜è¿°
- **ç‰ˆæ•°ç®¡ç†ã¸ã®æ··å…¥**: Gitãƒªãƒã‚¸ãƒˆãƒªã§ã®Accidental Commit
- **å…±æœ‰ã®å›°é›£æ€§**: ãƒãƒ¼ãƒ é–“ã§ã®å®‰å…¨ãªå…±æœ‰æ‰‹æ®µã®æ¬ å¦‚
- **ç›£æŸ»è¨¼è·¡ã®ä¸è¶³**: ã‚¢ã‚¯ã‚»ã‚¹å±¥æ­´ã‚„å¤‰æ›´å±¥æ­´ã®æ¬ å¦‚

**ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã®è¦ä»¶:**
1. **æš—å·åŒ–ä¿å­˜**: æ©Ÿå¯†æƒ…å ±ã® AES-256 æš—å·åŒ–
2. **ã‚¢ã‚¯ã‚»ã‚¹åˆ¶å¾¡**: èªè¨¼ã•ã‚ŒãŸãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã¿ã®æƒ…å ±ã‚¢ã‚¯ã‚»ã‚¹
3. **ç›£æŸ»ãƒ­ã‚°**: ã™ã¹ã¦ã®è¨­å®šå¤‰æ›´ã®è¿½è·¡å¯èƒ½æ€§
4. **ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³**: å®šæœŸçš„ãªèªè¨¼æƒ…å ±ã®æ›´æ–°æ©Ÿèƒ½
5. **åˆ†é›¢åŸå‰‡**: é–‹ç™ºãƒ»ãƒ†ã‚¹ãƒˆãƒ»æœ¬ç•ªç’°å¢ƒã®å®Œå…¨åˆ†é›¢

**å®Ÿè£…ã•ã‚ŒãŸã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æ©Ÿèƒ½:**

**1. å¤šå±¤æš—å·åŒ–**
```python
# æš—å·åŒ–ã®ä»•çµ„ã¿
OS Keyring â†’ æš—å·åŒ–ã‚­ãƒ¼ä¿å­˜ â†’ Fernetæš—å·åŒ– â†’ å®‰å…¨ãªæ©Ÿå¯†æƒ…å ±ä¿å­˜
```

**2. ã‚¼ãƒ­çŸ¥è­˜ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£**
- ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚„ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã‚’å¹³æ–‡ã§ä¿æŒã—ãªã„
- æš—å·åŒ–ã‚­ãƒ¼ã¯ OS ã® Keyring ã«å§”è¨—
- ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³çµ‚äº†æ™‚ã®è‡ªå‹•ãƒ¡ãƒ¢ãƒªã‚¯ãƒªã‚¢

**3. æ“ä½œã®é€æ˜æ€§**
- ã™ã¹ã¦ã®è¨­å®šå¤‰æ›´ã‚’ãƒ­ã‚°è¨˜éŒ²
- ã‚¢ã‚¯ã‚»ã‚¹æ™‚åˆ»ã¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å®Œå…¨ãªè¿½è·¡
- ç•°å¸¸ã‚¢ã‚¯ã‚»ã‚¹ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œçŸ¥

**å¯¾å¿œãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ :**
- **Windows**: Windows Credential Store
- **macOS**: Keychain Access
- **Linux**: Secret Service (GNOME/KDE)

**å®Ÿç”¨çš„ãªä½¿ç”¨ä¾‹:**
```python
# åˆå›ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼ˆ1å›ã®ã¿ï¼‰
config = SecureConfigManager()
config.setup_secure_credentials()

# æ—¥å¸¸çš„ãªä½¿ç”¨
tenant_id = config.get_credential("tenant_id")
client_secret = config.get_credential("client_secret")
```

**ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ç›£æŸ»å¯¾å¿œ:**
- GDPR ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹å¯¾å¿œ
- SOXæ³•ç›£æŸ»è¦ä»¶æº€è¶³
- ISO 27001 æƒ…å ±ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£åŸºæº–æº–æ‹ 
- PCI DSS ãƒ‡ãƒ¼ã‚¿ä¿è­·åŸºæº–å¯¾å¿œ

**å°å…¥åŠ¹æœ:**
- **ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒªã‚¹ã‚¯**: 90%ä»¥ä¸Šå‰Šæ¸›
- **ç›£æŸ»å·¥æ•°**: å¾“æ¥æ¯”50%å‰Šæ¸›
- **è¨­å®šãƒŸã‚¹**: äººçš„ã‚¨ãƒ©ãƒ¼80%å‰Šæ¸›
- **é–‹ç™ºåŠ¹ç‡**: ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¨­å®šã®è‡ªå‹•åŒ–

```python
# secure_config_manager.py
"""ã‚»ã‚­ãƒ¥ã‚¢ãªè¨­å®šç®¡ç†"""

import os
import keyring
from cryptography.fernet import Fernet
import base64
from typing import Optional

class SecureConfigManager:
    """ã‚»ã‚­ãƒ¥ã‚¢ãªè¨­å®šç®¡ç†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, service_name: str = "M365Management"):
        self.service_name = service_name
        self.encryption_key = self._get_or_create_encryption_key()
    
    def _get_or_create_encryption_key(self) -> bytes:
        """æš—å·åŒ–ã‚­ãƒ¼ã®å–å¾—ã¾ãŸã¯ä½œæˆ"""
        key_name = f"{self.service_name}_encryption_key"
        
        # ã‚­ãƒ¼ãƒªãƒ³ã‚°ã‹ã‚‰ã‚­ãƒ¼ã‚’å–å¾—
        stored_key = keyring.get_password(self.service_name, key_name)
        
        if stored_key:
            return base64.b64decode(stored_key.encode())
        else:
            # æ–°ã—ã„ã‚­ãƒ¼ã‚’ç”Ÿæˆãƒ»ä¿å­˜
            new_key = Fernet.generate_key()
            encoded_key = base64.b64encode(new_key).decode()
            keyring.set_password(self.service_name, key_name, encoded_key)
            return new_key
    
    def store_credential(self, key: str, value: str) -> None:
        """èªè¨¼æƒ…å ±ã®æš—å·åŒ–ä¿å­˜"""
        cipher = Fernet(self.encryption_key)
        encrypted_value = cipher.encrypt(value.encode())
        encoded_value = base64.b64encode(encrypted_value).decode()
        
        keyring.set_password(self.service_name, key, encoded_value)
    
    def get_credential(self, key: str) -> Optional[str]:
        """èªè¨¼æƒ…å ±ã®å¾©å·åŒ–å–å¾—"""
        encoded_value = keyring.get_password(self.service_name, key)
        
        if not encoded_value:
            return None
        
        try:
            cipher = Fernet(self.encryption_key)
            encrypted_value = base64.b64decode(encoded_value.encode())
            decrypted_value = cipher.decrypt(encrypted_value)
            return decrypted_value.decode()
        except Exception:
            return None
    
    def setup_secure_credentials(self):
        """ã‚»ã‚­ãƒ¥ã‚¢ãªèªè¨¼æƒ…å ±ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
        print("ã‚»ã‚­ãƒ¥ã‚¢ãªèªè¨¼æƒ…å ±ã®è¨­å®š")
        
        tenant_id = input("Tenant ID: ")
        client_id = input("Client ID: ")
        client_secret = input("Client Secret: ")
        
        self.store_credential("tenant_id", tenant_id)
        self.store_credential("client_id", client_id)
        self.store_credential("client_secret", client_secret)
        
        print("âœ… èªè¨¼æƒ…å ±ãŒå®‰å…¨ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸ")

# ä½¿ç”¨ä¾‹
config_manager = SecureConfigManager()

# åˆå›è¨­å®š
# config_manager.setup_secure_credentials()

# èªè¨¼æƒ…å ±ã®å–å¾—
tenant_id = config_manager.get_credential("tenant_id")
client_id = config_manager.get_credential("client_id")
client_secret = config_manager.get_credential("client_secret")
```

#### 2. ç›£æŸ»ãƒ­ã‚°ã®å®Ÿè£…

#### åŒ…æ‹¬çš„ç›£æŸ»ãƒ­ã‚°ã‚·ã‚¹ãƒ†ãƒ 

ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã¯ã€Microsoft 365 ç®¡ç†æ“ä½œã®ã™ã¹ã¦ã‚’è¨˜éŒ²ãƒ»è¿½è·¡ã™ã‚‹åŒ…æ‹¬çš„ãªç›£æŸ»ãƒ­ã‚°ã‚·ã‚¹ãƒ†ãƒ ã§ã™ã€‚ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹è¦ä»¶ã€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ç›£æŸ»ã€äº‹æ•…èª¿æŸ»ã€é‹ç”¨åˆ†æã®ã™ã¹ã¦ã®ãƒ‹ãƒ¼ã‚ºã«å¯¾å¿œã™ã‚‹ä¼æ¥­ãƒ¬ãƒ™ãƒ«ã®ç›£æŸ»ã‚·ã‚¹ãƒ†ãƒ ã‚’æä¾›ã—ã¾ã™ã€‚

**ç›£æŸ»ãƒ­ã‚°ã®æ³•çš„ãƒ»æ¥­å‹™çš„é‡è¦æ€§:**
- **ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹è¦ä»¶**: SOXæ³•ã€GDPRã€å€‹äººæƒ…å ±ä¿è­·æ³•ã¸ã®å¯¾å¿œ
- **ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¨¼è·¡**: ä¸æ­£æ“ä½œãƒ»å†…éƒ¨è„…å¨ã®æ¤œçŸ¥ã¨è¨¼æ˜
- **äº‹æ•…èª¿æŸ»**: å•é¡Œç™ºç”Ÿæ™‚ã®åŸå› ç©¶æ˜ã¨å½±éŸ¿ç¯„å›²ç‰¹å®š
- **é‹ç”¨æ”¹å–„**: æ“ä½œãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æã«ã‚ˆã‚‹åŠ¹ç‡åŒ–æ©Ÿä¼šã®ç™ºè¦‹

**å¾“æ¥ã®ãƒ­ã‚°ç®¡ç†ã¨ã®å·®åˆ¥åŒ–:**

**å¾“æ¥ã®å•é¡Œç‚¹:**
- æ•£ç™ºçš„ãªãƒ­ã‚°è¨˜éŒ²ï¼ˆé‡è¦æ“ä½œã®è¨˜éŒ²æ¼ã‚Œï¼‰
- æ¨™æº–åŒ–ã•ã‚Œã¦ã„ãªã„å½¢å¼ï¼ˆåˆ†æå›°é›£ï¼‰
- æ”¹ã–ã‚“å¯èƒ½æ€§ï¼ˆè¨¼æ‹ èƒ½åŠ›ã®æ¬ å¦‚ï¼‰
- æ¤œç´¢ãƒ»åˆ†ææ©Ÿèƒ½ã®ä¸è¶³

**æœ¬ã‚·ã‚¹ãƒ†ãƒ ã®ç‰¹å¾´:**
- **å®Œå…¨æ€§**: ã™ã¹ã¦ã®ç®¡ç†æ“ä½œã‚’æ¼ã‚Œãªãè¨˜éŒ²
- **æ¨™æº–æ€§**: æ§‹é€ åŒ–ã•ã‚ŒãŸJSONå½¢å¼ã§ã®çµ±ä¸€è¨˜éŒ²
- **ä¸å¯é€†æ€§**: ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã¨ãƒãƒƒã‚·ãƒ¥ã«ã‚ˆã‚‹æ”¹ã–ã‚“é˜²æ­¢
- **åˆ†ææ€§**: ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢ãƒ»åˆ†é¡ã«ã‚ˆã‚‹åŠ¹ç‡çš„åˆ†æ

**è¨˜éŒ²ã•ã‚Œã‚‹è©³ç´°æƒ…å ±:**

**åŸºæœ¬æƒ…å ±:**
- æ“ä½œæ—¥æ™‚ï¼ˆUTCã€ãƒŸãƒªç§’ç²¾åº¦ï¼‰
- æ“ä½œIDï¼ˆUUIDã€è¿½è·¡ç”¨ï¼‰
- æ“ä½œç¨®åˆ¥ï¼ˆCREATE/UPDATE/DELETEç­‰ï¼‰
- å®Ÿè¡Œãƒ¦ãƒ¼ã‚¶ãƒ¼ï¼ˆã‚·ã‚¹ãƒ†ãƒ /å€‹äººè­˜åˆ¥ï¼‰

**æ“ä½œè©³ç´°:**
- å¯¾è±¡ãƒªã‚½ãƒ¼ã‚¹ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã€ã‚°ãƒ«ãƒ¼ãƒ—ç­‰ï¼‰
- æ“ä½œçµæœï¼ˆæˆåŠŸ/å¤±æ•—/éƒ¨åˆ†æˆåŠŸï¼‰
- å¤‰æ›´å†…å®¹ï¼ˆå‰å¾Œã®å€¤ã€å¤‰æ›´ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ï¼‰
- ã‚¨ãƒ©ãƒ¼è©³ç´°ï¼ˆå¤±æ•—æ™‚ã®åŸå› æƒ…å ±ï¼‰

**ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æƒ…å ±:**
- ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆIPï¼ˆæ“ä½œå…ƒã®ç‰¹å®šï¼‰
- User-Agentï¼ˆåˆ©ç”¨ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
- ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢ï¼ˆæ“ä½œã®å±é™ºåº¦è©•ä¾¡ï¼‰
- é–¢é€£æ“ä½œï¼ˆåŒä¸€ã‚»ãƒƒã‚·ãƒ§ãƒ³å†…ã®æ“ä½œï¼‰

**è‡ªå‹•ãƒªã‚¹ã‚¯è©•ä¾¡æ©Ÿèƒ½:**
```python
ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢è¨ˆç®—å¼:
- DELETEæ“ä½œ: +50ç‚¹
- å¤§é‡å‡¦ç†(1000ä»¶ä»¥ä¸Š): +30ç‚¹
- ç®¡ç†è€…æ¨©é™å¤‰æ›´: +40ç‚¹
- å–¶æ¥­æ™‚é–“å¤–æ“ä½œ: +20ç‚¹
æœ€å¤§100ç‚¹ï¼ˆè¦æ³¨æ„ãƒ¬ãƒ™ãƒ«ï¼‰
```

**å®Ÿç”¨çš„ãªã‚¯ã‚¨ãƒªä¾‹:**
```python
# é«˜ãƒªã‚¹ã‚¯æ“ä½œã®æŠ½å‡º
high_risk_ops = [log for log in audit_logs if log['risk_score'] > 70]

# ç‰¹å®šãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ“ä½œå±¥æ­´
user_history = [log for log in audit_logs if log['user_principal'] == 'admin@company.com']

# å¤±æ•—æ“ä½œã®åˆ†æ
failed_ops = [log for log in audit_logs if log['result'] == 'FAILED']
```

**ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹è¦ä»¶ã¸ã®å¯¾å¿œ:**
- **ä¿æŒæœŸé–“**: 7å¹´é–“ã®è‡ªå‹•ä¿æŒï¼ˆæ³•çš„è¦ä»¶æº–æ‹ ï¼‰
- **æ¤œç´¢æ©Ÿèƒ½**: è¿…é€Ÿãªç›£æŸ»å¯¾å¿œï¼ˆ24æ™‚é–“ä»¥å†…ã®å›ç­”ï¼‰
- **ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ**: CSV/JSON/PDF ã§ã®è¨¼è·¡æå‡º
- **ç½²åæ©Ÿèƒ½**: ãƒ‡ã‚¸ã‚¿ãƒ«ç½²åã«ã‚ˆã‚‹çœŸæ­£æ€§ä¿è¨¼

```python
# audit_logger.py
"""åŒ…æ‹¬çš„ãªç›£æŸ»ãƒ­ã‚°ã‚·ã‚¹ãƒ†ãƒ """

import json
import logging
from datetime import datetime
from typing import Dict, Any, Optional
from dataclasses import dataclass, asdict
import hashlib
import uuid

@dataclass
class AuditLogEntry:
    """ç›£æŸ»ãƒ­ã‚°ã‚¨ãƒ³ãƒˆãƒª"""
    timestamp: str
    operation_id: str
    operation_type: str
    user_principal: str
    target_resource: str
    result: str
    details: Dict[str, Any]
    client_ip: Optional[str] = None
    user_agent: Optional[str] = None
    risk_score: Optional[int] = None

class AuditLogger:
    """åŒ…æ‹¬çš„ç›£æŸ»ãƒ­ã‚°ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, log_file: str = "m365_audit.log"):
        self.log_file = log_file
        self.logger = logging.getLogger("M365Audit")
        self.logger.setLevel(logging.INFO)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã®è¨­å®š
        file_handler = logging.FileHandler(log_file, encoding='utf-8')
        file_handler.setLevel(logging.INFO)
        
        # JSONå½¢å¼ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒã‚¿ãƒ¼
        formatter = logging.Formatter('%(message)s')
        file_handler.setFormatter(formatter)
        
        self.logger.addHandler(file_handler)
    
    def log_operation(
        self,
        operation_type: str,
        target_resource: str,
        result: str,
        details: Dict[str, Any],
        user_principal: str = "system",
        risk_score: Optional[int] = None
    ) -> str:
        """æ“ä½œã®ç›£æŸ»ãƒ­ã‚°è¨˜éŒ²"""
        
        operation_id = str(uuid.uuid4())
        
        log_entry = AuditLogEntry(
            timestamp=datetime.utcnow().isoformat() + "Z",
            operation_id=operation_id,
            operation_type=operation_type,
            user_principal=user_principal,
            target_resource=target_resource,
            result=result,
            details=details,
            risk_score=risk_score
        )
        
        # JSONå½¢å¼ã§ãƒ­ã‚°å‡ºåŠ›
        log_json = json.dumps(asdict(log_entry), ensure_ascii=False)
        self.logger.info(log_json)
        
        return operation_id
    
    def log_bulk_operation_start(
        self,
        operation_type: str,
        target_count: int,
        details: Dict[str, Any]
    ) -> str:
        """ä¸€æ‹¬æ“ä½œé–‹å§‹ã®ãƒ­ã‚°"""
        return self.log_operation(
            operation_type=f"BULK_{operation_type}_START",
            target_resource=f"users_count_{target_count}",
            result="INITIATED",
            details={
                **details,
                "bulk_operation": True,
                "target_count": target_count
            },
            risk_score=self._calculate_risk_score(operation_type, target_count)
        )
    
    def log_bulk_operation_end(
        self,
        operation_id: str,
        operation_type: str,
        success_count: int,
        failed_count: int,
        total_time: float
    ) -> str:
        """ä¸€æ‹¬æ“ä½œå®Œäº†ã®ãƒ­ã‚°"""
        return self.log_operation(
            operation_type=f"BULK_{operation_type}_END",
            target_resource=f"users_processed_{success_count + failed_count}",
            result="COMPLETED",
            details={
                "original_operation_id": operation_id,
                "success_count": success_count,
                "failed_count": failed_count,
                "total_time_seconds": total_time,
                "success_rate": (success_count / (success_count + failed_count)) * 100
            }
        )
    
    def _calculate_risk_score(self, operation_type: str, target_count: int) -> int:
        """æ“ä½œã®ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢è¨ˆç®—"""
        base_score = 0
        
        if "DELETE" in operation_type.upper():
            base_score += 50
        elif "CREATE" in operation_type.upper():
            base_score += 20
        elif "UPDATE" in operation_type.upper():
            base_score += 10
        
        # å¯¾è±¡æ•°ã«ã‚ˆã‚‹ã‚¹ã‚³ã‚¢å¢—åŠ 
        if target_count > 1000:
            base_score += 30
        elif target_count > 100:
            base_score += 20
        elif target_count > 10:
            base_score += 10
        
        return min(base_score, 100)  # æœ€å¤§100

# ä½¿ç”¨ä¾‹
audit_logger = AuditLogger()

# ä¸€æ‹¬æ“ä½œã®ãƒ­ã‚°è¨˜éŒ²ä¾‹
operation_id = audit_logger.log_bulk_operation_start(
    operation_type="USER_CREATE",
    target_count=500,
    details={
        "csv_file": "new_students_2025.csv",
        "department": "æƒ…å ±å­¦éƒ¨",
        "license_type": "A1_STUDENT"
    }
)

# å‡¦ç†å®Œäº†å¾Œ
audit_logger.log_bulk_operation_end(
    operation_id=operation_id,
    operation_type="USER_CREATE",
    success_count=485,
    failed_count=15,
    total_time=120.5
)
```

### é‹ç”¨ç›£è¦–ã¨ã‚¢ãƒ©ãƒ¼ãƒˆ

#### æœ¬ç•ªé‹ç”¨ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ 

ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã¯ã€Microsoft 365 ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã‚’24æ™‚é–“365æ—¥å®‰å®šç¨¼åƒã•ã›ã‚‹ãŸã‚ã®åŒ…æ‹¬çš„ãªé‹ç”¨ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ ã§ã™ã€‚å˜ãªã‚‹ã‚·ã‚¹ãƒ†ãƒ ç›£è¦–ã‚’è¶…ãˆã¦ã€ãƒ“ã‚¸ãƒã‚¹ç¶™ç¶šæ€§ã‚’ä¿è¨¼ã™ã‚‹äºˆé˜²çš„ç›£è¦–ã¨ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆãªã‚¢ãƒ©ãƒ¼ãƒˆæ©Ÿèƒ½ã‚’æä¾›ã—ã¾ã™ã€‚

**æœ¬ç•ªé‹ç”¨ã«ãŠã‘ã‚‹ç›£è¦–ã®é‡è¦æ€§:**
- **ãƒ“ã‚¸ãƒã‚¹ç¶™ç¶šæ€§**: ã‚·ã‚¹ãƒ†ãƒ åœæ­¢ã«ã‚ˆã‚‹æ¥­å‹™å½±éŸ¿ã®æœ€å°åŒ–
- **SLAéµå®ˆ**: ã‚µãƒ¼ãƒ“ã‚¹ãƒ¬ãƒ™ãƒ«å¥‘ç´„ã§å®šã‚ã‚‰ã‚ŒãŸç¨¼åƒç‡ã®ç¶­æŒ
- **äºˆé˜²çš„å¯¾å¿œ**: å•é¡ŒãŒæ·±åˆ»åŒ–ã™ã‚‹å‰ã®æ—©æœŸæ¤œçŸ¥ãƒ»å¯¾å¿œ
- **ãƒªã‚½ãƒ¼ã‚¹æœ€é©åŒ–**: é©åˆ‡ãªã‚­ãƒ£ãƒ‘ã‚·ãƒ†ã‚£ãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ã®åŸºç¤ãƒ‡ãƒ¼ã‚¿æä¾›

**å¾“æ¥ã®ç›£è¦–æ‰‹æ³•ã¨ã®é•ã„:**

**å¾“æ¥ã®åå¿œçš„ç›£è¦–:**
- å•é¡Œç™ºç”Ÿå¾Œã®äº‹å¾Œå¯¾å¿œ
- å˜ä¸€ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã§ã®å˜ç´”ã‚¢ãƒ©ãƒ¼ãƒˆ
- äººçš„ç›£è¦–ã¸ã®ä¾å­˜
- ãƒ“ã‚¸ãƒã‚¹å½±éŸ¿ã®è€ƒæ…®ä¸è¶³

**æœ¬ã‚·ã‚¹ãƒ†ãƒ ã®äºˆé˜²çš„ç›£è¦–:**
- **è¤‡åˆæŒ‡æ¨™ã«ã‚ˆã‚‹æ—©æœŸè­¦å‘Š**: CPU+ãƒ¡ãƒ¢ãƒª+APIå¿œç­”æ™‚é–“ã®çµ„ã¿åˆã‚ã›åˆ†æ
- **ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ**: éå»24æ™‚é–“ã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç•°å¸¸å‚¾å‘ã‚’æ¤œçŸ¥
- **ãƒ“ã‚¸ãƒã‚¹æŒ‡å‘**: æŠ€è¡“ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ãƒ“ã‚¸ãƒã‚¹å½±éŸ¿ã«ç¿»è¨³
- **è‡ªå‹•å¾©æ—§**: è»½å¾®ãªå•é¡Œã®è‡ªå‹•ä¿®å¾©æ©Ÿèƒ½

**ç›£è¦–å¯¾è±¡ã®åŒ…æ‹¬çš„ã‚«ãƒãƒ¬ãƒƒã‚¸:**

**ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹ç›£è¦–:**
- **CPUä½¿ç”¨ç‡**: ãƒ—ãƒ­ã‚»ã‚¹è² è·ã¨ã‚­ãƒ¥ãƒ¼ã®ç›£è¦–
- **ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡**: ç‰©ç†ãƒ»ä»®æƒ³ãƒ¡ãƒ¢ãƒªã®ä¸¡æ–¹ã‚’è¿½è·¡
- **ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨ç‡**: ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸å®¹é‡ã¨I/Oæ€§èƒ½
- **ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯**: å¸¯åŸŸä½¿ç”¨ç‡ã¨æ¥ç¶šæ•°

**ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ç›£è¦–:**
- **APIå¿œç­”æ™‚é–“**: Microsoft Graph API ã®æ€§èƒ½è¿½è·¡
- **ã‚¨ãƒ©ãƒ¼ç‡**: å¤±æ•—ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ã®æ¯”ç‡ç›£è¦–
- **å‡¦ç†ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ**: æ™‚é–“ã‚ãŸã‚Šã®å‡¦ç†ä»¶æ•°
- **ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ³**: åŒæ™‚æ¥ç¶šæ•°ã¨èªè¨¼çŠ¶æ…‹

**ãƒ“ã‚¸ãƒã‚¹ç›£è¦–:**
- **ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½œæˆç‡**: æ¥­å‹™ãƒ—ãƒ­ã‚»ã‚¹ã®å¥å…¨æ€§
- **ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ä½¿ç”¨ç‡**: ã‚³ã‚¹ãƒˆç®¡ç†ã¨ã‚­ãƒ£ãƒ‘ã‚·ãƒ†ã‚£äºˆæ¸¬
- **ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¤ãƒ™ãƒ³ãƒˆ**: ç•°å¸¸ã‚¢ã‚¯ã‚»ã‚¹ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œçŸ¥

**ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆã‚¢ãƒ©ãƒ¼ãƒˆæ©Ÿèƒ½:**

**ã‚¢ãƒ©ãƒ¼ãƒˆç–²ã‚Œã®å›é¿:**
- **é‡è¦åº¦ãƒ¬ãƒ™ãƒªãƒ³ã‚°**: Critical/Warning/Info ã®3æ®µéš
- **ã‚¢ãƒ©ãƒ¼ãƒˆçµ±åˆ**: é–¢é€£ã™ã‚‹è¤‡æ•°ã‚¢ãƒ©ãƒ¼ãƒˆã®çµ±åˆè¡¨ç¤º
- **ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³**: æ®µéšçš„ãªé€šçŸ¥å…ˆæ‹¡å¤§
- **è‡ªå‹•è§£æ±º**: ä¸€æ™‚çš„å•é¡Œã®è‡ªå‹•è§£æ±ºé€šçŸ¥

**ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã®æä¾›:**
```python
ã‚¢ãƒ©ãƒ¼ãƒˆå†…å®¹ä¾‹:
ğŸš¨ CRITICAL: APIå¿œç­”æ™‚é–“ç•°å¸¸
- ç¾åœ¨å€¤: 8.5ç§’ (é–¾å€¤: 5.0ç§’)
- éå»24æ™‚é–“å¹³å‡: 2.1ç§’
- å½±éŸ¿ç¯„å›²: ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½œæˆå‡¦ç†ã®é…å»¶
- æ¨å®šåŸå› : ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯é…å»¶ã¾ãŸã¯ã‚µãƒ¼ãƒãƒ¼è² è·
- å¯¾å¿œç­–: [è‡ªå‹•å†è©¦è¡Œæœ‰åŠ¹åŒ–æ¸ˆã¿]
```

**é‹ç”¨åŠ¹ç‡åŒ–æ©Ÿèƒ½:**
- **è‡ªå‹•ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ**: æ—¥æ¬¡ãƒ»é€±æ¬¡ãƒ»æœˆæ¬¡ã®é‹ç”¨ãƒ¬ãƒãƒ¼ãƒˆ
- **ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ**: é•·æœŸçš„ãªæ€§èƒ½å‚¾å‘ã®å¯è¦–åŒ–
- **å®¹é‡è¨ˆç”»**: å°†æ¥ã®ãƒªã‚½ãƒ¼ã‚¹éœ€è¦äºˆæ¸¬
- **æ ¹æœ¬åŸå› åˆ†æ**: å•é¡Œã®æ§‹é€ çš„åŸå› ã®ç‰¹å®š

**å¯ç”¨æ€§è¨­è¨ˆ:**
- **å†—é•·ç›£è¦–**: ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ è‡ªä½“ã®é«˜å¯ç”¨æ€§
- **ã‚ªãƒ•ãƒ©ã‚¤ãƒ³è€æ€§**: ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ–­çµ¶æ™‚ã®è‡ªå¾‹å‹•ä½œ
- **ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—é€šçŸ¥**: ä¸»è¦é€šçŸ¥æ‰‹æ®µå¤±æ•—æ™‚ã®ä»£æ›¿çµŒè·¯

```python
# production_monitor.py
"""æœ¬ç•ªé‹ç”¨ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ """

import asyncio
import psutil
import aiohttp
from datetime import datetime, timedelta
from typing import Dict, Any, List
from dataclasses import dataclass
import json

@dataclass
class SystemMetrics:
    """ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹"""
    timestamp: datetime
    cpu_percent: float
    memory_percent: float
    disk_usage_percent: float
    active_connections: int
    api_response_time: float

class ProductionMonitor:
    """æœ¬ç•ªé‹ç”¨ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.metrics_history: List[SystemMetrics] = []
        self.alert_thresholds = {
            "cpu_percent": 80.0,
            "memory_percent": 85.0,
            "disk_usage_percent": 90.0,
            "api_response_time": 5.0
        }
        self.monitoring_active = False
    
    async def start_monitoring(self, interval_seconds: int = 60):
        """ç›£è¦–é–‹å§‹"""
        self.monitoring_active = True
        logger.info("æœ¬ç•ªç›£è¦–ã‚’é–‹å§‹ã—ã¾ã—ãŸ")
        
        while self.monitoring_active:
            try:
                # ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®åé›†
                metrics = await self.collect_system_metrics()
                self.metrics_history.append(metrics)
                
                # å¤ã„ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ï¼ˆ24æ™‚é–“ä»¥ä¸Šå¤ã„ã‚‚ã®ã‚’å‰Šé™¤ï¼‰
                cutoff_time = datetime.now() - timedelta(hours=24)
                self.metrics_history = [
                    m for m in self.metrics_history 
                    if m.timestamp > cutoff_time
                ]
                
                # ã‚¢ãƒ©ãƒ¼ãƒˆãƒã‚§ãƒƒã‚¯
                await self.check_alerts(metrics)
                
                # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®ä¿å­˜ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
                await self.save_metrics(metrics)
                
                await asyncio.sleep(interval_seconds)
                
            except Exception as e:
                logger.error(f"ç›£è¦–ã‚¨ãƒ©ãƒ¼: {e}")
                await asyncio.sleep(interval_seconds)
    
    async def collect_system_metrics(self) -> SystemMetrics:
        """ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®åé›†"""
        
        # CPUãƒ»ãƒ¡ãƒ¢ãƒªãƒ»ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨ç‡
        cpu_percent = psutil.cpu_percent(interval=1)
        memory = psutil.virtual_memory()
        disk = psutil.disk_usage('/')
        
        # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šæ•°
        connections = len(psutil.net_connections())
        
        # APIå¿œç­”æ™‚é–“ã®æ¸¬å®š
        api_response_time = await self.measure_api_response_time()
        
        return SystemMetrics(
            timestamp=datetime.now(),
            cpu_percent=cpu_percent,
            memory_percent=memory.percent,
            disk_usage_percent=disk.percent,
            active_connections=connections,
            api_response_time=api_response_time
        )
    
    async def measure_api_response_time(self) -> float:
        """Graph APIã®å¿œç­”æ™‚é–“æ¸¬å®š"""
        try:
            start_time = datetime.now()
            
            # è»½é‡ãªAPIå‘¼ã³å‡ºã—ï¼ˆè‡ªåˆ†ã®ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«å–å¾—ï¼‰
            from graph_client import GraphAPIClient
            async with GraphAPIClient() as client:
                await client._make_request('GET', 'me?$select=id')
            
            end_time = datetime.now()
            response_time = (end_time - start_time).total_seconds()
            
            return response_time
            
        except Exception as e:
            logger.warning(f"APIå¿œç­”æ™‚é–“æ¸¬å®šå¤±æ•—: {e}")
            return 99.0  # ã‚¨ãƒ©ãƒ¼æ™‚ã¯é«˜ã„å€¤ã‚’è¿”ã™
    
    async def check_alerts(self, metrics: SystemMetrics):
        """ã‚¢ãƒ©ãƒ¼ãƒˆãƒã‚§ãƒƒã‚¯"""
        alerts = []
        
        # CPUä½¿ç”¨ç‡ãƒã‚§ãƒƒã‚¯
        if metrics.cpu_percent > self.alert_thresholds["cpu_percent"]:
            alerts.append(f"CPUä½¿ç”¨ç‡ãŒé«˜ã„ã§ã™: {metrics.cpu_percent:.1f}%")
        
        # ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡ãƒã‚§ãƒƒã‚¯
        if metrics.memory_percent > self.alert_thresholds["memory_percent"]:
            alerts.append(f"ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡ãŒé«˜ã„ã§ã™: {metrics.memory_percent:.1f}%")
        
        # ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨ç‡ãƒã‚§ãƒƒã‚¯
        if metrics.disk_usage_percent > self.alert_thresholds["disk_usage_percent"]:
            alerts.append(f"ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨ç‡ãŒé«˜ã„ã§ã™: {metrics.disk_usage_percent:.1f}%")
        
        # APIå¿œç­”æ™‚é–“ãƒã‚§ãƒƒã‚¯
        if metrics.api_response_time > self.alert_thresholds["api_response_time"]:
            alerts.append(f"APIå¿œç­”æ™‚é–“ãŒé…ã„ã§ã™: {metrics.api_response_time:.1f}ç§’")
        
        # ã‚¢ãƒ©ãƒ¼ãƒˆé€ä¿¡
        if alerts:
            await self.send_alerts(alerts, metrics)
    
    async def send_alerts(self, alerts: List[str], metrics: SystemMetrics):
        """ã‚¢ãƒ©ãƒ¼ãƒˆã®é€ä¿¡"""
        alert_message = f"""
ğŸš¨ ã‚·ã‚¹ãƒ†ãƒ ã‚¢ãƒ©ãƒ¼ãƒˆ - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

ä»¥ä¸‹ã®å•é¡ŒãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ:
{chr(10).join(f"â€¢ {alert}" for alert in alerts)}

ç¾åœ¨ã®ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ³:
â€¢ CPU: {metrics.cpu_percent:.1f}%
â€¢ ãƒ¡ãƒ¢ãƒª: {metrics.memory_percent:.1f}%
â€¢ ãƒ‡ã‚£ã‚¹ã‚¯: {metrics.disk_usage_percent:.1f}%
â€¢ APIå¿œç­”æ™‚é–“: {metrics.api_response_time:.1f}ç§’
"""
        
        # Slack/Teamsé€šçŸ¥ï¼ˆå®Ÿè£…ã¯ intelligent_monitor.py å‚ç…§ï¼‰
        logger.critical(alert_message)
    
    async def save_metrics(self, metrics: SystemMetrics):
        """ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®ä¿å­˜"""
        # JSONå½¢å¼ã§ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        metrics_data = {
            "timestamp": metrics.timestamp.isoformat(),
            "cpu_percent": metrics.cpu_percent,
            "memory_percent": metrics.memory_percent,
            "disk_usage_percent": metrics.disk_usage_percent,
            "active_connections": metrics.active_connections,
            "api_response_time": metrics.api_response_time
        }
        
        with open("system_metrics.jsonl", "a", encoding="utf-8") as f:
            json.dump(metrics_data, f, ensure_ascii=False)
            f.write("\n")
    
    def stop_monitoring(self):
        """ç›£è¦–åœæ­¢"""
        self.monitoring_active = False
        logger.info("æœ¬ç•ªç›£è¦–ã‚’åœæ­¢ã—ã¾ã—ãŸ")

# ä½¿ç”¨ä¾‹
async def start_production_monitoring():
    """æœ¬ç•ªç›£è¦–ã®é–‹å§‹"""
    monitor = ProductionMonitor()
    
    try:
        await monitor.start_monitoring(interval_seconds=30)  # 30ç§’é–“éš”
    except KeyboardInterrupt:
        monitor.stop_monitoring()
        print("ç›£è¦–ã‚’åœæ­¢ã—ã¾ã—ãŸ")

if __name__ == "__main__":
    asyncio.run(start_production_monitoring())
```

---

## âœ… å­¦ç¿’æˆæœã®ç¢ºèª

### ç¿’å¾—ã‚¹ã‚­ãƒ«ãƒã‚§ãƒƒã‚¯

ã“ã®ç¯€ã‚’å®Œäº†ã—ãŸã‚‰ã€ä»¥ä¸‹ã®é …ç›®ã«ã¤ã„ã¦å®Ÿéš›ã«æ“ä½œã§ãã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ï¼š

- [ ] **Pythonç’°å¢ƒæ§‹ç¯‰**: ä»®æƒ³ç’°å¢ƒãƒ»å¿…è¦ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®å®Œå…¨ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
- [ ] **Graph APIèªè¨¼**: Azure ADã‚¢ãƒ—ãƒªç™»éŒ²ã‹ã‚‰èªè¨¼ãƒ†ã‚¹ãƒˆã¾ã§
- [ ] **åŸºæœ¬APIæ“ä½œ**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ»ã‚°ãƒ«ãƒ¼ãƒ—ãƒ»ãƒ©ã‚¤ã‚»ãƒ³ã‚¹æƒ…å ±ã®å–å¾—ãƒ»æ“ä½œ
- [ ] **CSVå‡¦ç†ãƒ»æ¤œè¨¼**: å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã®å“è³ªç¢ºä¿ãƒ»Graph APIå½¢å¼å¤‰æ›
- [ ] **éåŒæœŸä¸€æ‹¬å‡¦ç†**: æ•°åƒåè¦æ¨¡ã®é«˜é€Ÿå‡¦ç†ãƒ»é€²æ—ç›£è¦–
- [ ] **ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°**: ãƒ¬ãƒ¼ãƒˆåˆ¶é™ãƒ»ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãƒ»èªè¨¼ã‚¨ãƒ©ãƒ¼ã®å¯¾å¿œ
- [ ] **å®Ÿé‹ç”¨å¯¾å¿œ**: ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ»ç›£æŸ»ãƒ»ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ ã®å®Ÿè£…

### å®Ÿè·µèª²é¡Œ: Pythonç‰ˆç·åˆæ¼”ç¿’

å®Ÿéš›ã®ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºç’°å¢ƒã‚’æƒ³å®šã—ãŸåŒ…æ‹¬çš„ãªèª²é¡Œã«å–ã‚Šçµ„ã‚“ã§ãã ã•ã„ï¼š

```markdown
ğŸ¯ ç·åˆèª²é¡Œ: ã‚°ãƒ­ãƒ¼ãƒãƒ«ä¼æ¥­ã® M365 çµ±åˆãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ

## èƒŒæ™¯
ã‚°ãƒ­ãƒ¼ãƒãƒ«ä¼æ¥­ãŒè¤‡æ•°ã®å­ä¼šç¤¾ã‚’è²·åã—ã€çµ±ä¸€ã®Microsoft 365ç’°å¢ƒã¸ã®ç§»è¡Œã‚’å®Ÿæ–½ã—ã¾ã™ã€‚

## æŠ€è¡“è¦ä»¶
- ç·ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°: 15,000åï¼ˆæœ¬ç¤¾5,000åã€å­ä¼šç¤¾A 4,000åã€å­ä¼šç¤¾B 3,000åã€ä»–3,000åï¼‰
- åœ°åŸŸ: æ—¥æœ¬ã€ã‚¢ãƒ¡ãƒªã‚«ã€ãƒ¨ãƒ¼ãƒ­ãƒƒãƒ‘ï¼ˆ3ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³ï¼‰
- æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ é€£æº: äººäº‹ã‚·ã‚¹ãƒ†ãƒ ï¼ˆREST APIï¼‰ã€Active Directory
- å‡¦ç†æ™‚é–“åˆ¶ç´„: å„åœ°åŸŸ 2æ™‚é–“ä»¥å†…ã§ã®å®Œäº†

## å®Ÿè£…è¦ä»¶
1. **ãƒãƒ«ãƒãƒªãƒ¼ã‚¸ãƒ§ãƒ³å¯¾å¿œ**: åœ°åŸŸåˆ¥ã®æ®µéšçš„å‡¦ç†
2. **å¤–éƒ¨ã‚·ã‚¹ãƒ†ãƒ é€£æº**: äººäº‹ã‚·ã‚¹ãƒ†ãƒ ã‹ã‚‰ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‡ãƒ¼ã‚¿åŒæœŸ
3. **è¤‡é›‘ãªæ¥­å‹™ãƒ­ã‚¸ãƒƒã‚¯**: å½¹è·ãƒ»åœ°åŸŸã«å¿œã˜ãŸãƒ©ã‚¤ã‚»ãƒ³ã‚¹è‡ªå‹•å‰²ã‚Šå½“ã¦
4. **å®Œå…¨è‡ªå‹•åŒ–**: ã‚¼ãƒ­ã‚¿ãƒƒãƒãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆ
5. **åŒ…æ‹¬çš„ç›£è¦–**: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ãƒ»ã‚¢ãƒ©ãƒ¼ãƒˆ
6. **ç½å®³å¯¾å¿œ**: éšœå®³æ™‚ã®è‡ªå‹•å¾©æ—§ãƒ»ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½

## æˆæœç‰©
- å®Œå…¨è‡ªå‹•åŒ–ã‚·ã‚¹ãƒ†ãƒ ï¼ˆPythonã‚³ãƒ¼ãƒ‰ä¸€å¼ï¼‰
- APIçµ±åˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆäººäº‹ã‚·ã‚¹ãƒ†ãƒ é€£æºï¼‰
- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰
- åŒ…æ‹¬çš„ãªãƒ†ã‚¹ãƒˆçµæœãƒ¬ãƒãƒ¼ãƒˆ
- éšœå®³å¯¾å¿œãƒ»å¾©æ—§æ‰‹é †æ›¸
- ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ãƒ¬ãƒãƒ¼ãƒˆ
```

---

## ğŸš€ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã¨ç™ºå±•å­¦ç¿’

### æ¨å¥¨å­¦ç¿’ãƒ‘ã‚¹

ã“ã®ç¯€ã‚’å®Œäº†ã—ãŸã‚‰ã€ä»¥ä¸‹ã®å­¦ç¿’ã«é€²ã‚€ã“ã¨ã‚’æ¨å¥¨ã—ã¾ã™ï¼š

1. **[3.4 ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ­ãƒ¼ãƒ«ã¨æ¨©é™](04-roles-permissions.md)**
   - Graph APIã‚’æ´»ç”¨ã—ãŸé«˜åº¦ãªæ¨©é™ç®¡ç†
   - ã‚«ã‚¹ã‚¿ãƒ ãƒ­ãƒ¼ãƒ«ãƒ»æ¡ä»¶ä»˜ãã‚¢ã‚¯ã‚»ã‚¹ã®è‡ªå‹•åŒ–

<!-- 2. **[ç¬¬5ç« : ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã¨ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹](../05-security-compliance/)** -->
   - Pythonã«ã‚ˆã‚‹ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒãƒªã‚·ãƒ¼ã®è‡ªå‹•åŒ–
   - ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹ãƒ¬ãƒãƒ¼ãƒˆã®è‡ªå‹•ç”Ÿæˆ

<!-- 3. **[ç¬¬8ç« : é‹ç”¨ç›£è¦–ã¨ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°](../08-monitoring-troubleshooting/)** -->
   - åŒ…æ‹¬çš„ãªç›£è¦–ã‚·ã‚¹ãƒ†ãƒ ã®æ§‹ç¯‰
   - AIé§†å‹•ã®ç•°å¸¸æ¤œçŸ¥ã‚·ã‚¹ãƒ†ãƒ 

### ç™ºå±•æŠ€è¡“é ˜åŸŸ

- **Microsoft Graph API ã®é«˜åº¦æ´»ç”¨**: Webhookãƒ»å·®åˆ†ã‚¯ã‚¨ãƒªãƒ»ãƒãƒƒãƒå‡¦ç†
- **Azure Functions ã¨ã®é€£æº**: ã‚µãƒ¼ãƒãƒ¼ãƒ¬ã‚¹è‡ªå‹•åŒ–ã‚·ã‚¹ãƒ†ãƒ 
- **AIãƒ»æ©Ÿæ¢°å­¦ç¿’ã®æ´»ç”¨**: ç•°å¸¸æ¤œçŸ¥ãƒ»äºˆæ¸¬åˆ†æãƒ»è‡ªå‹•æœ€é©åŒ–
- **DevOpsçµ±åˆ**: CI/CDãƒ»Infrastructure as Codeãƒ»è‡ªå‹•ãƒ†ã‚¹ãƒˆ
- **ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹åŒ–**: ã‚³ãƒ³ãƒ†ãƒŠåŒ–ãƒ»Kubernetesãƒ»åˆ†æ•£ã‚·ã‚¹ãƒ†ãƒ 

### å®Ÿç”¨çš„ãªãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆä¾‹

### å®Ÿç”¨çš„ãªãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆä¾‹

ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã¯ã€æœ¬ã‚¬ã‚¤ãƒ‰ã§ç¿’å¾—ã—ãŸæŠ€è¡“ã‚’ç™ºå±•ã•ã›ãŸã€å®Ÿéš›ã®ä¼æ¥­ç’°å¢ƒã§ä¾¡å€¤ã‚’ç™ºæ®ã™ã‚‹é«˜åº¦ãªãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆä¾‹ã§ã™ã€‚ã“ã‚Œã‚‰ã¯å˜ãªã‚‹å­¦ç¿’ç”¨ã‚µãƒ³ãƒ—ãƒ«ã§ã¯ãªãã€å®Ÿè£…ã™ã‚Œã°å³åº§ã«ãƒ“ã‚¸ãƒã‚¹ä¾¡å€¤ã‚’æä¾›ã§ãã‚‹å®Ÿç”¨çš„ãªã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã¨ãªã£ã¦ã„ã¾ã™ã€‚

**å„ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®å®Ÿç”¨çš„ä¾¡å€¤:**

**1. AIé§†å‹•ãƒ¦ãƒ¼ã‚¶ãƒ¼åˆ†æã‚·ã‚¹ãƒ†ãƒ **
- **ROI**: 15-30%ã®ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã‚³ã‚¹ãƒˆå‰Šæ¸›
- **åŠ¹æœ**: æœªä½¿ç”¨ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã®è‡ªå‹•æ¤œå‡ºã€æœ€é©ãªé…ç½®ã®æ¨å¥¨
- **é©ç”¨å ´é¢**: 1000åä»¥ä¸Šã®å¤§è¦æ¨¡çµ„ç¹”ã§ã®å®šæœŸçš„ãªæœ€é©åŒ–

**2. çµ±åˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚·ã‚¹ãƒ†ãƒ **  
- **ROI**: äººäº‹æ¥­å‹™åŠ¹ç‡80%å‘ä¸Š
- **åŠ¹æœ**: å…¥ç¤¾ãƒ»ç•°å‹•ãƒ»é€€ç¤¾ãƒ—ãƒ­ã‚»ã‚¹ã®å®Œå…¨è‡ªå‹•åŒ–
- **é©ç”¨å ´é¢**: äººäº‹ç•°å‹•ãŒé »ç¹ãªçµ„ç¹”ã§ã®é‹ç”¨è² è·å‰Šæ¸›

**3. ã‚»ãƒ«ãƒ•ã‚µãƒ¼ãƒ“ã‚¹ãƒãƒ¼ã‚¿ãƒ«**
- **ROI**: ITç®¡ç†æ¥­å‹™è² è·50%å‰Šæ¸›
- **åŠ¹æœ**: ã‚¨ãƒ³ãƒ‰ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è‡ªç«‹çš„ãªç®¡ç†ã€å•ã„åˆã‚ã›å‰Šæ¸›
- **é©ç”¨å ´é¢**: ITéƒ¨é–€ã®ãƒªã‚½ãƒ¼ã‚¹æœ€é©åŒ–ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼æº€è¶³åº¦å‘ä¸Š

**æŠ€è¡“çš„ãªç™ºå±•è¦ç´ :**
- **æ©Ÿæ¢°å­¦ç¿’**: scikit-learn, TensorFlow ã§ã®äºˆæ¸¬åˆ†æ
- **Web ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯**: FastAPI, Flask ã§ã®APIé–‹ç™º
- **ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰**: React, Vue.js ã§ã®ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰
- **ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹**: PostgreSQL, MongoDB ã§ã®å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ç®¡ç†
- **ã‚³ãƒ³ãƒ†ãƒŠ**: Docker, Kubernetes ã§ã®æœ¬ç•ªå±•é–‹

**å®Ÿè£…ã®æ®µéšçš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ:**
1. **MVP (Minimum Viable Product)**: åŸºæœ¬æ©Ÿèƒ½ã®å®Ÿè£…ãƒ»æ¤œè¨¼
2. **æ©Ÿèƒ½æ‹¡å¼µ**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã«åŸºã¥ãæ”¹å–„
3. **ã‚¹ã‚±ãƒ¼ãƒ«å¯¾å¿œ**: å¤§è¦æ¨¡ç’°å¢ƒã§ã®æ€§èƒ½æœ€é©åŒ–
4. **AIçµ±åˆ**: æ©Ÿæ¢°å­¦ç¿’ã«ã‚ˆã‚‹é«˜åº¦ãªè‡ªå‹•åŒ–

```python
# ç™ºå±•ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ã‚¢ã‚¤ãƒ‡ã‚¢

# 1. AIé§†å‹•ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼åˆ†æã‚·ã‚¹ãƒ†ãƒ 
class AIUserAnalytics:
    """æ©Ÿæ¢°å­¦ç¿’ã‚’æ´»ç”¨ã—ãŸãƒ¦ãƒ¼ã‚¶ãƒ¼è¡Œå‹•åˆ†æ"""
    
    async def analyze_usage_patterns(self):
        """ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æãƒ»ç•°å¸¸æ¤œçŸ¥"""
        pass
    
    async def predict_license_needs(self):
        """ãƒ©ã‚¤ã‚»ãƒ³ã‚¹éœ€è¦äºˆæ¸¬"""
        pass
    
    async def recommend_optimizations(self):
        """æœ€é©åŒ–æ¨å¥¨ã®è‡ªå‹•ç”Ÿæˆ"""
        pass

# 2. çµ±åˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚·ã‚¹ãƒ†ãƒ 
class IntegratedWorkflowSystem:
    """è¤‡æ•°ã‚·ã‚¹ãƒ†ãƒ çµ±åˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼"""
    
    async def sync_with_hr_system(self):
        """äººäº‹ã‚·ã‚¹ãƒ†ãƒ ã¨ã®åŒæ–¹å‘åŒæœŸ"""
        pass
    
    async def automated_onboarding(self):
        """å®Œå…¨è‡ªå‹•åŒ–ã•ã‚ŒãŸæ–°äººç ”ä¿®ãƒ—ãƒ­ã‚»ã‚¹"""
        pass
    
    async def compliance_automation(self):
        """ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹è¦ä»¶ã®è‡ªå‹•é©ç”¨"""
        pass

# 3. ã‚»ãƒ«ãƒ•ã‚µãƒ¼ãƒ“ã‚¹ãƒãƒ¼ã‚¿ãƒ«
class SelfServicePortal:
    """ã‚¨ãƒ³ãƒ‰ãƒ¦ãƒ¼ã‚¶ãƒ¼å‘ã‘ã‚»ãƒ«ãƒ•ã‚µãƒ¼ãƒ“ã‚¹"""
    
    async def user_profile_management(self):
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼è‡ªèº«ã«ã‚ˆã‚‹æƒ…å ±æ›´æ–°"""
        pass
    
    async def access_request_system(self):
        """ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ã®ç”³è«‹ãƒ»æ‰¿èªã‚·ã‚¹ãƒ†ãƒ """
        pass
    
    async def automated_support(self):
        """AI ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã«ã‚ˆã‚‹è‡ªå‹•ã‚µãƒãƒ¼ãƒˆ"""
        pass
```

---

## ğŸ“š å‚è€ƒãƒªã‚½ãƒ¼ã‚¹

### Microsoftå…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

- **[Microsoft Graph API Reference](https://docs.microsoft.com/en-us/graph/api/overview)** - å®Œå…¨ãªAPIä»•æ§˜
- **[Microsoft Graph Python SDK](https://github.com/microsoftgraph/msgraph-sdk-python)** - å…¬å¼Python SDK
- **[Azure Identity Python Library](https://docs.microsoft.com/en-us/python/api/azure-identity/)** - èªè¨¼ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
- **[Microsoft Graph ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹](https://docs.microsoft.com/en-us/graph/best-practices-concept)** - ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–

### Pythonãƒ©ã‚¤ãƒ–ãƒ©ãƒªãƒ»ãƒ„ãƒ¼ãƒ«

- **[aiohttp](https://docs.aiohttp.org/)** - éåŒæœŸHTTPã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
- **[pandas](https://pandas.pydata.org/)** - ãƒ‡ãƒ¼ã‚¿åˆ†æãƒ»æ“ä½œ
- **[tenacity](https://tenacity.readthedocs.io/)** - è‡ªå‹•å†è©¦è¡Œãƒ©ã‚¤ãƒ–ãƒ©ãƒª
- **[rich](https://rich.readthedocs.io/)** - ãƒªãƒƒãƒãªã‚³ãƒ³ã‚½ãƒ¼ãƒ«å‡ºåŠ›
- **[loguru](https://loguru.readthedocs.io/)** - é«˜æ©Ÿèƒ½ãƒ­ã‚°ã‚·ã‚¹ãƒ†ãƒ 

### ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ãƒ»ã‚µãƒãƒ¼ãƒˆ

- **[Microsoft Graph Community](https://techcommunity.microsoft.com/t5/microsoft-graph/ct-p/microsoftgraph)** - å…¬å¼ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£
- **[Stack Overflow - Microsoft Graph](https://stackoverflow.com/questions/tagged/microsoft-graph)** - æŠ€è¡“çš„ãªè³ªå•ãƒ»å›ç­”
- **[GitHub - Microsoft Graph Samples](https://github.com/microsoftgraph/)** - ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰ãƒ»å®Ÿä¾‹
- **[Microsoft Graph Blog](https://developer.microsoft.com/en-us/graph/blogs/)** - æœ€æ–°æƒ…å ±ãƒ»ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹

### å®Ÿè·µçš„ãªå­¦ç¿’ãƒªã‚½ãƒ¼ã‚¹

<!-- - **[Graph API æ¼”ç¿’ç”¨ã‚¹ã‚¯ãƒªãƒ—ãƒˆé›†](../../appendices/python-scripts/)** -->
   - èªè¨¼ãƒ»åŸºæœ¬æ“ä½œãƒ»ä¸€æ‹¬å‡¦ç†ã®å®Œå…¨ãªã‚µãƒ³ãƒ—ãƒ«
   - ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ»ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ä¾‹

<!-- - **[å®Ÿè£…ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ](../../appendices/checklists/python-implementation-checklist.md)** -->
   - æœ¬ç•ªç’°å¢ƒå±•é–‹å‰ã®ç¢ºèªé …ç›®
   - ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ»ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ»é‹ç”¨ã®è¦³ç‚¹

<!-- - **[ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚¬ã‚¤ãƒ‰](../../appendices/troubleshooting/python-graph-api-issues.md)** -->
   - ã‚ˆãã‚ã‚‹å•é¡Œã¨è§£æ±ºæ–¹æ³•
   - ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å•é¡Œã®è¨ºæ–­æ‰‹é †

---

*ğŸ“… æœ€çµ‚æ›´æ–°: 2025å¹´6æœˆ2æ—¥*  
*âœï¸ æ›´æ–°è€…: Microsoft 365 ãƒãƒ³ãƒ‰ãƒ–ãƒƒã‚¯ç·¨é›†ãƒãƒ¼ãƒ *  
*ğŸ“– å¯¾è±¡ãƒãƒ¼ã‚¸ãƒ§ãƒ³: Microsoft 365 (2025å¹´6æœˆç‰ˆ) 